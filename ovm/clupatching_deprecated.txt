""" 
 Copyright (c) 2014, 2021, Oracle and/or its affiliates.

NAME:
    Patch - Basic Functionality

FUNCTION:
    Provide basic/core API for manageing the Exadata patching in the cluster

Special note for developer:-  
     The clupatching.py is no more used on production env and it's obsoleted.
     This file is refactored and re-implemented under below path. If you wanted
     to make changes to clupatching.py, then plan to make to below code path 
     without miss and contact infra patching dev team for any help.

     Infra patching refactor code located in below path:
         ecs/exacloud/exabox/infrapatching/

     But, we wanted to keep this file here as is for sometime.

NOTE:
    None

History:
    MODIFIED (MM/DD/YY)
    nmallego 06/13/21 - ER 32991330 - The clupatching is obsoleted and hence  
                        renaming to clupatching_deprecated.py but still keep
                        it here for reference. 
    alsepulv 03/16/21 - Enh 32619413: remove any code related to Higgs
    rajsag   02/12/21 - x8m :bb:after provisioning with elastic cells /u02
                         downscale reshape failed after waiting for crs to come
                         up
    josedelg 05/01/21 = Bug32315902 - Change env variable from 
                        EXADATA_IMAGE_IBSWITCH_ROLLBACK_VERSION to
                        EXADATA_IMAGE_IBSWITCH_DOWNGRADE_VERSION
    nmallego 12/07/20 - Bug31982131 - Do not ignore real h/w alerts
    araghave 07/28/20 - Bug31399993 - Cleanup ibswitch flags
    araghave 07/28/20 - Bug32204077 - Fetch correct target version for switch
    sringran 11/23/20 - Bug32025441 - INFRA PATCH TIMEDOUT EVEN THOUGH
                        PATCHMGR SUCEEDED
    nmallego 11/13/20 - Bug32134826 - Do not read patchmgr console if patching 
                        request is not idempotent/retry
    nmallego 11/04/20 - Bug32109585 - override latest conversion for exacc
    vmallu   10/29/20 - Bug 32078800 - Clusterless cell patching fails consistently
                        with ECRA 20.2.1 DROP 6
    vmallu   10/14/20 - Bug 32006820 - ecracli patch cmd fails with 
                        data too long for column
    nmallego 10/08/20 - Bug31987132 - Return [] instead of None in 
                        mGetExcludedList()
    vmallu   10/05/20 - XbranchMerge vmallu_bug-31900436 from
                        st_ecs_20.2.1.0.0rel
    gsundara 10/05/20 - bug 31959933: fwd merge from 20.2.1
    vmallu   09/28/20 - Bug 31945775 - X8M STORAGE-ONLY CABINET CLUSTERLESS
                        PATCHING FAILS
    vgerard  09/24/20 - Bug31919030: Populate Dom0s for clusterless rack
    pbellary 08/19/20 - Bug 31768768 - Revised fortify fix
    nmallego 08/17/20 - Bug 31761732 - target_version list with return payload
    pbellary 08/10/20 - Bug 31364037 - FORTIFY: COMMAND INJECTION IN LOCAL.PY
    nmallego 08/09/20 - Bug31730630 - Fix string decode in ANSI Escape chars
    vgerard  08/07/20 - Bug 31677145 - Fix error no '_EXABOXCLUCTRL__UUID'
    nmallego 08/07/20 - ER  31678601 - Upgrade free nodes from elastic cabinet
    vmallu   08/06/20 - Bug 31536500 - xml entity expansion
    scoral   07/30/20 - Bug30590874 - Adding compatible code to support python3.
    vmallu   07/29/20 - Enh 31690438 - Support heterogeneous patch versions
    araghave 07/28/20 - BUG 31678870 - DBMCLI STATUS OUTPUT CHANGES REQUIRED IN
                        NEWER EXADATA VERSIONS
    naps     07/24/20 - XbranchMerge naps_bug-31637189_19.4.3.3.0 from
                        st_ecs_19.4.3.0.0
    jyotdas  07/15/20 - Enh 31606581 - EXACLOUD: SUPPORT SINGLE NODE DOM UPGRADE
                        WITH NON ROLLING STYLE
    nmallego 07/13/20 - Bug31605216 - Connect as opc user for dom0domu plugins
                        console log read 
    talagusu 07/07/20 - Bug 31582140 - INFRA PATCHING SHOULD IGNORE DOM0DOMU
                        PLUGINS WHEN NON-ROLLING
    araghave 07/01/20 - Bug 31465889 - RESTORE ATP SPECIFIC SYSCTL SETTINGS
                        POST DOMU UPGRADE
    araghave 05/29/20 - Bug 31420579 - CONFIG PATH CHANGES FOR EXACC
                        ENVIRONMENTS TO STORE PATCH CHECKSUM FILES
    vmallu   05/28/20 - BUG 31395282 - EXACS domo patching failed to establish
                        domu heartbeat with cell
    araghave 05/27/20 - Bug 31223513 - INFRAPATCHING: INVALID REQUEST ADDED
                        WHEN PATCHING ATTEMPTED VIA CURL
    nmallego 05/19/20 - Bug31376251 - Wrong PatchPayload path on ExaCC
    nmallego 05/15/20 - Bug31115077: Upgrade RocE/KVM based components
    naps     07/20/20 - check if crs and db is up during resize.
    devbabu  05/04/20 - remove the duplicate error code
    nmallego 04/28/20 - Bug31234669: Read RackName from ecra payload
    scoral   04/23/20 - Bug 31145240 - Python 3 migration code adaption
    nmallego 04/07/20 - Enh 30995812 - Make pre and post plugins idempotent
    nmallego 03/30/20 - ER 30995919 - store patching states in metadata json
    vmallu   03/30/20 - Bug 31049092 - EXACCOCI: INFRA PATCHING FAILING AT 
                        IMPORTKEYS WITH KMS
    vmallu   03/30/20 - Bug 31101389 - fix ociexacc patch payload patch
    araghave 03/22/20 - Bug 31065254 - Non log rotation, heartbeat check is 
                        failed.
    araghave 03/20/20 - Enh 31052954 - MAKE PRE AND POST PLUGINS SCRIPTS RUN IN
                        BACKGROUND
    nmallego 03/16/20 - Bug30922125 - fix concurrent issue
    jyotdas  03/10/20 - Bug 31007529 - Cleanup and fix the ssh leaks in
                        clupatching layer
    araghave 03/03/20 - Bug 30536095 - COPYING THE SYSTEM IMAGE ISO FOR THE
                        WRONG TARGET VERSION
    araghave 02/27/20 - Bug 30932804 - PRECHECK FAILS TO FIND DOMU HEARTBEAT IN
                        CELL ALERT LOG
    araghave 02/19/20 - Enh 30908782 - ksplice and one-off configuration on dom0 
                        and cells
    nmallego 02/05/20 - Enh Bug30687255 - Idempotent on patching
    araghave 02/17/20 - BUG 30908200 - DISABLE EXAWATCHER LOG COLLECTION FOR
                        PATCHING DURING INCIDENT LOG COLLECTION.
    araghave 01/15/20 - Bug 30768661 - ADD MISSING LOG DIRECTORY PATH FOR ALL
                        THE DOMU OPERATIONS
    nmallego 01/08/20 - Bug-30327503 - fix fortify errors
    araghave 12/24/19 - Enh 30687229 - EXACLOUD: PATCHMGR SHOULD RUN WITH NOHUP
                        ON LAUNCH NODE
    nmallego 11/24/19 - Bug29997448 - Add detail to return payload in case of
                        no action taken
    araghave 11/13/19 - Bug 30511640 - Exception handling for validating
                        services on IbSwitch
    araghave 10/30/19 - Bug 28493752 - Enable patchmgr to run in Non-rolling
                        fashion during prereq operations for the notifications
                        to work
    araghave 10/29/19 - BUG 30458885 - Import SSH  keys in a KMS environment
    araghave 09/30/19 - ER-30208083 - ATP/EXACLOUD INFRA PATCHING: DISALLOW
                        PATCHING UNLESS POSTCHECKS SUCCEEDED 
    araghave 10/03/19 - ENH 30208068 - ATP/EXACLOUD INFRA PATCHING: DETECT
                        KNOWN H/W INTERFACE ALERTS GENERATED
    araghave 09/23/19 - Enh 30337815 - COMPARE CRS RESOURCES BEFORE AND AFTER
                        DOMU PATCHING ACTIVITY
    sringran 09/23/19 - BUG 30336872 - INCORRECT DISK SPACE CALCULATION CAUSING
                        19.2.6 PATCHING FAILURE
    araghave 09/04/19 - BUG 30174632 - PATCHING PRE-CHECK SHOULD CHECK THE NTP
                        CONFIGURATION OF IB SWITCH.
    araghave 09/03/19 - Bug 30243541 - EXCEPTION IN RUNNING PATCHING
                        OPERATION MULTIPLE TIME
    araghave 08/13/19 - Bug 30176781 - Correct invalid path reference to 
                        exadata system image bits
    nmallego 08/07/19 - Bug30115824: Read customer name based on xmlns tag
                        in oeda xml 
    nmallego 08/01/19 - Bug30125729 - Use common plugin directory path 
    araghave 07/18/19 - Bug 30069717 - MAP PATCHPAYLOAD TO IMAGE DOWNLOAD 
                        LOCATION FOR OCI-EXACC 
    araghave 07/18/19 - ENH 30006991 - GENERATE INCIDENT ZIP FILE DURING INFRA
                        PATCHING OPERATION
    oespinos 07/16/19 - 30052539 - CLUSTER MEMORY RESHAPE IS FAILING
    araghave 07/10/19 - Bug 30034127 - REVERTING CHANGES OF ENH 29833650
    nmallego 07/09/19 - Bug30014992: Receive oeda xml data and written 
                        to a file with base64
    araghave 07/02/19 - ENH 29911293 - POSTCHECK OPTION FOR ALL PATCH
                        OPERATIONS.
    araghave 06/20/19 - ENH 29833650 EXADATA INFRA PATCHING: MAP TO DOWNLOAD 
                        LOCATION FROM IMAGE MGT SERVICE FOR PATCHPAYLOAD
    araghave 05/19/19 - Bug 29800200 - Pass non-rolling option for prereq 
                        on all the targets.
    araghave 05/16/19 - Bug 29669900 - griddisk status check during prereq
                        and patch operations
    nmallego 05/08/19 - Bug29719329 - fix disk free (df) command option
    araghave 04/10/19 - Bug 29623387 - Exacloud mount point validation as 
                        per exabox.conf file
    nmallego 04/08/19 - Bug29608693 - plugins version 3
    araghave 03/29/19 - Bug 28248796 - fedramp configuration check
    araghave 03/18/19 - Bug 28584487 - Exacloud mount point storage check
                        before proceeding with patch requests.
    araghave 03/15/19 - ENH 29486325 - Additional options added for 
                        IgnoreAlerts, ForceRemoveCustomRpms and ModifyAtPrereq 
                        cases.
    nmallego 02/13/19 - Bug29305666: Patch specified node
    vmallu   03/06/19 - Bug 29435285 - fix running cellsrv count logic 
    araghave 03/04/19 - Bug29434322 - IBSwitch patch logs copy fix.
    nmallego 02/26/19 - Bug29324353 - Add Diag code: log exec command in 
                        mCheckTargetVersion() when fetching image version
    araghave 02/16/19 - Bug 28823221 : Post checks - higgs configuration
    nmallego 01/23/19 - Bug29052011: Pre and Post Exalcoud Plugins-V2
    nmallego 01/07/19 - Bug29136926: Replace service command with cellcli to
                        check cellsrv status
    nmallego 12/14/18 - bug29056361 - Stop node upgrade if there any failure
                        and do not continue
    vmallu   12/13/18 - Bug 29052055 - NEED TO HAVE EXECUTE PERMISSION ON THE
                        PRE POST PLUGINS AFTER COPY TO DOMU AND DOM0 NODE
    nmallego 12/02/18 - Bug29002621 - fix the typo
    nmallego 11/16/18 - Bug26774129 - pre-post plugins/scripts run
    nmallego 11/08/18 - Bug28876616 - Need adjust to correct version format
    nmallego 10/29/18 - Bug28845368: Add diag code
    pnkrishn 10/19/18 - 28568167: Ib switch ssh connection leak
    pnkrishn 09/22/18 - 28632087: asmdeactivationoutcome check
    nmallego 09/03/18 - Bug28585904: Log appropriate message if node list 
                        turn out to be empty.
    nmallego 07/06/18 - Bug28225552 - Add log path to output json of exacloud
    nmallego 06/13/18 - ER Bug28155938 - Pass additional options for exadata
                        infra patching and integrate of ibswitch upgrade per
                        rack basis
    nmallego 06/06/18 - Bug28126586 - Validate the image version of the node
                        during prereq and upgrade
    nmallego 04/02/18 - Bug27796233 - evaluate latest target version properly
                        to cover version format 18.1.3.0.0.171219.2'
    nmallego 03/14/18 - Bug27643616 - add option BackupMode for upgrade of
                        domU/dom0
    nmallego 03/07/18 - Bug27643008 - Enhance exadata infra patching capability
                        to take image backup separately
    nmallego 03/02/18 - Bug27556005 - have single class object for ssh setup
                        and cleanup to retain the host_key comment
    nmallego 02/23/18 - Bug27589883 - Patchmgr and postcheck steps needs to be
                        corrected for dom0 and domU upgrade
    nmallego 02/20/18 - Bug27574842 - Invalid string format in
                        mPatchDom0sOrDomus()
    nmallego 02/10/18 - Bug27409907 - fix the issue of parsing cell heartbeat
                        logic
    nmallego 01/09/18 - Bug27156405 - Scan OSS to get the latest verion and
                        also download missing files from OSS
    nmallego 01/02/18 - Bug27263414 - read grid hb timeout and exacloud patch
                        size from exabox.conf, instead from system env variable
    nkedlaya 12/08/17 - Bug 27239627 - EXABMC:17.4.2:DOM0 PATCH
                        FAILURE-NAMEERROR: GLOBAL NAME TR IS NOT DEFINED
    nmallego 12/04/17 - bug27084627 - update logdir path for domu/dom0
    nmallego 11/17/17 - Bug27130067 - mPatchDom0sOrDomus should take
                        appropriate action for CNS
    nmallego 11/09/17 - bug27099983 - fix undefined var node_to_patch_nodes
    nkedlaya 10/28/17 - BUG 27032704 - DOMU EXADATA UPDATE TO USE DOMU S LAUNCH
                        POINT NOT DOM0
    nmallego 10/27/17 - Bug26830429 - add option LATEST to patch operation
    nmallego 10/03/17 - Bug26726236 - Additional post check for ibswitch
    nmallego 10/09/17 - Bug26943824 - fix the ibswitch post check failure
    nmallego 10/05/17 - bug26863775 - add exadata_rack to cns payload
    nmallego 08/18/17 - patch notification for dom0, cell, domu, ibswitch
    nkedlaya 08/24/17 - Bug 26678535 - APPLY SECURITY FIXES EXADATA
                        12.2.1.1.2.170714 FAILED ON SECOND DOM0
    pnkrishn 08/11/17 - 26618330: Incorrect validate of IBSwitchVersion
                        upgrade/downgrade
    nkedlaya 08/09/17 - bug 26608328 : DOM0 patching fails with
                        __domu_patch_base_after_unzip object has no attribute
    nmallego 07/20/17 - bug26499199 - Use log_dir option with patchmgr (for
                        cell and ibswitch patch operations)
    nkedlaya 06/14/17 - bug 26242636 : EXACLOUD DOMU PATCHING SHOULD COPY
                        PATCHMGR DIAGS,TRACES TO DOM0
    nkedlaya 05/17/17 - add patching input json key constants
    nkedlaya    12/05/2017 - bug 25892555 - implement domu patching in exacloud
    bmartin     03/17/2016 - Dom0 patchmgr functionality
    marrorod    03/17/2016 - Cell/IBSwitch patchmgr functionality
    bmartin     03/18/2016 - post dom0 patch heartbeat checks
    marrorod    04/15/2016 - Master request support. Monitor added
    bmartin     04/22/2016 - Environment variables support
    marrorod    04/25/2016 - Error handling
    marrorod    04/26/2016 - Added checks: DB services, cell services, ping host, SM state
    bmartin     04/26/2016 - Added target version check
    marrorod    04/28/2016 - Lock changes. Master request acquires the lock before sending a request
"""
import os
import re
import string
import time
import datetime
import json
import copy
import zipfile
import traceback
import threading
from time import sleep
import random
from uuid import uuid4
from exabox.BaseServer.AsyncProcessing import ProcessManager, ProcessStructure
from exabox.core.Error import ebError, ebPatchBuildError, ExacloudRuntimeError
from exabox.core.Node import exaBoxNode
from exabox.log.LogMgr import ebLogError, ebLogInfo, ebLogWarn, ebLogDebug
from exabox.core.Context import get_gcontext
from exabox.ovm.vmcontrol import ebVgLifeCycle
from exabox.core.DBStore import ebGetDefaultDB
from multiprocessing import Process
from exabox.agent.Client import ebExaClient
from exabox.ovm.clumisc import ebCluSshSetup
from defusedxml import ElementTree as ET
from exabox.ovm.clumisc import OracleVersion
from base64 import b64decode
from exabox.ovm.clumisc import ebFortifyIssues
from exabox.ovm.clupatchmetadata import mWritePatchInitialStatesToLaunchNodes, mUpdatePatchMetadata, mGetLaunchNodeForTargetType
from exabox.ovm.clupatchmetadata import mUpdateMetadataLaunchNode, mUpdateAllPatchStatesForNode, mGetPatchStatesForNode

def mSetFromEnv(default, aEnvVariable=None, aErrorOn=None, aMustConvertTo=None):
    """
       Returns default (str) unless aEnvVariable (str) is provided and an environment variable with the same name exists.
       aErrorOn is an optional list of strings that can be checked to make sure the value does not equal.
       aMustConvertTo is an optional type (str, int, float) that can check to make sure the value
       (which is, and will be returned as string) can safely convert to
     """

    if aEnvVariable and aEnvVariable in os.environ:
        value = os.environ[aEnvVariable]
    else:
        # Just return default, no point in testing error conditions on it.
        return default

    if aErrorOn:
        if any(value == error_value for error_value in aErrorOn):
            err_msg = ("constant taken from environment variable %s should not be any of [%s] but we got %s"
                       % (aEnvVariable, ",".join(aErrorOn), value))
            raise Exception(err_msg)

    if aMustConvertTo:
            try:
                if aMustConvertTo == int:
                    int(value)
                elif aMustConvertTo == float:
                    float(value)
                # It should always be convertable to string (env variables are all strings), but, just to be safe
                elif aMustConvertTo == str:
                    str(value)
            except ValueError as e:
                ebLogError(str(e))
                err_msg = ("constant taken from environment variable %s should be convertable to type [%s], we got %s"
                           % (aEnvVariable, aMustConvertTo, value))
                raise Exception(err_msg)

    return value


class ebCluPatchControl(object):
    """
    TODO:
        1) DomU processing.
        2) Non rolling processing.
        3) One-offs patch processing.
        4) Change the behavior of the patch depending on the target environment.

    Processes a single cluster for any target type (dom0, cell, ibswitch).
    Processes operations: patch_prereq_check, patch, rollback_prereq_check,
                          rollback, backup_image on dom0/domU.
    Type of processing: rolling.

    """
    PATCH_BASE = mSetFromEnv(default="/EXAVMIMAGES/", aEnvVariable="EXACLOUD_PATCH_PAYLOAD_BASE", aErrorOn=["/tmp", "/tmp/"])
    EXADATA_PATCH_WORKING_SPACE_MB = 0 
    EXADATA_PATCH_GRID_HEARTBEAT_TIMEOUT_SEC = 0 
    EXADATA_PATCHMGR_CONSOLE_READ_TIMEOUT_SEC = 0
    EXACLOUD_DO_DOM0_ROLLBACK_EVEN_IF_DOMU_MODIFIED_POST_PATCH = mSetFromEnv(default="", aEnvVariable="EXACLOUD_DO_DOM0_ROLLBACK_EVEN_IF_DOMU_MODIFIED_POST_PATCH")

    PATCH_STDOUT      = "patchmgr.stdout"
    PATCH_STDERR      = "patchmgr.stderr"
    PATCH_TRC         = "patchmgr.trc"
    PATCH_LOG         = "patchmgr.log"
    PATCH_CONSOLE_LOG = "PatchmgrConsole.out"
    IBSWITCH_LOG = "upgradeIBSwitch.log"
    IBSWITCH_TRC = "upgradeIBSwitch.trc"

    PATCH_DOM0     = "dom0"
    PATCH_CELL     = "cell"
    PATCH_IBSWITCH = "ibswitch"
    PATCH_ROCESWITCH = "roceswitch"
    PATCH_DOMU     = "domu"
    PATCH_ALL      = "all_nodes"
    PRE_PATCH   = "pre_patch"
    POST_PATCH  = "post_patch"
    PATCH_MGR   = "patch_mgr"
    PLUGIN_DBNU     = "dbnu_plugins"
    PLUGIN_EXACLOUD = "exacloud_plugins"

    PATCH_PENDING   = "pending"
    PATCH_RUNNING   = "running"
    PATCH_FAILED    = "failed"
    PATCH_COMPLETED = "completed"

    CELL_ALERT_LOG = "$CELLTRACE/alert.log"
    DOM0_ROLLBACK_NOT_ALLOWED = -2000
    DOM0_POSTCHECKS_FAILED = -3000
    DOMU_POSTCHECKS_FAILED = -6000
    DOMU_PRECHECKS_FAILED = -7000
    DOM0_PRECHECKS_FAILED = -8000
    NO_ACTION_REQUIRED = -4000
    NO_DOM0U_LIST_RUN = -5000

    TASK_PREREQ_CHECK = "patch_prereq_check"
    TASK_PATCH = "patch"
    TASK_POSTCHECK = "postcheck"
    TASK_ROLLBACK_PREREQ_CHECK = "rollback_prereq_check"
    TASK_ROLLBACK = "rollback"
    TASK_BACKUP_IMAGE = "backup_image"
    TASK_KSPLICE = "ksplice"
    TASK_ONEOFF = "oneoff"

    PAYLOAD_RELEASE = 'exadata_release'
    PAYLOAD_NON_RELEASE = 'one-offs'
    ENV_PRODUCTION = 'production'
    ENV_PREPRODUCTION = 'preproduction'
    ENV_DEVELOPMENT = 'development'
    ENV_TEST = 'test'
    OP_STYLE_AUTO = 'auto'
    OP_STYLE_ROLLING = 'rolling'
    OP_STYLE_NON_ROLLING = 'non-rolling'
    OP_BACKUPMODE_NO = 'no'
    OP_BACKUPMODE_YES = 'yes'
    OP_FEDRAMP_ENABLED = 'ENABLED'
    OP_FEDRAMP_DISABLED = 'DISABLED'
    CNS_OP_SLEEP_TIME_SECONDS = 5 
    CNS_OP_TIME_OUT_SECONDS = 180 
    CNS_OP_MONITOR_INTERVAL_SECONDS = 60 
    PREPATCH_CRS_LOG = "/var/log/exadatatmp/prepatch_crs_stat.log"
    POSTPATCH_CRS_LOG = "/var/log/exadatatmp/postpatch_crs_stat.log"

    ANSI_ESCAPE = re.compile(r'(\x9B|\x1B\[)[0-?]*[ -\/]*[@-~]')
    WAIT_LINES_ESCAPE = re.compile(r'(/|-|\||\\){5}')

    STEP_SELECT_LAUNCH_NODE = 'select_launch_node_and_copy_files'
    STEP_FILTER_NODES = 'filter_nodes'
    STEP_GATHER_NODE_DATA = 'gather_data'
    STEP_PREP_ENV = 'prepare_environment'
    STEP_RUN_PATCH_CELL = 'patch_cells'
    STEP_RUN_PATCH_IBSWITCH = 'patch_ibswitches'
    STEP_RUN_PATCH_DOM0 = 'patch_dom0s'
    STEP_RUN_PATCH_DOMU = 'patch_domus'
    STEP_RUN_PATCH_SECOND_DOM0 = 'patch_init_dom0'
    STEP_RUN_PATCH_SECOND_DOMU = 'patch_init_domu'
    STEP_CLEAN_UP = 'clean_up_cells'
    STEP_CLEAN_ENV = 'clean_environment'
    STEP_POSTCHECKS = 'run_postchecks'
    STEP_END = 'patch_done'
    STEP_SHUTDOWN_VMS = 'shutdown_vms'
    STEP_STOP_CELL_SERVICES = 'stop_cell_services'
    STEP_START_VMS = 'start_vms'
    STEP_START_CELL_SERVICES = 'start_cell_services'

    PATCH_ONLY_CELL_STEP_LIST = [STEP_RUN_PATCH_CELL, STEP_CLEAN_UP]
    PATCH_ONLY_IBSWITCH_STEP_LIST = [STEP_RUN_PATCH_IBSWITCH]

    # patching input json keys
    KEY_NAME_Dom0_YumRepository = 'Dom0YumRepository'
    KEY_NAME_Domu_YumRepository = 'DomuYumRepository'
    KEY_NAME_PatchFile          = 'PatchFile'
    KEY_NAME_DBPatchFile        = 'DBPatchFile'
    KEY_NAME_CellPatchFile      = 'CellPatchFile'
    KEY_NAME_SwitchPatchFile    = 'SwitchPatchFile'

    # CNS constants
    CNS_DOM0_PATCHER = 'cns.dom0_patcher'
    CNS_DOMU_PATCHER = 'cns.domu_patcher'

    #KVM file substring
    KVM_FILE_IDENTIFIER_STRING = "ol7"

    # Env types constants, it's used for future 
    ENV_ECS = 'ecs'

    def __init__(self,
                 aCluCtrlObj,
                 aLocalLog,
                 aTargetType,
                 aTask,
                 aOperationStyle='rolling',
                 aPayloadType='release',
                 aTargetEnv='production',
                 aCellIBSwitchesPatchZipFile='',
                 aDom0DomuPatchZipFiles='',
                 aTargetVersion='',
                 aClusterID=None,
                 aBackupMode='yes',
                 aEnablePlugins='no',
                 aPluginTypes='none',
                 aFedramp='DISABLED',
                 aRetry='no',
                 aRequestId='none',
                 aRackName='none',
                 aAdditionalOptions = {}):

        self.__cluctrl = aCluCtrlObj
        self.__log_path = aLocalLog
        self.__target_type = aTargetType
        self.__task = aTask
        self.__op_style = aOperationStyle
        self.__payload = aPayloadType
        self.__target_env = aTargetEnv

        # This target version will be updated, later in case of dom0, domu and cell.
        # Note, we have not used aTargetVersion which is passed to this module.
        # Will see how it can be used, later.
        self.__target_version = None

        self.__backup_mode = aBackupMode 
        self.__enable_plugins = aEnablePlugins 
        self.__plugin_types = aPluginTypes 
        self.__fedramp = aFedramp
        self.__patch_req_retry = aRetry
        self.__master_request_id = aRequestId
        self.__rack_name = aRackName
        self.__additional_options = aAdditionalOptions 

        # Flags to indicate whether we should run exadata/exacloud plugins
        self.__run_plugins_enable = True
        self.__run_plugins_disable = False 

        # Flag to indicate whether we need to run plugins or not 
        self.__run_user_plugins = self.__run_plugins_disable 

        # Flag to indicate whether we need to run plugins on domu of it's dom0.
        # Ideally, we can run plugins on domu on ADW or ATP or FA since domu is
        # accessible.
        self.__run_user_plugins_on_dom0s_domu_node = self.__run_plugins_disable 
        self.__run_user_plugins_on_dom0_node = self.__run_plugins_disable 
        self.__run_user_plugins_on_domu_node = self.__run_plugins_disable 

        self.__exadata_env_type = ebCluPatchControl.ENV_ECS

        self.__cluster_id = aClusterID
        self.__fabric = None
        self.__fabric_id = None
        self.__process = None
        self.__process_cns_monitor = None

        self.__dom0_to_patch_cells_ibswitches = None
        self.__dom0_to_patch_dom0 = None
        self.__dom0_to_patch_initial_dom0 = None
        self.__dummy_xml_created_on_initial_dom0 = None

        self.__current_target_type = ""
        self.__ibswitch_upgrade_version = None
        self.__ibswitch_rollback_version = None
        self.__executed_targets = []
        self.__json_status = {}

        self.__patchmgr_log_path_on_launch_node = ""
        self.__plugins_log_path_on_launch_node = ""
        self.__callbacks = [] 
        self.__patchmgr_cmd = ""
        self._last_node_patched = "" 

        # old patchmgr xml location for checking the pathing status change
        self.__patchmgr_old_xml_loc = None
        # Infers to collect the CNS once 
        self.__instant_collect_of_cns = True 

        # Flag to indicate whether we should send CNS at the end of cluster
        self.__yes_collect_final_notification = True
        self.__no_collect_final_notification = False
        self.__choice_collect_final_notification = self.__yes_collect_final_notification
        
        # Bug27556005 - Get ssh setup class object and use the same for both 
        # ssh key generate and cleanup. It's used only for cell and ibswitch
        # patch operation. Dom0/Domu already having single object.
        self.__ssh_env_setup = None 

        #Absolute path of metadata path and json which contains patch progress states 
        self.__metadata_json_file    = ""
        self.__patch_states_base_dir = ""

        # Initialize kvm env type
        self.__kvm_env = None

        # Bug27263414: Read grid heartbeat timeout to check the cell 
        #              heartbeat from domu. 
        self.EXADATA_PATCH_GRID_HEARTBEAT_TIMEOUT_SEC = self.__cluctrl.mCheckConfigOption('exadata_patch_grid_heartbeat_timeout_sec')
        if self.EXADATA_PATCH_GRID_HEARTBEAT_TIMEOUT_SEC:
            ebLogDebug("Exadata patch grid heartbeat timeout is %s seconds." % \
                        self.EXADATA_PATCH_GRID_HEARTBEAT_TIMEOUT_SEC)
        else:
            ebLogError("Invalid exadata patch grid heartbeat timeout is configured.")

        # Read exacloud patch working space size 
        self.EXADATA_PATCH_WORKING_SPACE_MB = self.__cluctrl.mCheckConfigOption('exadata_patch_working_space_mb')
        if self.EXADATA_PATCH_WORKING_SPACE_MB:
            ebLogDebug("Exacloud patch working size is %s MB." % \
                        self.EXADATA_PATCH_WORKING_SPACE_MB)
        else:
            ebLogError("Invalid exadata patch working space is configured.") 

        # The expectation is to finish the patchmgr in 12 hours even in case of
        # full rack on all cells. For compute node, we should take even lesser time.
        self.EXADATA_PATCHMGR_CONSOLE_READ_TIMEOUT_SEC = int(self.__cluctrl.mCheckConfigOption('exadata_patchmgr_console_read_timeout_sec'))
        if self.EXADATA_PATCHMGR_CONSOLE_READ_TIMEOUT_SEC:
            ebLogInfo("Exadata patchmgr console read timeout is {} seconds.".format( \
                        self.EXADATA_PATCHMGR_CONSOLE_READ_TIMEOUT_SEC))
        else:
            ebLogError("Invalid exadata patchmgr console read timeout is configured.")

        if (self.PATCH_CELL in self.__target_type or 
            self.PATCH_IBSWITCH in self.__target_type):
            self.__cells_ibswitches_local_patch_zip = aCellIBSwitchesPatchZipFile
            self.__cells_ibswitches_patch_zip_name = None
            self.__cells_ibswitches_patch_base = None
            self.__cells_ibswitches_patch_zip = None
            self.__cells_ibswitches_patch_base_after_unzip = None
            self.__cells_ibswitches_patch_zip_size_mb = None
            self.__cells_ibswitches_patch_necessary_space_mb = None
            self.__dom0_to_patch_cells_ibswitches = None

        if self.PATCH_DOM0 in self.__target_type:
            self.__dom0_local_patch_zip = aDom0DomuPatchZipFiles[0]
            self.__dom0_local_patch_zip2 = aDom0DomuPatchZipFiles[1]
            self.__dom0_patch_zip_name = None
            self.__dom0_patch_zip2_name = None
            self.__dom0_patch_base = None
            self.__dom0_patch_zip = None
            self.__dom0_patch_base_after_unzip = None
            self.__dom0_patchmgr = None
            self.__dom0_patch_zip_size_mb = None
            self.__dom0_patch_zip2_size_mb = None
            self.__dom0_patch_necessary_space_mb = None
            self.__dom0_to_patch_dom0 = None
            self.__dom0_to_patch_initial_dom0 = None
            self.__dom0_patchmgr_intput_file = None
            self.__dom0s_to_patch = []
            self.__all_dom0s = []

        if self.PATCH_DOMU in self.__target_type:
            self.__domu_local_patch_zip = aDom0DomuPatchZipFiles[0] 
            self.__domu_local_patch_zip2 = aDom0DomuPatchZipFiles[1] 
            self.__domu_patch_zip_name = None
            self.__domu_patch_zip2_name = None
            self.__domu_patch_base = None
            self.__domu_patch_zip = None
            self.__domu_patch_base_after_unzip = None
            self.__domu_patchmgr = None
            self.__domu_patch_zip_size_mb = None
            self.__domu_patch_zip2_size_mb = None
            self.__domu_patch_necessary_space_mb = None
            self.__domu_to_patch_domus = None
            self.__domu_to_patch_initial_domu = None
            self.__domu_patchmgr_intput_file = None
            self.__domus_to_patch = []
            self.__all_domus = []
            self.__dummy_xml_created_on_initial_domu = None            
        self.__shutdown_services = \
            (self.__op_style == self.OP_STYLE_NON_ROLLING and
             self.__task in [self.TASK_PATCH, self.TASK_ROLLBACK])

        self.__step_list = self.mCreateStepList()
        self.__clupatchcheck = ebCluPatchHealthCheck(aCluCtrlObj)
        self.mBuildIBFabric()

    @staticmethod
    def mFormatOut(_o):
        # Example: output was represented as [u'23434\n'], need just the number stuff
        _o = _o.readlines()
        out = str("".join(_o))
        return out

    @staticmethod
    def mGetFirstDirInZip(aZipFile):

        _fortify_obj = ebFortifyIssues()
        if _fortify_obj.mPathManipulationError(aZipFile):
            raise Exception("mGetFirstDirInZip: The vulnerable word or character found in file path: %s." % aZipFile)

        _zip_file = zipfile.ZipFile(aZipFile, "r")
        for filename in _zip_file.namelist():
            if filename.endswith('/'):
                return filename

    @staticmethod
    def mReadCallback(aData):
        # Escapes special characters to return a well formed output
        _data = ebCluPatchControl.ANSI_ESCAPE.sub('', aData.decode('utf-8'))
        _data = ebCluPatchControl.WAIT_LINES_ESCAPE.sub('', _data)
        for _line in _data.split('\n'):
            if _line.strip() == '':
                continue
            ebLogInfo(_line, aNoNL=True)

    @staticmethod
    def mErrorCallback(aData):
        # Escapes escape special characters to return a well formed output
        _data = ebCluPatchControl.ANSI_ESCAPE.sub('', aData.decode('utf-8'))
        _data = ebCluPatchControl.WAIT_LINES_ESCAPE.sub('', _data)
        for _line in _data.split('\n'):
            if _line.strip() == '':
                continue
            ebLogError(_line, aNoNL=True)

    @staticmethod
    def mReadPatcherInfo(aCnsPatcherFile):
        # This would read and return launch node and it's log directory 
        try:
            _launch_node = None
            _patchmgr_log_dir = None

            _fortify_obj = ebFortifyIssues()
            if _fortify_obj.mPathManipulationError(aCnsPatcherFile):
                raise Exception("mReadPatcherInfo: The vulnerable word or character found in file path: %s." % aCnsPatcherFile)

            if os.path.isfile (aCnsPatcherFile):
                with open(aCnsPatcherFile, "r") as _f_cur_launch_node:
                    _launch_node, _patchmgr_log_dir = \
                    _f_cur_launch_node.read().split(':')
        except Exception as e:
            ebLogInfo('Failed to read patcher file %s: %s' %
                         (aCnsPatcherFile, str(e)))

        return _launch_node, _patchmgr_log_dir

    def mGetMasterReqId(self):
        """
        Method to return master request id. We are using this to tag in
        log_dir path for reading the patchmgr console in case of patch retry. 
        """
        return self.__master_request_id 

    def mPatchRequestRetried(self):
        """
        This method would return whether the patching request is re-attempted by
        ecra, perhaps, after ecra/exacloud is upgraded or rebooted.
        Return value:
          True  --> Same patch request is tried with master request id 
          False --> If patch request is fresh and new one
        """

        if self.__patch_req_retry == 'yes':
            return True
        else:
            return False 

    def mGetRackName(self):
        """
        Method to return rack or cluster name. 
        """
        return self.__rack_name

    def mSetKvmEnv(self):
        """
        Set kvm env type 
        """
        if self.__cluctrl.mIsKVM():
            ebLogInfo("The environment is KVM")
            self.__kvm_env = True
        else:
            ebLogDebug("OVM environment type")
            self.__kvm_env = False 

    def mIsKvmEnv(self):
        """
        Check for KVM or OVM.
        Return
          True  --> if kvm env, 
          False --> otherwise
        """
        return self.__kvm_env
    

    def __mSetPatchEnvironment(self):
        """
        Sets all the variables used to select the dom0 that will run the patchmgr.
        """
        # Update kvm env type
        self.mSetKvmEnv()

        for _target in self.__target_type:
            if _target in [self.PATCH_ALL, self.PATCH_CELL, self.PATCH_IBSWITCH] and \
               self.__cells_ibswitches_local_patch_zip:

                # Name of the patch zip file (without the path)
                self.__cells_ibswitches_patch_zip_name = self.__cells_ibswitches_local_patch_zip.split("/")[-1]
                # Base dir to copy the patch onto the remote dom0
                self.__cells_ibswitches_patch_base = self.PATCH_BASE + self.__cells_ibswitches_patch_zip_name + "/"
                # Full path to the zip patch on the remote dom0
                self.__cells_ibswitches_patch_zip = self.__cells_ibswitches_patch_base + \
                                                    self.__cells_ibswitches_patch_zip_name
                # Full path to the unziped patch folder on the remote dom0
                self.__cells_ibswitches_patch_base_after_unzip = (self.__cells_ibswitches_patch_base +
                                                                  self.mGetFirstDirInZip(\
                                                                  self.__cells_ibswitches_local_patch_zip))
                # Full path to the patchmgr script on the remote dom0
                self.__cells_ibswitches_patchmgr =  self.__cells_ibswitches_patch_base_after_unzip + "patchmgr"
                self.__cells_ibswitches_patch_zip_size_mb = int(os.path.getsize( \
                                                                self.__cells_ibswitches_local_patch_zip)) >> 20
                # NOTE size is *2 of the zip file because we need to copy the zip, and unzip +
                # EXADATA_PATCH_WORKING_SPACE_MB for any logs generated?
                self.__cells_ibswitches_patch_necessary_space_mb = (self.__cells_ibswitches_patch_zip_size_mb * 2 +
                                                                    int(self.EXADATA_PATCH_WORKING_SPACE_MB))

                self.__dom0_to_patch_cells_ibswitches = self._mSetDom0ToPatchCellsIBSwitches()

                self.__patchmgr_log_path_on_launch_node = (
                    self.__cells_ibswitches_patch_base_after_unzip 
                    + "patchmgr_log_" + self.mGetMasterReqId())

                self.__ibswitch_upgrade_version,self.__ibswitch_rollback_version = self._mGetIBSwitchTargetVersion()

            # self.__dom0_patch_zip2_name: is of the format shown below
            # [domains/exacloud/PatchPayloads/19.3.6.0.0.200317/Dom0YumRepository/exadata_ol7_19.3.6.0.0.200317_Linux-x86-64.zip,
            # domains/exacloud/PatchPayloads/19.3.6.0.0.200317/Dom0YumRepository/exadata_ovs_19.3.6.0.0.200317_Linux-x86-64.zip]

            if _target in [self.PATCH_ALL, self.PATCH_DOM0] and self.__dom0_local_patch_zip and \
               self.__dom0_local_patch_zip2:
                # Select the appropriate zip file based on KVM (e.g exadata_ol7_19.3.6.0.0.200317_Linux-x86-64.zip ) or
                # OVM (e.g exadata_ovs_19.3.6.0.0.200317_Linux-x86-64.zip)
                dom0zip2Files = self.__dom0_local_patch_zip2
                if dom0zip2Files.find(',') > -1:
                    patchFiles = dom0zip2Files.strip().split(',')
                    for _file in patchFiles:
                        if self.mIsKvmEnv() and _file.find(ebCluPatchControl.KVM_FILE_IDENTIFIER_STRING) > -1:
                            ebLogInfo("Dom0Repository: KVM file is: %s " % _file)
                            self.__dom0_local_patch_zip2 = _file
                            break
                        elif not self.mIsKvmEnv() and _file.find(ebCluPatchControl.KVM_FILE_IDENTIFIER_STRING) < 0:
                            ebLogInfo("Dom0Repository NON KVM file is: %s " % _file)
                            self.__dom0_local_patch_zip2 = _file
                            break

                ebLogDebug("dom0_local_patch_zip name %s" % self.__dom0_local_patch_zip)
                ebLogDebug("dom0_local_patch_zip2 name %s" % self.__dom0_local_patch_zip2)

                if not self.__dom0_local_patch_zip2:
                    ebLogError("Dom0 Patch Zip file not found")
                    raise Exception("Dom0 Patch Zip file not found")

                # Dom0 patching needs 2 zip files. first one has the patchmgr, second one is the actual patch
                self.__dom0_patch_zip_name = self.__dom0_local_patch_zip.split("/")[-1]
                self.__dom0_patch_zip2_name = self.__dom0_local_patch_zip2.split("/")[-1]
                self.__dom0_patch_base = self.PATCH_BASE+self.__dom0_patch_zip_name+"_"+self.__dom0_patch_zip2_name+"/"
                self.__dom0_patch_zip = self.__dom0_patch_base + self.__dom0_patch_zip_name
                self.__dom0_patch_base_after_unzip = (self.__dom0_patch_base +
                                                      self.mGetFirstDirInZip(self.__dom0_local_patch_zip))
                self.__dom0_patchmgr =  self.__dom0_patch_base_after_unzip + "patchmgr"
                self.__dom0_patch_zip_size_mb = int(os.path.getsize(self.__dom0_local_patch_zip)) >> 20
                self.__dom0_patch_zip2_size_mb = int(os.path.getsize(self.__dom0_local_patch_zip2.strip())) >> 20
                self.__dom0_patch_necessary_space_mb = (self.__dom0_patch_zip_size_mb + self.__dom0_patch_zip2_size_mb \
                                                        + int(self.EXADATA_PATCH_WORKING_SPACE_MB))
                self.__all_dom0s = self._mGetDom0List()
                _launchNodes = self._mSetLaunchNodeToPatchOtherNondes(self.PATCH_DOM0)

                try:
                    self.__dom0_to_patch_dom0 = _launchNodes[0]
                    self.__dom0_to_patch_initial_dom0 = _launchNodes[1]
                except IndexError:
                    pass

                self.__patchmgr_log_path_on_launch_node = (
                    self.__dom0_patch_base_after_unzip 
                    + "patchmgr_log_" + self.mGetMasterReqId())

            if (_target in [self.PATCH_ALL, self.PATCH_DOMU] and 
                self.__domu_local_patch_zip and self.__domu_local_patch_zip2):
                # alter the PATCH_BASE for DOMU
                if (_target == self.PATCH_DOMU):
                       self.PATCH_BASE = mSetFromEnv(default="/u02/", aEnvVariable="EXACLOUD_PATCH_PAYLOAD_BASE", aErrorOn=["/tmp", "/tmp/"])

                # Domu patching needs 2 zip files. first one has the patchmgr, 
                # second one is the actual patch
                self.__domu_patch_zip_name = \
                    self.__domu_local_patch_zip.split("/")[-1]
                self.__domu_patch_zip2_name = \
                    self.__domu_local_patch_zip2.split("/")[-1]
                self.__domu_patch_base = self.PATCH_BASE+\
                                         self.__domu_patch_zip_name+"_"+ \
                                         self.__domu_patch_zip2_name+"/"
                self.__domu_patch_zip = self.__domu_patch_base + \
                                        self.__domu_patch_zip_name
                self.__domu_patch_base_after_unzip = (self.__domu_patch_base + 
                    self.mGetFirstDirInZip(self.__domu_local_patch_zip))
                self.__domu_patchmgr =  self.__domu_patch_base_after_unzip + \
                                        "patchmgr"
                self.__domu_patch_zip_size_mb = \
                    int(os.path.getsize(self.__domu_local_patch_zip)) >> 20
                self.__domu_patch_zip2_size_mb = \
                    int(os.path.getsize(self.__domu_local_patch_zip2)) >> 20
                self.__domu_patch_necessary_space_mb = \
                    (self.__domu_patch_zip_size_mb + \
                     self.__domu_patch_zip2_size_mb + \
                     int(self.EXADATA_PATCH_WORKING_SPACE_MB))
                self.__all_domus = self._mGetDomUList()
                _launchNodes = self._mSetLaunchNodeToPatchOtherNondes(self.PATCH_DOMU)

                try:
                    self.__domu_to_patch_domus = _launchNodes[0]
                    self.__domu_to_patch_initial_domu = _launchNodes[1]
                except IndexError:
                    pass

                self.__patchmgr_log_path_on_launch_node = (
                    self.__domu_patch_base_after_unzip 
                    + "patchmgr_log_" +self.mGetMasterReqId())

    def mAddError(self, aHost, aError, aSuggestion=None, aComment=None):
        """
        Generate the patch error report.
        """

        if aHost not in self.__json_status:
            self.__json_status[aHost] =  {}

        _name, _json = ebPatchBuildError(aError, aSuggestion, aComment)
        if _name not in self.__json_status[aHost]:
            self.__json_status[aHost][_name] = _json

            self.__json_status["data"] = self.mAddPatchreport()

        # Save json error in db
        if self.__fabric:
            _reqobj = self.__cluctrl.mGetRequestObj()
            if _reqobj:
                ebLogWarn('Updating JSON patch report: ' + aHost)
                _db = ebGetDefaultDB()
                _db.mUpdateJsonPatchReport(_reqobj.mGetUUID(), self.__json_status)

    def mAddPatchreport(self):
        """
        Return patch report with more detail. We try to maintain the same
        format of patching CNS payload so that it can be read uniformly
        in ecra side.
        """

        # fill up the payload json for notificaiton
        _patch_report_json = {}

        _myuuid = uuid4().hex
        _patch_report_json['httpRequestId'] = _myuuid

        _patch_report_json['recipients'] =  []
        _channel_info = {}
        _channel_info['channelType'] = "topics"
        _patch_report_json['recipients'].append(_channel_info)

        _patch_report_json['notificationType'] = {}
        _patch_report_json['notificationType']['componentId']  = "Patch_ExadataInfra_SM"
        _patch_report_json['notificationType']['id'] = "Patch_ExadataInfra_SMnotification_v1"
    
        _patch_report_json['service'] = "ExadataPatch"
        _patch_report_json['component'] = "Patch Exadata Infrastructure"
        _patch_report_json['subject'] = "Patch Exadata Infrastructure Service Update"
        _patch_report_json['event_post_time'] = time.strftime("%Y-%m-%d:%H.%M.%S %Z")
        _patch_report_json['log_dir'] = self.__patchmgr_log_path_on_launch_node

        # Fetch cluster name
        _patch_report_json['cluster_name'] = self.mGetRackName()

        # This is required for mandatory CNS check in CNSOperation.java
        _patch_report_json['exadata_rack'] = self.mGetRackName()
 
        # target type, such as cell, dom0, etc
        _patch_report_json['target_type']  = self.__target_type 

        # task type such as, prereq, patch, rollback, etc 
        _patch_report_json['operation_type'] = self.__task

        # operation style, rolling and / or non-rolling.
        _patch_report_json['operation_style'] = self.__op_style

        # These are required in ecra Patcher.java for updating the image version
        # and cabinet status
        _patch_report_json['target_version'] = self.__target_version
        if self.mIsClusterLessUpgrade():
            _patch_report_json['cluster_less'] = 'yes'
        else:
            _patch_report_json['cluster_less'] = 'no'

        _patch_report_json['topic'] = ''

        return _patch_report_json

    def mFedrampRestoreConfig(self, aTargetType):
        """
        Restores all the FEDRAMP configuration files
        and settings as patch upgrade removes all the
        fedramp settings.
        """

        #Set the Fedramp settings post upgrade.
        self.__cluctrl.mFedrampConfig(aTargetType)

    def mFedrampDom0RestoreConfig(self, aNodesList, _Pre_Aud, _Post_Aud):
        """
        Backup the audit config file /etc/audit/audit.rules to
        preserve audit configuration for pre and post configuration.
        """

        try:
            for _node in aNodesList:
                _aDom0 = exaBoxNode(get_gcontext())
                _aDom0.mConnect(aHost=_node)
                ebLogInfo("Audit rules file copy. Source file : %s - Destination file : %s - Node : %s." % (_Pre_Aud, _Post_Aud, _node))
                _aDom0.mExecuteCmdLog("\cp -rp %s %s" % (_Pre_Aud, _Post_Aud))
        except Exception as e:
            ebLogError("Error while taking backup of audit config file /etc/audit/audit.rules. \n\n" +str(e))
        finally:
            _aDom0.mDisconnect()

    def mUpdateCnsJsonPayload(self, cnsjson):
        """
        Post CNS payload for patch state change. 
        """

        # Save cns json in db
        if self.__fabric:
            _reqobj = self.__cluctrl.mGetRequestObj()
            if _reqobj:
                ebLogInfo('Save the patch notification JSON to database')
                _db = ebGetDefaultDB()
                _db.mUpdateJsonPatchReport(_reqobj.mGetUUID(), cnsjson)

    def mRunPatchMgr(self, aTaskType=''):
        """
        Patchmgr initial call. It handles the ibfabric/cluster lock.
        This function should be call in order to run any task from patchmgr.
        """

        _set_lock = False
        _rc = 0

        if self.mPatchRequestRetried():
            ebLogInfo("\n############################################")
            ebLogInfo("### PATCH OPERATION RE ATTEMPTED BY ECRA ###")
            ebLogInfo("############################################\n")

        # Try to acquire the ibfabric and cluster lock
        if self.__fabric:
            # The master request always acquires the lock before launching the 
            # current request. However, we want to be sure the lock is still 
            # there. If acquiring the lock returns False, it means the lock is 
            # actually there.
            ebLogInfo("Checking IBFabric lock before running patchmgr")
            if self.PATCH_IBSWITCH in self.__target_type:
                _lock = self.__fabric.mLock(self.__cluster_id, False)
            else:
                _lock = self.__fabric.mLock(self.__cluster_id, True)

            if _lock is False:
                ebLogInfo("Lock was correctly acquired by master request")
                _set_lock = True

        try:
            # Set variables and copy patch to dom0
            self.__mSetPatchEnvironment()

            # Run patch task/tasks
            _rc = self.mRunPatchingTask(aTaskType)

        except Exception as e:
            ebLogError("mRunPatchMgr error: " + str(e))
            ebLogError(traceback.format_exc())
            return ebError(0x0610)

        finally:
            # Release ibfabric and cluster lock
            if _set_lock and self.__fabric:
                ebLogInfo("Releasing IBFabric lock")
                # If an ibswitch task was executed, we must be sure do_switch is
                # updated to 'no'
                if self.PATCH_IBSWITCH in self.__target_type:
                    self.__fabric.mSetDoSwitch('no')
                    self.__fabric.mUpdateDoSwitchDB()
                self.__fabric.mRelease(self.__cluster_id)

                # Extra process should not be alive. This is an 'extra' check to
                # ensure the process is not longer alive
                if self.__process and self.__process.is_alive():
                    ebLogError('Terminate extra process: ' + str(self.__process.pid) )
                    self.__process.terminate()

                if self.__process_cns_monitor and self.__process_cns_monitor.is_alive():
                    ebLogError('Terminate monitor process for patch notification generation ' + str(self.__process_cns_monitor.pid))
                    self.__process_cns_monitor.terminate()

            # Update status
            if self.__executed_targets:
                _comment = "_".join(self.__executed_targets)
            else:
                _comment = 'None'
            self.mUpdatePatchStatus(True, self.STEP_END, _comment)

            ebLogInfo(self.__json_status)

            _rc = self.mVerifySystemImage(_rc)

        ebLogInfo("mRunPatch: Return code: %s" % _rc)

        return _rc

    def mVerifySystemImage(self, aReturnCode):
        """
        Copy System boot image if required to dom0. 
        Return 0 if success, otherwise return error code. 
        """

        _sys_first_boot_image = None
        _rc = aReturnCode 
        # In case of Postcheck, ksplice and oneoff operations, we need not copy images.
        if self.__task in [ self.TASK_KSPLICE, self.TASK_ONEOFF, self.TASK_POSTCHECK ]:
            ebLogInfo("Ignoring file copy of exadata image iso for task : %s on any Dom0." % (self.__task))
            return _rc
        
        if self.PATCH_DOM0 in self.__target_type and self.__task in [ self.TASK_PREREQ_CHECK, self.TASK_PATCH ] and aReturnCode == 0:
            _repo_image_loc = self.mGetImageLocation("images/")
            if not _repo_image_loc:
                ebLogError("*** OCI-EXACC patch stage location not specified in exabox.conf")
                self.mAddError(self.mGetRackName(), 1021, 2023)
                return ebError(0x0621)
            
            # In case of kvm env, copy kvm image file.
            if self.mIsKvmEnv():
                _sys_first_boot_image = "System.first.boot.%s.kvm.img.bz2" % (self.__target_version)
            else:
                _sys_first_boot_image = "System.first.boot.%s.img.bz2" % (self.__target_version)

            if not _sys_first_boot_image:
                raise ExacloudRuntimeError(0x0730, 0xA, "No suitable System Image found. Aborting", aStackTrace=False)

            ebLogDebug("System First Boot image is: %s " % _sys_first_boot_image)

            _rc = self.mValidateImageCheckSum(_sys_first_boot_image, _repo_image_loc, "/EXAVMIMAGES/", self._mGetDom0List(), self.__dom0_patch_necessary_space_mb)
         
        return _rc

    def mGetImageLocation(self,aPatchLoc=None):
        """
        In case of OCI EXACC environemnts, PatchPayload details are fetched
        from ociexacc_exadata_patch_download_loc parameter as per details from
        the exabox.conf file.
        """

        _imgrev = aPatchLoc
        self.OCIEXACC = self.__cluctrl.mCheckConfigOption('ociexacc')
        if self.OCIEXACC == "True":
            self.OCIEXACC_LOC = self.__cluctrl.mCheckConfigOption('ociexacc_exadata_patch_download_loc').strip()
            if(not self.OCIEXACC_LOC or self.OCIEXACC_LOC == '' or self.OCIEXACC_LOC == None):
                _imgrev = False
            else:
                _imgrev = self.OCIEXACC_LOC + aPatchLoc
        else:
            ebLogDebug('*** ociexacc parameter is set to False. Retaining the patch path to default exacloud location.')
        return _imgrev

    def mValidateImageCheckSum(self, aPatchFile, aPatchRepo, aRemotePatchBase, aNodeList, aRemoteNecessarySpaceMb):
        """
         This method checks for existence of patch file, if the
         file is available, it validates the sha256sum of the file
         and updates the checksum_exadata_patchfiles.json file if the
         computed sha256sum and the value in the input json file are
         mismatch or if the entry is missing or a new entry for the file
         is made. Below is a snippet of how checksum_exadata_patchfiles.json
         file looks like.
    
            {
                "list_of_files": [
                    {
                        "patch_file": "System.first.boot.19.3.8.1.0.191211.1.img.bz2",
                        "file_size": "4G",
                        "sha256sum": "FSAHDGKJAFKHGHWLKFLKZVKWFKEGLE"
                    },
                    {
                        "patch_file": "System.first.boot.19.3.2.1.0.191211.1.img.bz2",
                        "file_size": "4G",
                        "sha256sum": "UEDUHFELKWHJBVKDNBJVLKEGEWGVJLR"
    
                    },
                ]
            }

         Retrun:-
           0        --> if checksum evaluation and files copy are successful. 
           Non-zero --> If there any failures 
            
        """
    
        def _mExecute_FileCopy(_remote_node, _rc_status):
            """ 
             Sub function to copy patches parallely to multiple target nodes. 
            """ 

            _rc_status[_remote_node] = 0
            
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost = _remote_node)
        
            # Create Patch and Images directory if missing.
            _node.mExecuteCmdLog("mkdir -p %s" % aRemotePatchBase)
            _node.mExecuteCmdLog("mkdir -p %s" % _remote_config_loc)
        
            # Calculating the free disk space on remote node.
            _patch_base_df_cmd = (
                    "df -mP %s | tail -n1 | awk '{print $(NF - 2); }'" % (
                        aRemotePatchBase))
        
            _i, _o, _e  = _node.mExecuteCmd(_patch_base_df_cmd)
            _patch_base_space_available = self.mFormatOut(_o)
            try:
                _patch_base_space_available = int(_patch_base_space_available)
            except ValueError as e:
                ebLogWarn("Could not parse %s for free space on %s. Expected a number, got %s. Trying a different node"
                          % (self.PATCH_BASE, str(_remote_node), str(e)))
                _node.mDisconnect()
                return False
        
            # If the space to copy patch is not available on the target node
            # this node will be skipped.
            if _patch_base_space_available < aRemoteNecessarySpaceMb:
                ebLogWarn("%s does not have enough space in %s to be used as the patching base. Needed %smb, got %smb, this node will be skipped."
                          % (_remote_node, self.PATCH_BASE, str(aRemoteNecessarySpaceMb), str(_patch_base_space_available)))
                _node.mDisconnect()
                self.mAddError(_remote_node, 1000, 2001)
                _rc_status[_remote_node] = 0x0730
                return False
        
            if not _node.mFileExists(_remote_patch_file) or not _node.mFileExists(_checksum_remote_json):
                ebLogInfo('*** Copying Patch and checksum files to Node : %s in progress...' % (_remote_node))
                _node.mCopyFile(_local_patch_file, _remote_patch_file)
                _node.mCopyFile(_checksum_local_json, _checksum_remote_json)
                _i, _o, _e =_node.mExecuteCmd(_patch_unzip_cmd)
                _exit_code = _node.mGetCmdExitStatus()
                if int(_exit_code) != 0:
                    ebLogError("Error while unziping the patch on %s, skipping this Node. err: %s" % (str(_remote_node), _e))
                    _node.mExecuteCmdLog("rm -f %s" % _remote_patch_file)
                    _patch_copy_end_time = datetime.datetime.now()
                    self.mGetPatchRunningTime(_task_type, _patch_copy_start_time, _patch_copy_end_time)
                    _rc_status[_remote_node] = 0x0730
                    self.mAddError(_remote_node, 1000, 2002)
                    return False
                ebLogInfo('*** Patch file transferred to Node : %s' % (_remote_node))
                _node.mDisconnect()
            elif _node.mFileExists(_checksum_remote_json):
                _node.mCopy2Local(_checksum_remote_json, "/tmp/checksum_patchfile_node.json")
                with open("/tmp/checksum_patchfile_node.json") as json_node:
                    checksum_node = json.load(json_node)
                    for _list in list(checksum_node['list_of_files']):
                        if _list["patch_file"] == aPatchFile:
                            _node_checksum = _list["sha256sum"]
                            if _checksum != _node_checksum or _node_checksum is None:
                                ebLogInfo('*** Copying Patch and checksum files to Node : %s checksum of patch files are different.' % (_remote_node))
                                # Delete the patch zip file if found on the node.
                                if _node.mFileExists(_remote_patch_file):
                                    ebLogInfo("Patch zip file found in %s at %s. It will be removed." % (_remote_node, _remote_patch_file))
                                    _node.mExecuteCmdLog("rm -f %s" % _remote_patch_file)

                                _node.mCopyFile(_local_patch_file, _remote_patch_file)
                                _node.mCopyFile(_checksum_local_json, _checksum_remote_json)
                                _i, _o, _e = _node.mExecuteCmd(_patch_unzip_cmd)
                                _exit_code = _node.mGetCmdExitStatus()
                                if int(_exit_code) != 0:
                                    ebLogError("Error while unziping the patch on %s, skipping this Node. err: %s" % (str(_remote_node), _e))
                                    _node.mExecuteCmdLog("rm -f %s" % _remote_patch_file)
                                    _patch_copy_end_time = datetime.datetime.now()
                                    self.mGetPatchRunningTime(_task_type, _patch_copy_start_time, _patch_copy_end_time)
                                    self.mAddError(_remote_node, 1000, 2002)
                                    _rc_status[_remote_node] = 0x0730
                                    return False
                                ebLogInfo('*** Patch file transferred to Node : %s' % (_remote_node))
                                _node.mDisconnect()
                            else:
                                ebLogInfo('Patch file with the same checksum and size as source is already staged on %s' % _remote_node)
            else:
                # Delete the patch zip file if found on the node.
                if _node.mFileExists(_remote_patch_file):
                    ebLogInfo("Patch zip file found in %s at %s. It will be removed." % (_remote_node, _remote_patch_file))
                    _node.mExecuteCmdLog("rm -f %s" % _remote_patch_file)

                # When either of checksum or Patch file is missing at target.
                ebLogInfo('*** Copying Patch and checksum files to Node : %s in progress...' % (_remote_node))
                _node.mCopyFile(_local_patch_file, _remote_patch_file)
                _node.mCopyFile(_checksum_local_json, _checksum_remote_json)
                _i, _o, _e = _node.mExecuteCmd(_patch_unzip_cmd)
                _exit_code = _node.mGetCmdExitStatus()
                if int(_exit_code) != 0:
                    ebLogError("Error while unziping the patch on %s, skipping this Node. err: %s" % (str(_remote_node), _e))
                    _node.mExecuteCmdLog("rm -f %s" % _remote_patch_file)
                    _patch_copy_end_time = datetime.datetime.now()
                    self.mGetPatchRunningTime(_task_type, _patch_copy_start_time, _patch_copy_end_time)
                    self.mAddError(_remote_node, 1000, 2002)
                    return False
                ebLogInfo('*** Patch file transferred to Node : %s' % (_remote_node))
            _node.mDisconnect()
 
        # End of _mExecute_FileCopy sub function.
 
        _patch_copy_start_time = datetime.datetime.now()
        _config_loc = "config/"
        _remote_config_loc = "/opt/exacloud/clusters/config/"

        _checksum_local_json = os.path.join(_config_loc, "checksum_exadata_patchfiles.json")
        _checksum_remote_json = os.path.join(_remote_config_loc, "checksum_exadata_patchfiles.json")
        _local_patch_file = os.path.join(aPatchRepo, aPatchFile)
        _remote_patch_file = os.path.join(aRemotePatchBase, aPatchFile)
        _task_type = "Patch_copy"
       
        # If patch file does not exist at source, Patch copy exits with error.
        ebLogInfo("\n*** Generating checksum for the patch file : %s ***" % _local_patch_file)
        _cmd = '/bin/sha256sum %s ' % (_local_patch_file)
        _in, _out, _err = self.__cluctrl.mExecuteCmd(_cmd)

        _cmd = '/bin/cut -d" " -f1'
        _in, _out, _err = self.__cluctrl.mExecuteCmd(_cmd, aStdIn=_out)
        _output = _out.readlines()
        _checksum = _output[0].strip()

        if not len(_checksum):
            ebLogError('*** Local Patch file : %s not found, unable to transfer file. Aborting.' % (_local_patch_file))
            return ebError(0x0620)
        else:
            _cmd = "/bin/du -sh %s " % (_local_patch_file)
            _in, _out, _err = self.__cluctrl.mExecuteCmd(_cmd)

            _cmd_size = "/bin/awk '{print $1}'"
            _in, _out, _err = self.__cluctrl.mExecuteCmd(_cmd_size, aStdIn=_out)
            _output = _out.readlines()
            _file_size = _output[0].strip()

        # if the checksum file is empty or missing. An empty list as below is created.
        if not os.path.exists(_checksum_local_json) or os.stat(_checksum_local_json).st_size == 0:
            checksum_read = {}
            checksum_read['list_of_files'] = []
            with open(_checksum_local_json, 'w') as json_file:
                json.dump(checksum_read, json_file, indent=4)

        # Patch unzip command is prepared based on patch file extension.
        if _remote_patch_file.endswith('.zip'):
            _patch_unzip_cmd = "cd %s && unzip -o %s" % (aRemotePatchBase, _remote_patch_file)
        elif _remote_patch_file.endswith('.bz2'):
            _patch_unzip_cmd = "bunzip2 -f -k -v  %s" % (_remote_patch_file)
    

        # Update local json file checksum.
        # Mismatch of checksum value of patch file in checksum file, hence both patch and checksum files are copied.
        with open(_checksum_local_json) as json_read:
            checksum_read = json.load(json_read)
        if aPatchFile in str(checksum_read['list_of_files']):
            checksum_read = {}
            checksum_read['list_of_files'] = []
            with open(_checksum_local_json) as json_read:
                checksum_read = json.load(json_read)
            for _list in list(checksum_read['list_of_files']):
                if _list["patch_file"] == aPatchFile and _list["sha256sum"] != _checksum:
                    _list["sha256sum"] = _checksum
                    _list["file_size"] = _file_size
                    with open(_checksum_local_json, 'w') as json_file:
                        json.dump(checksum_read, json_file, indent=4)
                    ebLogInfo("Patch file details were added to %s." % _checksum_local_json)
        else:
            # File is already present but the patch details are missing in source checksum file.
            checksum_read['list_of_files'].append({
                "patch_file" : aPatchFile,
                "file_size" : _file_size,
                "sha256sum" : _checksum
            })
            with open(_checksum_local_json, 'w') as outfile:
                json.dump(checksum_read, outfile, indent=4)
            ebLogInfo("Checksum file missing or is empty at source. Copying both {0} and {1}.".format(_checksum_local_json,aPatchFile))

        """
         Parallelize execution on all target nodes. In case 
         of Dom0/DomU patching, patches are copied to multiple 
         nodes. In case of Cell and IBSwitches patching, patches 
         are copied to one launch node. For more details regarding
         parallel file copy, please refer mParallelFileLoad and 
         mCheckSystemImage methods in clucoontrol file. 
        """
        _plist = ProcessManager()
        _rc_status = _plist.mGetManager().dict()
            
        for _remote_node in aNodeList:
            if self.mIsClusterLessUpgrade() and _remote_node not in self.__cluctrl.mGetHostList():
                # Only in clusterless CELL, the launch node will not be part of HostList
                self.__cluctrl.mAppendToHostList(_remote_node)
                self.__cluctrl.mImportKeys(None)
            _p = ProcessStructure(_mExecute_FileCopy, [_remote_node, _rc_status], _remote_node)
            _p.mSetMaxExecutionTime(30*60) # 30 minutes
            _p.mSetJoinTimeout(5)
            _p.mSetLogTimeoutFx(ebLogWarn)
            _plist.mStartAppend(_p)
            
        _plist.mJoinProcess()
            
        # validate the return codes
        _rc_all = 0
        for _remote_node in aNodeList:
            if _rc_status[_remote_node]:
                _rc_all = ebError(_rc_status[_remote_node])               
            _patch_copy_end_time = datetime.datetime.now()
            self.mGetPatchRunningTime(_task_type, _patch_copy_start_time, _patch_copy_end_time)
    
        if _rc_all:
            return ebError(0x0620)
        return 0 

    def mGetPatchRunningTime(self, aTaskType, aPatchStartTime=None, aPatchEndTime=None):
        """
         This method computes the time taken for a patch operation to 
         complete.
        """
        
        if aPatchStartTime is None or aPatchEndTime is None:
            ebLogWarn("Task Type : %s execution time could not be computed as the Start or end time is None." % aTaskType)
        else:
            _execution_time = aPatchEndTime - aPatchStartTime
            ebLogInfo("Task Type : %s execution time : %s" % (aTaskType, str(_execution_time)))

    def mCustomCheck(self, aTargetType, aNodes=None, aTaskType=None):
        """ 
         This method performs a post checks independently on
         all of the Exadata targets like Dom0, DomU,IbSwitches
         and cells.

         Return value :
          0 -> if post check is success
          1 -> if post check fails 
          Otherwise, pre-defined non zero error code
        """ 
    
        _post_patch_failed_nodes = []
        _node_prepatch_version = {}
        _err_msg_template = "%s %s failed. Errors printed to screen and logs"
        ret = 0

        '''
         Dom0 and DomU Independent Postchecks.
         aPrePatchVersion and aPostPatchTargetVersion are the image versions 
         before and after patches respectively. They do not have any 
         significance in case of running an independent post check, but they
         are only passed as they are mandatory arguments.
        '''

        if (aTargetType == self.PATCH_DOM0):
            _domU_listed_by_xm_list = []
            for _dom0_to_patch in aNodes:
                _node_prepatch_version[_dom0_to_patch] = self.__clupatchcheck.mCheckTargetVersion(_dom0_to_patch, self.PATCH_DOM0)
                _domU_listed_by_xm_list = self.__clupatchcheck.mCheckVMsUp(_dom0_to_patch)
                ebLogInfo("Dom0 : %s contains DomU : %s" %( _dom0_to_patch , _domU_listed_by_xm_list ))
                # aRollback is set to False as this is not a rollback operation.
                # But in case of postcheck we dont know what task was performed.
                # Hence version check will be skipped.

                aCellNewMark = "Exadata_Cloud_Service_CellHeartbeatCheck_" + _dom0_to_patch
                if not self._mPostDom0PatchCheck(aDom0 = _dom0_to_patch,
                        aCellAlertLogMark = aCellNewMark,
                        aDomUList = _domU_listed_by_xm_list,
                        aPrePatchVersion = _node_prepatch_version[_dom0_to_patch],
                        aPostPatchTargetVersion = self.__target_version,
                        aRollback = False,
                        aTaskType = self.TASK_POSTCHECK):
                    _post_patch_failed_nodes.append(_dom0_to_patch)
                    ret = self.DOM0_POSTCHECKS_FAILED
                     
                if (ret == self.DOM0_POSTCHECKS_FAILED):
                    ebLogError(_err_msg_template % ( aTargetType.upper(), "upgrade postchecks" ))
                    ret = ebError(0x0611)

        elif (aTargetType == self.PATCH_DOMU):
            for _domu_to_patch in aNodes:
                _node_prepatch_version[_domu_to_patch] = self.__clupatchcheck.mCheckTargetVersion(_domu_to_patch, self.PATCH_DOMU)
                if not self._mPostDomUPatchCheck(aDomU=_domu_to_patch,
                        aPrePatchVersion=_node_prepatch_version[_domu_to_patch],
                        aPostPatchTargetVersion=self.__target_version,
                        aRollback = False,
                        aTaskType = self.TASK_POSTCHECK):
                    _post_patch_failed_nodes.append(_domu_to_patch)
                    ret = self.DOMU_POSTCHECKS_FAILED
            
            if (ret == self.DOMU_POSTCHECKS_FAILED):
                ebLogError(_err_msg_template % ( aTargetType.upper(), "upgrade postchecks" ))
                ret = ebError(0x0611)
                
        elif aTargetType in [self.PATCH_ALL, self.PATCH_IBSWITCH]:
            # Enh 30208083 - Disallow patching if required/critical services 
            # are not running on the upgraded node(s).
            if aNodes:
                _final_IB_list = aNodes
            else: 
                # Get list of all the ibswitches in the cluster           
                _final_IB_list = self._mGetIBSwitchList()

            for _ibswitch in _final_IB_list:
                if not self.mPrePostIBSwitchCheck(_ibswitch, aTaskType):
                    ret = ebError(0x0611)
                    
        elif aTargetType in [self.PATCH_ALL, self.PATCH_CELL]:
            # Enh 30208083 - Disallow patching if required/critical services 
            # are not running on the upgraded node(s).
            if aNodes:
                _final_Cell_list = aNodes
            else:
                # Get list of all the cells in the cluster
                _final_Cell_list = self._mGetCellList()

            for _cell in _final_Cell_list:
                if not self.mPrePostCellCheck(_cell, aTaskType):
                    ret = ebError(0x0611)

        return ret

    def mExecuteOneOffPatch(self, aTargetType, aNodeList ,aPatchFile, aPluginRemoteDir, aLogDir):
        """
         This method executes the one off scripts and options specified 
         by user. Currently a one off script is checked in and 
         will always return success. User can customise this file 
         as per their requirement.
                
          -> return True if successful.
          -> return False is failure.
        """        
        
        ret = True
        _connected_as_non_root_user = False
        _sudo_str = ''
        _cmd_script_existence_chk = "ls %s/oneoff_patch.sh" % (aPluginRemoteDir)

        for aNode in aNodeList:
            _node = exaBoxNode(get_gcontext())
            # Try to connect as opc user to domu. If not exist, then try with root user
            if aTargetType == self.PATCH_DOMU and self.mIsOpcUserExist(aNode):
                _node.mSetUser('opc')
                _connected_as_non_root_user = True
                ebLogInfo("One-off Patch run: Connecting as opc user to '%s' to run plugins." % (aTargetType))
            else:
                ebLogInfo("One-off Patch run: Connecting as root user to '%s' to run plugins." % (aTargetType))

            if _connected_as_non_root_user:
                _sudo_str = 'sudo '

            _cmd_oneoff_run = "{2}chmod +x {0}/oneoff_patch.sh; {2}{0}/oneoff_patch.sh > {1} ".format(aPluginRemoteDir, aLogDir, _sudo_str)
            ebLogInfo("One off command is : %s" % _cmd_oneoff_run)

            _node.mConnect(aHost=aNode)
            _i, _o, _e = _node.mExecuteCmd(_cmd_script_existence_chk)
            _rc = _node.mGetCmdExitStatus()
            if int(_rc) != 0:
                _node.mDisconnect()
                ebLogError("Unable to find one off patch file : %s" % (aPatchFile))
                self.mAddError(aNode, 1019)
                return False
            
            _i, _o, _e = _node.mExecuteCmd(_cmd_oneoff_run)
            _out = _o.readlines()
            for _output in _out:
                ebLogInfo("%s" % _output.strip())
            _rc = _node.mGetCmdExitStatus()
            if int(_rc) == 0:
                ebLogInfo("\nOne-off Patch apply completed successfully on %s.\n" % aNode)
            else:
                ebLogError('Running one-off patch failed on node = %s' % aNode)
                self.mAddError(aNode, 1019)
                ret = False
            _node.mDisconnect()
          
        return ret 
    
    def mExecuteKsplice(self, aTargetType, aNodeList ,aPatchFile, aksplice_action, aPluginRemoteDir, aLogDir):
        """
         This method checks for the kernel version on the node based on the 
         target type passed as an argument and validates if relevant uptrack 
         RPMs are present in the patch stage location previously provided.
         This method does not assume if all the nodes are at the same version,
         Hence it captures kernel version from all nodes as per the current type 
         and checks for relevant RPMs in the stage location.
         
          -> return True if successful.
          -> return False is failure.
        """
        
        ret = True
        
        if aksplice_action == "install":
            _ksplice_action = "-install"
        elif aksplice_action == "remove":
            _ksplice_action = "-remove"
        elif aksplice_action == "list":
            _ksplice_action = "-list"
        
        _cmd_script_existence_chk = "ls %s" %( aPatchFile )
        _cmd_check_file = "ls %s/*`uname -r`*" % ( aPluginRemoteDir )
        _cmd_ksplice_run = "nohup %s %s > %s &" % ( aPatchFile, _ksplice_action, aLogDir )
        ebLogInfo("Ksplice command is : %s " % _cmd_ksplice_run)

        ret = True
        for _node_name in aNodeList:
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=_node_name)
            _i, _o, _e = _node.mExecuteCmd(_cmd_script_existence_chk)
            _rc = _node.mGetCmdExitStatus()
            if int(_rc) != 0:
                _node.mDisconnect()
                ebLogError("Unable to find Ksplice patch file : %s" % (aPatchFile))
                self.mAddError(_node_name, 1019)
                ret = False
                return ret

            # -list option does not require RPMs to be present.
            if _ksplice_action != "-list":
                _i, _o, _e = _node.mExecuteCmd(_cmd_check_file)
                _rc = _node.mGetCmdExitStatus()
                if int(_rc) != 0:
                    _node.mDisconnect()
                    ebLogError("Unable to find uptrack RPMs at the stage location : %s" % (aPluginRemoteDir))
                    self.mAddError(_node_name, 1019)
                    ret = False
                    return ret
            
            _node.mExecuteCmd(_cmd_ksplice_run)
            _node.mDisconnect()

            # Read plugins console log output.
            if self.mReadPluginScriptConsoleOut(_node_name ,aLogDir, aTargetType):
                ebLogInfo("The script '%s' executed successfully on %s" % (_cmd_ksplice_run,_node_name))
            else:
                ebLogError("The execution of script '%s' failed on %s" % (_cmd_ksplice_run,_node_name))
                self.mAddError(_node_name, 1019)
                ret = False
                return ret

        return ret 
            
    def mApplyKspliceOneOffPatch(self, aTargetType, aTaskType):
        """
         This method provides options to apply ksplice updates and one off 
         patches on the targets specified. While oneoff patch option is 
         applicable to all targets, ksplice is applicable only to Dom0 and cells.
         User can either specify the location of the RPM,patches and scripts staged or 
         the infra patching code will automatically search for the input files in the 
         default ksplice_plugins or oneoff_patch location under exacloud/ExadataPrePostPlugins.
         
         -> return Zero if successful.
         -> return None-Zero if failure.
        """
        
        ret = 0

        '''
         Fetch the oneoff patch/Ksplice files stage location if provided 
         else use the default plugin location file as below.
        '''
        if aTaskType in [ self.TASK_KSPLICE ]:
            ebLogInfo("Executing ksplice plugin operation...\n")
            _plugin_remote_dir = "/opt/exacloud/customs/plugins/ksplice_plugins/"
            _script_file = "ksplice_infrapatch.sh"
            _plugin_loc_dir  = "exadataPrePostPlugins/ksplice_plugins/"
            _plugin_log = "/opt/exacloud/customs/plugins/ksplice_plugins/ksplice_console.log"
        elif aTaskType in [ self.TASK_ONEOFF ]:
            ebLogInfo("Executing One-off patch operation...\n")
            _plugin_remote_dir = "/opt/exacloud/customs/plugins/oneoff_patches/"
            _script_file = "oneoff_patch.sh"
            _plugin_loc_dir = "exadataPrePostPlugins/oneoff_patch/"
            _plugin_log = "/opt/exacloud/customs/plugins/oneoff_patches/oneoff_console.log"

        if self.__additional_options and 'plugin_location' in self.__additional_options[0]\
           and self.__additional_options[0]['plugin_location'] != 'none':
            plugin_loc_dir = self.__additional_options[0]['plugin_location']
        
        aTargetType = aTargetType[0].encode()
        # Get node list based on the target type.
        if aTargetType == self.PATCH_DOM0:                    
            _node_list = self._mGetDom0List()                    
        elif aTargetType == self.PATCH_CELL:                        
            _node_list = self._mGetCellList()
        elif aTargetType == self.PATCH_DOMU:
            _node_list = self._mGetDomUList()
        elif aTargetType == self.PATCH_IBSWITCH:
            _node_list = self._mGetIBSwitchList()
        
        '''
         Below code snippet validates for existence of Ksplice plugin/
         one off patch directories locally on the exacloud as well as the 
         target nodes.
        '''

        # Location of exacloud and dbnu plugins (on exacloud and on target node)
        try:
            if os.path.isdir (_plugin_loc_dir) is False:
                ebLogError("Parent plugins for '%s' are not found on '%s'" %\
                          (aTargetType, _plugin_loc_dir))
                return ebError(0x0783)
        except Exception as e:
            ebLogError("Exception: Validating presence of ksplice plugins/One off patches: "+str(e))

        try:
            # Step 1. Copy ksplice Plugins/ One-off patches.
            
            for _entry_file in os.listdir(_plugin_loc_dir):
                for _node_name in _node_list:
                    ebLogDebug("Target Node: %s, Copy plugins: Source = %s, Destination file = %s" % \
                               (_node_name, os.path.join(_plugin_loc_dir, _entry_file),
                               os.path.join(_plugin_remote_dir, _entry_file)))
                    if os.path.isdir(os.path.join(_plugin_loc_dir, _entry_file)):
                        ebLogInfo("The '%s' is a directory, we skip to copy directory." % \
                                   os.path.join(_plugin_loc_dir, _entry_file))
                        continue
                    else:
                        _node = exaBoxNode(get_gcontext())
                        _node.mConnect(aHost=_node_name)
                        _node.mExecuteCmdLog("mkdir -p "+ _plugin_remote_dir)

                        # Copy ksplice script only in case of listing the security updates installed as 
                        # RPMs are not required to be copied in the case.
                        if aTaskType in [ self.TASK_KSPLICE ] and self.__additional_options[0]['KspliceAction'] == "list":
                            _node.mCopyFile(os.path.join(_plugin_loc_dir, "ksplice_infrapatch.sh"), os.path.join(_plugin_remote_dir, "ksplice_infrapatch.sh"))
                        else:
                            _node.mCopyFile(os.path.join(_plugin_loc_dir, _entry_file), os.path.join(_plugin_remote_dir, _entry_file))
                        _node.mDisconnect()
        except Exception as e:
            ebLogError("Exception: Error in Copying ksplice plugins/One off patches to target nodes: "+str(e))
        
        '''
          Below snippet fetches the "KspliceAction" to be performed 
          when ksplice operation is provided and performs the 
          required ksplice KspliceAction.
        '''

        _patch_file = os.path.join(_plugin_remote_dir, _script_file)
        if aTargetType in [ self.PATCH_DOM0, self.PATCH_CELL ] and aTaskType in [ self.TASK_KSPLICE ]\
           and self.__additional_options and 'KspliceAction' in self.__additional_options[0]\
           and self.__additional_options[0]['KspliceAction'] != 'none':
            _ksplice_action = self.__additional_options[0]['KspliceAction']
            # Step 2. Run ksplice plugin operation.
            if not self.mExecuteKsplice(aTargetType, _node_list, _patch_file, _ksplice_action, _plugin_remote_dir, _plugin_log):
                ret = ebError(0x0783)
                return ret
        elif aTaskType in [ self.TASK_ONEOFF ]:
            pass
        else:
            ebLogError("Additional option 'KspliceAction' is missing in ecracli.cfg and exadata_infra_patch_extra_params.json or the argument is not passed through ecracli or REST call. Please re-run the script with 'KspliceAction' option.")
            ret = ebError(0x0783)
            return ret
        
        '''
         Below snippet of code executes one off related
         scripts provided by user.
        '''

        if aTaskType in [ self.TASK_ONEOFF ] and aTargetType in [ self.PATCH_DOM0, self.PATCH_CELL, self.PATCH_DOMU, self.PATCH_IBSWITCH ]:
            # Step 2. Run one off patch operation.
            if not self.mExecuteOneOffPatch(aTargetType, _node_list, _patch_file, _plugin_remote_dir, _plugin_log):
                ret = ebError(0x0784)
                return ret

        '''
         Clean up scripts and config files on the
         Target nodes.
        '''
        try:
            # Step 3. Clean-up
            for _node_name in _node_list:
                _node = exaBoxNode(get_gcontext())
                _node.mConnect(aHost=_node_name)
                # 3 a. Copy all the relevant log to local.
                ebLogInfo("Copying the logs from Node : %s, Location : %s to Local Directory : %s " %(_node_name, _plugin_log, self.__log_path))
                _node.mCopy2Local(_plugin_log, self.__log_path+'/'+aTaskType+'.'+_node_name+'.'+'log')
                # 3 b. Delete ksplice Plugins/ One-off patches.
                if os.path.isdir(_plugin_remote_dir):
                    ebLogInfo("Deleting plugin directory = %s from target node : %s" % (_plugin_remote_dir, _node_name))
                    _node.mExecuteCmdLog("rm -rf %s" % _plugin_remote_dir)
                _node.mDisconnect()
        except Exception as e:
            ebLogError("Exception: Error in deleting ksplice plugins/One off patch directories on target nodes: "+str(e)) 
   
        return ret


    def mCheckShutdownservices(self, op_style, aTaskType):
        """
        Checks for the operation style to be non-rolling and the task type
        to be patch or rollback, if so, then update the flag to infer 
        shutdown of VM(s) before proceeds with patching/rollback of dom0.
        """

        self.__shutdown_services = (op_style == self.OP_STYLE_NON_ROLLING
           and aTaskType in [self.TASK_PATCH, self.TASK_ROLLBACK])

    def mRunPatchingTask(self, aTaskType=''):
        """
        Runs the patchmgr tasks: precheck, patch or rollback
        """

        # Callback functions used to execute async the patch. In this way, 
        # we can see the patch output in the console.

        _callbacks = [self.mReadCallback, None, self.mErrorCallback, None]
 
        # No action required counter. If all the nodes are at the intended 
        # version, we should return an error code that will be displayed as 
        # warning
        _no_action_taken = 0
        _dom0_domu_no_action_taken = 0

        if not aTaskType:
            aTaskType = self.__task

        # Set OperationStyle to correct value
        self.mSetPatchOperationStyle(aTaskType)

        # Default patch exit code
        ret = 0

        # ER - 30908782 - ksplice and oneoff options using op=ksplice and op=oneoff
        if aTaskType in [ self.TASK_KSPLICE, self.TASK_ONEOFF ]:
            for _ttype in self.__target_type:            
                ebLogInfo("\n---------------> Starting %s in %s <---------------\n" % (aTaskType, _ttype))
                ret = self.mApplyKspliceOneOffPatch(self.__target_type , aTaskType)
                return ret


        for _ttype in [self.PATCH_CELL, self.PATCH_DOM0, self.PATCH_DOMU,
                       self.PATCH_IBSWITCH, self.PATCH_ALL]:

            if _ttype not in self.__target_type:
                continue

            try:
                # Target version will be derived based on the patch zip file in payload area.
                if _ttype in [ self.PATCH_CELL ]:
                    self.__target_version = (self.__cells_ibswitches_local_patch_zip[::-1].split("/")[0])[::-1].replace(".patch", "").replace(".zip","")
                elif _ttype in [ self.PATCH_IBSWITCH, self.PATCH_ROCESWITCH ]:
                    self.__target_version = (self.__cells_ibswitches_local_patch_zip[::-1].split("/")[0])[::-1].replace(".switch.patch", "").replace(".zip","")
                elif _ttype in [ self.PATCH_DOM0 ]:
                    self.__target_version = self.__dom0_local_patch_zip2.split("/")[-1].split("_")[2]
                elif _ttype in [ self.PATCH_DOMU ]:
                    self.__target_version = self.__domu_local_patch_zip2.split("/")[-1].split("_")[2]
            except Exception as e:
                ebLogError(traceback.format_exc())
                raise ebLogError("Failure in evaluating target version based on patch file. Error = %s." % str(e))
            
            if not self.__target_version:
                raise ebLogError("Invalid target version evaluated based on patch file.")
            else:
                ebLogInfo("Actual Target Version based on patch file = %s" % self.__target_version)

            # Bug - 29911293 Cell postcheck using op=postcheck option.
            if _ttype in [self.PATCH_ALL, self.PATCH_CELL] and aTaskType in [ self.TASK_POSTCHECK, self.TASK_PREREQ_CHECK, self.TASK_ROLLBACK_PREREQ_CHECK ]:
                if aTaskType in [ self.TASK_POSTCHECK ]:
                    ebLogInfo("\n---------------> Starting %s in cells <---------------\n" % aTaskType)
                ret = self.mCustomCheck(self.PATCH_CELL, None, aTaskType)
 
            # Cell Operations
            if _ttype in [self.PATCH_ALL, self.PATCH_CELL] and aTaskType not in [ self.TASK_POSTCHECK ]:
                ebLogInfo("\n---------------> Starting %s in cells <---------------\n" % aTaskType)

                _dom0s_list = {}

                # Add to executed targets
                self.__executed_targets.append(self.PATCH_CELL)

                # Set current patch. Information necessary to update status in db
                self.__current_target_type = self.PATCH_CELL

                # If patching req retried, then we expect patchmgr log file and we need to read that.
                # Also, we need to bring up domU at the end.
                if self.mPatchRequestRetried():
                    # Get list of domUs and it's required for bring up the domUs at the end.
                    for _dom0 in self._mGetDom0List():
                        _dom0s_list[_dom0] = self._mGetDomUList(_dom0, aFromXmList=True)

                    # monitor patch notifications for status change
                    self.mMonitorCNSEvents()

                    ebLogInfo('Launch Node = %s' % self.__dom0_to_patch_cells_ibswitches)
                    _exit_code = self.mReadPatchmgrConsoleOut(self.__dom0_to_patch_cells_ibswitches, self.__patchmgr_log_path_on_launch_node)
 
                    # If patchmgr cmd success, then it return '0', otherwise, error 
                    if _exit_code == 0:
                        ret = _exit_code
                    else:
                        ret = ebError(0x0612)

                    # Reading the path of the input file from the reference of last request_id run
                    _input_file_retry_case = os.path.join(self.__cells_ibswitches_patch_base_after_unzip, "node_list")

                    _list_of_cells_retry_case = self._mGetNodeList(_input_file_retry_case, self.__dom0_to_patch_cells_ibswitches) 
    
                    # Run cleanup to get diagnosis files.
                    self._mCellsCleanUp(_input_file_retry_case, _callbacks)

                    # Clean the environment: Delete passwordless, delete input file
                    self._mCleanEnvironment(self.__dom0_to_patch_cells_ibswitches, _list_of_cells_retry_case, 
                                            _input_file_retry_case, self.__cells_ibswitches_patch_base_after_unzip, 
                                            self.__patchmgr_log_path_on_launch_node, self.PATCH_CELL)

                    # Turn on vms
                    if self.__shutdown_services:
                        for _dom0 in _dom0s_list.keys():
                            self.mUpdatePatchStatus(True, self.STEP_START_VMS, _dom0)
                            self.__clupatchcheck.mManageVMs(_dom0, _dom0s_list[_dom0], aAction='start')

                # Get list of all the cells in the cluster for regular patch flow (but not in patch retry)
                if not self.mPatchRequestRetried():
                    _list_of_cells, _discarded = self._mFilterNodesToPatch(self._mGetCellList(), self.PATCH_CELL, aTaskType)

                if not self.mPatchRequestRetried() and len(_discarded) > 0 \
                    and aTaskType not in [ self.TASK_PREREQ_CHECK, self.TASK_ROLLBACK_PREREQ_CHECK ]:
                    _ret = self.mCustomCheck(self.PATCH_CELL ,_discarded, aTaskType)
                    if _ret != 0:
                        ebLogError("Although cell nodes '%s' are on requested version, required services are not running." %(_discarded))
                        self.mAddError(_discarded, 1015)
                        ret = ebError(0x0778)
                        _no_action_taken+=1
                        continue

                if not self.mPatchRequestRetried() and len(_list_of_cells) > 0:

                    # Init extra process that will look for cell information to keep status updated
                    if self.__fabric :
                        self.__process = Process(target=self.mUpdateTaskFile)
                        self.__process.start()

                    # monitor patch notifications for status change
                    self.mMonitorCNSEvents()

                    '''
                     Collect the precheck data before the upgrade/rollback and 
                     same would be compare against the result after the 
                     patching.
                    '''

                    # Gather precheck data
                    if aTaskType not in [ self.TASK_PREREQ_CHECK, self.TASK_ROLLBACK_PREREQ_CHECK ]:
                        _precheck_data = self._mGatherCellPreCheckData(_list_of_cells)

                    # Check cell services for the below cellcli commands to work
                    for _cell in _list_of_cells:
                        if not self.__clupatchcheck.mCheckCellServices(_cell, aCheckRunning=True):
                            self.mAddError(_cell, 1009)
                            ebLogError('Cell services seems to be not up on cell %s. Please verify the cell service functionality.' % _cell)
                            ret = ebError(0x0619)
                            _no_action_taken+=1
                            continue
                        ebLogDebug("Cell services on %s are up and running." % _cell)

                    # Prepare environment: passwordless between dom0 and cells, create input file
                    (_key, _input_file) = self._mPrepareEnvironment(self.__dom0_to_patch_cells_ibswitches, _list_of_cells,
                                                                    self.__cells_ibswitches_patch_base_after_unzip)

                    # if rolling upgrade, check asmdeactivationoutcome
                    if not self.__shutdown_services:
                        ebLogInfo("Verifying ASM deactivationoutcome for cells to be patched in Rolling mode.")
                        if not self.__clupatchcheck.mVerifyGriddiskDeactivationOutcome(_list_of_cells, self.__op_style):
                            ebLogError("Pre-patch check: ASM deactivationoutcome status is not 'Yes' in some of the cells and the outcome is not successful.")
                            self.mAddError('',1014)
                            ret = ebError(0x0619)
                            _no_action_taken+=1
                            continue
                        ebLogInfo("ASM deactivationoutcome successful on all cells")

                    # If non-rolling check for asmmodestatus, then shutdown vms and cell services
                    if self.__shutdown_services:
                        ebLogInfo("Verifying ASM asmmodestatus for cells to be patched in non-rolling mode.")
                        if not self.__clupatchcheck.mVerifyGriddiskDeactivationOutcome(_list_of_cells, self.__op_style):
                            ebLogError("Pre-patch check: ASM asmmodestatus is not 'ONLINE' in some of the cells.")
                            self.mAddError('',1014)
                            ret = ebError(0x0619)
                            _no_action_taken+=1
                            continue
                        ebLogInfo("ASM asmmodestatus successful on all cells")

                        # Shutdown vms
                        for _dom0 in self._mGetDom0List():
                            self.mUpdatePatchStatus(True, self.STEP_SHUTDOWN_VMS, _dom0)
                            _dom0s_list[_dom0] = self._mGetDomUList(_dom0, aFromXmList=True)
                            self.__clupatchcheck.mManageVMs(_dom0, _dom0s_list[_dom0], aAction='shutdown')
              
                        # Shutdown cell services in cells that will be patched
                        self.mUpdatePatchStatus(True, self.STEP_STOP_CELL_SERVICES)
                        self.__clupatchcheck.mControlCellServices(_list_of_cells, aAction='stop')
                    
                    # Run patchmgr command
                    _patch_ret = self._mPatchCellsIBSwitchesRolling(self.PATCH_CELL, aTaskType, _list_of_cells, _input_file, _callbacks)

                    if _patch_ret != 0:
                        for _host in _list_of_cells:
                            self.mAddError(_host, 1001)
                        ret = ebError(0x0612)

                    # Run cleanup to get diagnosis files.
                    self._mCellsCleanUp(_input_file, _callbacks)

                    # Clean the environment: Delete passwordless, delete input file
                    self._mCleanEnvironment(self.__dom0_to_patch_cells_ibswitches, _list_of_cells, _input_file, self.__cells_ibswitches_patch_base_after_unzip, self.__patchmgr_log_path_on_launch_node, self.PATCH_CELL)

                    # Turn on vms
                    if self.__shutdown_services:
                        for _dom0 in _dom0s_list.keys():
                            self.mUpdatePatchStatus(True, self.STEP_START_VMS, _dom0)
                            self.__clupatchcheck.mManageVMs(_dom0, _dom0s_list[_dom0], aAction='start')
                    #self.__clupatchcheck.mControlCellServices(_list_of_cells, aAction='start')

                    # Do postchecks
                    _wait_before_post_check = False
                    if aTaskType in [self.TASK_PATCH, self.TASK_ROLLBACK]:
                        _wait_before_post_check = True

                    '''
                     After the cell upgrade/rollback, do the postcheck and 
                     compare the result against the precheck data collected 
                     before patching/rollback.
                    '''

                    if aTaskType not in [ self.TASK_PREREQ_CHECK, self.TASK_ROLLBACK_PREREQ_CHECK ] and ret == 0:
                        if not self._mDoCellPostCheck(_precheck_data, aTaskType, aWait=_wait_before_post_check):
                            ret = ebError(0x0611)
                elif not self.mPatchRequestRetried():
                    ebLogInfo('No available cell nodes to run the patchmgr. Nothing to do here.')
                    _no_action_taken+=1
                    # We need to populate more info about the patching operation when 
                    # no action is required and it requires to update ecra rack 
                    # status to previous
                    self.mAddError(self.mGetRackName(), 1017)

            # Dom0 operations
            if _ttype in [self.PATCH_ALL, self.PATCH_DOM0] and ret == 0:
                ret, _dom0_domu_no_action_taken = self.mPatchDom0sOrDomus(self.PATCH_DOM0, aTaskType)
                _no_action_taken = _no_action_taken + _dom0_domu_no_action_taken 
                # END DOM0 

            # DomU operations
            if _ttype in [self.PATCH_ALL, self.PATCH_DOMU]:

                # Restore ATP setting prior to DomU operations.
                _domu_list = self._mGetDomUList() 
                if not self.mSetExaccAtpSettingsOnDomU(_domu_list, "prepatch"):
                    return ebError(0x0659)

                ret, _dom0_domu_no_action_taken = self.mPatchDom0sOrDomus(self.PATCH_DOMU, aTaskType)
                _no_action_taken = _no_action_taken + _dom0_domu_no_action_taken 
                # END DOMU 

            # Bug - 29911293 postcheck using op=postcheck option.
            if _ttype in [ self.PATCH_ALL, self.PATCH_IBSWITCH ] and aTaskType in [ self.TASK_POSTCHECK, self.TASK_PREREQ_CHECK, self.TASK_ROLLBACK_PREREQ_CHECK ]:
                if aTaskType in [ self.TASK_POSTCHECK ]:
                    ebLogInfo("\n---------------> Starting %s in ibswitches <---------------\n" % aTaskType)
                ret = self.mCustomCheck(self.PATCH_IBSWITCH, None, aTaskType)

            # IBSwitch Operations
            if _ttype in [self.PATCH_ALL, self.PATCH_IBSWITCH] and aTaskType not in [ self.TASK_POSTCHECK ]:
                ebLogInfo("\n---------------> Starting %s in ibswitches <---------------\n" % aTaskType)

                # Add to executed targets
                self.__executed_targets.append(self.PATCH_IBSWITCH)

                # Set current patch. Information necessary to update status in db
                self.__current_target_type = self.PATCH_IBSWITCH
                _ibswitches_to_upgrade = []
                # Need to get the list of switches either from single rack or 
                # from whole fabric 
                if self.__additional_options and 'RackSwitchesOnly' in self.__additional_options[0]\
                   and self.__additional_options[0]['RackSwitchesOnly'] == 'yes': 
                    ebLogWarn("Warning: Attempting to upgrade only leaf switches of the cluster %s " 
                               % self.mGetRackName())
                    # Get list of ibswitches (only leaf, mostly, two switches)
                    # from single rack in a fabric.
                    _switchCfg = self.__cluctrl.mGetSwitches()

                    _ib_switches_from_single_rack = _switchCfg.mGetSwitchesList()
                    _ib_switches_from_fabric = self._mGetIBSwitchList() 
                    """
                     Discard admin switches and remove _id from each ibswitch addresses.
                     Ideally, mGetSwitchesList() returns list. Example:
                       ['slcs16sw-adm01.us.oracle.com_id', 
                        'slcs16sw-ibb0.us.oracle.com_id', 
                        'slcs16sw-iba0.us.oracle.com_id'
                       ] 
                    """
                    # remove '_id' from swich entry
                    _ib_switches_from_single_rack = [item[:-3] for item in _ib_switches_from_single_rack] 
                    # get common ibswitches
                    _ib_set1 = set(_ib_switches_from_single_rack)
                    _ib_set2 = set(_ib_switches_from_fabric)
                    _ibswitches_to_upgrade = list(_ib_set1 & _ib_set2)
                else:
                    # Get list of all the ibswitches in the cluster
                    _ibswitches_to_upgrade = self._mGetIBSwitchList()

                # This is for purely for patch retry operation 
                if self.mPatchRequestRetried():
                    # We should monitor patch notifications for status change in case of patch retry 
                    self.mMonitorCNSEvents()

                    _exit_code = self.mReadPatchmgrConsoleOut(self.__dom0_to_patch_cells_ibswitches, self.__patchmgr_log_path_on_launch_node)
 
                    # If patchmgr cmd success, then it return '0', otherwise, error. 
                    if _exit_code == 0:
                        ret = _exit_code
                    else:
                        ret = ebError(0x0612)

                    # Clean up and gather diagnostic files:-
                    # Reading the path of the input file from the reference of last request_id run
                    _input_file_retry_case = os.path.join(self.__cells_ibswitches_patch_base_after_unzip, "node_list")

                    # Read list of ibswith from input file
                    _list_of_ibswitches_retry_case = self._mGetNodeList(_input_file_retry_case, self.__dom0_to_patch_cells_ibswitches) 
   
                    # Clean the environment: Delete passwordless, delete input file
                    self._mCleanEnvironment(self.__dom0_to_patch_cells_ibswitches, _list_of_ibswitches_retry_case,
                                             _input_file_retry_case, self.__cells_ibswitches_patch_base_after_unzip,
                                             self.__patchmgr_log_path_on_launch_node, self.PATCH_IBSWITCH)
    
                    # Workaround bug 22750766 - IB SWITCH ROLLBACK FAILS IF MORE THAN ONE RUN IS DONE OF PATCHMGR
                    self._mBug22750766(aTaskType)

                # filter valid ibswitches. This is for regular flow 
                if not self.mPatchRequestRetried(): 
                    _list_of_ibswitches, _discarded = self._mFilterIBSwitchesToPatch(_ibswitches_to_upgrade, aTaskType)

                if not self.mPatchRequestRetried() and len(_discarded) > 0  \
                      and aTaskType not in [ self.TASK_PREREQ_CHECK, self.TASK_ROLLBACK_PREREQ_CHECK ]:
                    _ret = self.mCustomCheck(self.PATCH_IBSWITCH ,_discarded, aTaskType)
                    if _ret != 0:
                        ebLogError("Although some of the IBSwitch nodes '%s' are on requested version, required services are not running." %(_discarded))
                        self.mAddError(_discarded, 1015)
                        ret = ebError(0x0778)
                        _no_action_taken+=1
                        continue

                if not self.mPatchRequestRetried() and len(_list_of_ibswitches) > 0:
                    # monitor patch notifications for status change
                    self.mMonitorCNSEvents()
 
                    '''
                     Collect the precheck data before the upgrade/rollback and 
                     same would be compare against the result after the 
                     patching.
                    '''

                    # Gather precheck data
                    if aTaskType not in [ self.TASK_PREREQ_CHECK, self.TASK_ROLLBACK_PREREQ_CHECK ]:
                        _precheck_data = self._mGatherIBSwitchPreCheckData(_list_of_ibswitches)

                    # Prepare environment: passwordless between dom0 and cells, create input file
                    (_key, _input_file) = self._mPrepareEnvironment(self.__dom0_to_patch_cells_ibswitches,
                                                                        _list_of_ibswitches,
                                                                        self.__cells_ibswitches_patch_base_after_unzip)
                                                           
                    # Delete images from /dev/shm on each switch
                    for _ibswitch in _list_of_ibswitches:
                        self._mBug23519421_CleanupShm(_ibswitch)

                    # Run patchmgr command
                    _patch_ret = self._mPatchCellsIBSwitchesRolling(self.PATCH_IBSWITCH, aTaskType, _list_of_ibswitches,
                                                                    _input_file, _callbacks)

                    '''
                     After the ibswitch upgrade/rollback, do the postcheck and 
                     compare the result against the precheck data collected 
                     before patching/rollback.
                    '''
                    if _patch_ret != 0:
                        ret = ebError(0x0612)
                    elif aTaskType not in [ self.TASK_PREREQ_CHECK, self.TASK_ROLLBACK_PREREQ_CHECK ] and not self._mDoIBSwitchPostCheck(_precheck_data, aTaskType):
                        ret = ebError(0x0611)

                    # Clean the environment: Delete passwordless, delete input file
                    self._mCleanEnvironment(self.__dom0_to_patch_cells_ibswitches, _list_of_ibswitches, _input_file,
                                            self.__cells_ibswitches_patch_base_after_unzip, 
                                            self.__patchmgr_log_path_on_launch_node, self.PATCH_IBSWITCH)
    
                    # Workaround bug 22750766 - IB SWITCH ROLLBACK FAILS IF MORE THAN ONE RUN IS DONE OF PATCHMGR
                    self._mBug22750766(aTaskType)

                elif not self.mPatchRequestRetried():
                    ebLogInfo('No available ibswitches to run the patchmgr. Nothing to do here.')
                    _no_action_taken+=1
                    # We need to populate more info about the patching operation when 
                    # no action is required and it requires to update ecra rack 
                    # status to previous
                    self.mAddError(self.mGetRackName(), 1017)


            ebLogInfo("Task: %s - Type: %s\t\t[ ret_code = %d ]" % (aTaskType, _ttype, ret))
            if ret != 0:
                ebLogError("%s '%s' failed. Patch execution stopped." % (_ttype, aTaskType))
                break

        # Per cluster basis, if any patch action is done, then
        # extract and post the notification (CNS) at the end and also
        # there is no need of collecting CNS for dom0/domu rollback
        # pre-requisite check
        if (_no_action_taken == 0 and 
            self.__choice_collect_final_notification == self.__yes_collect_final_notification):
                ebLogInfo('Collecting final patch notification for the cluster %s' 
                           % self.mGetRackName())
                self.mMonitorPatchReqForCNS(aFinalLastCns = True)
  
        if ret == 0 and _no_action_taken == len (self.__target_type):
            return ebError(0x0614)

        return ret

    def mCheckPatchmgrSessionExistence(self, aPatchmgLogPathLaunchNode, aLaunchNode=None, aNodeList=None):
        """
         This method checks for existing of patchmgr session.

         Return two values:
          1) Non-zero (EB ERROR - 613) : One or more patchmgr sessions
              OR
             Zero: No patchmgr session are running
          2) Node name which is running pacthmgr
        """ 

        def _patchmgr_session_hint(aNode):
            """
             Return:
               True: One or more patchmgr sessions are running or had patchmgr ran
               False: No patchmgr sessions are running. 
            """
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=aNode)

            # Search of 'patchmgr -' in the grep command.
            _cmd = "ps -ef | egrep -i 'patchmgr -' | egrep -vi 'grep|tail'"
            _i, _o, _e = _node.mExecuteCmd(_cmd)
            if int(_node.mGetCmdExitStatus()) == 0:
                ebLogInfo("The patchmgr session is active on this cluster. Patchmgr Active Node = '%s'." % aNode)
                _node.mDisconnect()
                return True 

            """
            TODO: Below code can be used for future requirement:-
            # See if there any remote console log found
            if not aPatchmgLogPathLaunchNode:
                ebLogInfo("The patchmgr console log found. Active Launch Node = '%s'." % aNode)

            _patchmgr_console_log_find = 'find %s/PatchmgrConsole.out' % (aPatchmgLogPathLaunchNode)
            _i, _o, _e = _node.mExecuteCmd(_patchmgr_console_log_find)
            if int(_node.mGetCmdExitStatus()) == 0:
                ebLogInfo("The patchmgr console log found. Active Launch Node = '%s'." % aNode)
                _node.mDisconnect()
                return True 
            """

            _node.mDisconnect()
            return False
        # end of _patchmgr_session_hint

         
        ret = 0
        _patchmgr_session_active_node = None 
 
        ebLogInfo("*** Checking for existence of patchmgr/dbnodeupdate.sh sessions in the cluster.")
        # Find patchmgr session in the given list of nodes
        if aNodeList: 
            for _dom0domU in aNodeList:
                if _patchmgr_session_hint(aNode=_dom0domU):
                    ret = ebError(0x613)
                    _patchmgr_session_active_node = _dom0domU
        # Find patchmgr session on the launch node 
        elif aLaunchNode:
            if _patchmgr_session_hint(aNode=aLaunchNode):
                ret = ebError(0x613)
                _patchmgr_session_active_node = aLaunchNode

        if _patchmgr_session_active_node:
            ebLogInfo("*** Patchmgr session found on %s" % _patchmgr_session_active_node)
        else:
            ebLogDebug("*** Patchmgr session not found.")

        return ret, _patchmgr_session_active_node 

    def mPrePostCellCheck(self, aCell, aTaskType):
        
        """
         This method performs basic sanity checks on all Cells in the 
         clusters during Cell prereq and postcheck operartions. These 
         checks are independent of previous checks.
             - return True if success
             - return False if failure
        """

        '''
          Check cell services and ping check only during postcheck 
          stage they are checked at early stages of prereq while
          filtering the list of nodes and is a duplication
          of checks.
        '''
        if aTaskType in [ self.TASK_POSTCHECK ]:
            if not self.__clupatchcheck.mPingNode(aCell):
                ebLogError("Cell %s is not pingable" % (aCell))
                return False
            
            if not self.__clupatchcheck.mCheckCellServices(aCell):
                self.mAddError(aCell, 1009)
                ebLogError('Cell services are not up in %s' % aCell)
                return False
 
        '''
         Check image status
        '''

        _rc = True
        if not self.__clupatchcheck.mCheckImageSuccess(aCell):
            ebLogError("Image status not successful in cell %s" % aCell)

            # Get error messages from /var/log/cellos/validations.log /var/log/cellos/vldrun.*.log
            _errors = 'validations.log/vldrun.*.log output:\n'

            _cell = exaBoxNode(get_gcontext())
            _cell.mConnect(aHost=aCell)
            _i, _o, _e = _cell.mExecuteCmd("grep -as '\[ERROR\|\[FAIL' /var/log/cellos/validations.log"\
                                           " /var/log/cellos/vldrun.*.log")
            _output = _o.readlines()
            if _output:
                _errors += str("".join(_output))
                self.mAddError(aCell, 1008, aComment=_errors)
                _rc = False
            _cell.mDisconnect()

        '''
         Check alert history for error details
        '''

        _cell = exaBoxNode(get_gcontext())
        _cell.mConnect(aHost=aCell)
        _cmd_alert = 'cellcli -e LIST ALERTHISTORY WHERE endtime=null AND alerttype=stateful'
        _i, _o, _e = _cell.mExecuteCmd(_cmd_alert)
        _output = _o.readlines()
        if _output:
            ebLogError("\nErrors were observed in alerthistory output on cell : %s\n" %aCell)
            for out in _output:
                ebLogError("%s" % out)
        _cell.mDisconnect()

        return _rc

    def mPrePostIBSwitchCheck(self, aIBSwitch, aTaskType):
    
        """
         This method performs basic sanity checks on all IBSwitches 
         in the clusters during IBSwitch prereq and postcheck operations. 
         These checks are independent of previous checks.
             - return True if success
             - return False if failure
        """
        
        '''
         Check ping check only during postcheck stage as 
         they are checked at early stages of prereq while 
         filtering the list of nodes and is a duplication 
         of checks.
        '''

        if aTaskType in [ self.TASK_POSTCHECK ]:
            # Ping test to each IBSwitch in the cluster.
            if not self.__clupatchcheck.mPingNode(aIBSwitch):
                self.mAddError(aIBSwitch, 1006)
                return False 
        
        
        # Check SM state
        if not self.__clupatchcheck.mCheckIBSwitchSMState(aIBSwitch):
            self.mAddError(aIBSwitch, 1011)
            return False
        
        # Check smnodes and smpartition list
        if not self.__clupatchcheck.mCheckIBSwitchPartitions(aIBSwitch):
            ebLogError("The output for the command is changed across upgrade or rollback: (1) smnodes list (2) smpartition list active no-page")
            self.mAddError(aIBSwitch, 1013)
            return False

        # Since this is taking longer to fetch the output
        # and is delaying the patch validation process,
        # below snippet of code is commented out for now.
        # In case of any future requirement, it will be
        # enabled.
        
        ''' 
        # FWVerify check validation.
        _aIBSwitch = exaBoxNode(get_gcontext())
        _aIBSwitch.mConnect(aHost=aIBSwitch)
        _i, _o, _e = _aIBSwitch.mExecuteCmd("fwverify")
        _rc = int(_aIBSwitch.mGetCmdExitStatus())
        _aIBSwitch.mDisconnect()
        if _rc != 0:
            _out = _o.readlines()
            ebLogError("Fwverify command failed with error, Please fix the errors and re-run patch operations, more details below.")
            for _output in _out:
                ebLogError("%s" % _output.strip("\n"))   
            return False 
        '''
    
        return True

    def _mCheckKnownAlertHistory(self, aTargetType, aTaskType):

        """
         This method checks for alerts in the alerthistory to
         see if it could be ignored or needs attention, List of
         alerts would be updated in a list based on analysis peformed.

         Although for now ignore_alerts option is of prime focus, More
         actions would be taken for other options as well in future
         releases.
        """

        if aTargetType == self.PATCH_DOM0:
            _node_list = self._mGetDom0List()
        elif aTargetType == self.PATCH_DOMU:
            _node_list = self._mGetDomUList()
        elif aTargetType == self.PATCH_CELL:
            _node_list = self._mGetCellList()

        '''
         The below filter method is called to extract nodes where
         patch or rollback are yet to be performed as it is better to
         check these nodes for alerts than checking the same in the
         already upgraded or rollbacked nodes to enable additional
         options.
        '''

        _list_of_nodes, _discarded = self._mFilterNodesToPatch(_node_list, aTargetType, aTaskType )

        _dom0_filter_list = [ "No link detected on required Ethernet" ]
        _domu_filter_list = [ "Exadata cloud services test message." ]
        _cell_filter_list = [ "Exadata cloud services test message." ]

        if aTargetType in [ self.PATCH_DOM0 ]:
            _dbmcli_cmd = "dbmcli -e 'LIST ALERTHISTORY WHERE endtime=null AND alerttype=stateful'"
            _dom0_filter = '|'.join(_dom0_filter for _dom0_filter in _dom0_filter_list)
            _filter_cmd = " | egrep -i '%s'" %(_dom0_filter)
            _cmd = _dbmcli_cmd + _filter_cmd
        elif aTargetType in [ self.PATCH_DOMU ]:
            _dbmcli_cmd = "dbmcli -e 'LIST ALERTHISTORY WHERE endtime=null AND alerttype=stateful'"
            _domu_filter = '|'.join(_domu_filter for _domu_filter in _domu_filter_list)
            _filter_cmd = " | egrep -i '%s'" %(_domu_filter)
            _cmd = _dbmcli_cmd + _filter_cmd
        elif aTargetType in [ self.PATCH_CELL ]:
            _cellcli_cmd = "cellcli -e 'LIST ALERTHISTORY WHERE endtime=null AND alerttype=stateful'"
            _cell_filter = '|'.join(_cell_filter for _cell_filter in _cell_filter_list)
            _filter_cmd = " | egrep -i '%s'" %(_cell_filter)
            _cmd = _cellcli_cmd + _filter_cmd

        _ignore_alert_flag = False
        for aNode in _list_of_nodes:
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=aNode)
            _i, _o, _e = _node.mExecuteCmd(_cmd)
            _out = _o.readlines()
            _node.mDisconnect()

            if _out:
                ebLogWarn("Error observed in alerthistory output on %s %s." %(aTargetType, aNode))
                ebLogWarn("%s" %(_out))
                ebLogWarn("-ignore_alerts will be appended to the patchmgr command.")
                _ignore_alert_flag |= True
        return _ignore_alert_flag
    

    def _mCheckHwCriticalAlert(self, aTargetType, aTaskType):
        """
         This method checks for the existence of real hardware alert on all
         filter nodes of the specified target, and other than known and 
         specified alerts.
         Return:
            True  --> if genuine hardware alerts found
            False --> if no genuine hardware alerts found
        """
        _cmd = ""

        ebLogInfo("Critical hardware alerts verification started.")

        if aTargetType == self.PATCH_DOM0:
            _node_list = self._mGetDom0List()
        elif aTargetType == self.PATCH_DOMU:
            _node_list = self._mGetDomUList()
        elif aTargetType == self.PATCH_CELL:
            _node_list = self._mGetCellList()

        # list of nodes which are participating in the patch operations.
        _list_of_nodes, _discarded = self._mFilterNodesToPatch(_node_list, aTargetType, aTaskType)

        # Known and ignorable alerts.
        _dom0_filter_list = [ "No link detected on required Ethernet" ]
        _domu_filter_list = [ "Exadata cloud services test message." ]
        _cell_filter_list = [ "Exadata cloud services test message." ]

        if aTargetType in [ self.PATCH_DOM0 ]:
            _dbmcli_cmd = "dbmcli -e 'LIST ALERTHISTORY WHERE endtime=null AND alerttype=stateful and alertShortName=Hardware and severity=Critical'"
            _dom0_filter = '|'.join(_dom0_filter for _dom0_filter in _dom0_filter_list)
            _filter_cmd = " | grep -vE '%s'" %(_dom0_filter)
            _cmd = _dbmcli_cmd + _filter_cmd
        elif aTargetType in [ self.PATCH_DOMU ]:
            _dbmcli_cmd = "dbmcli -e 'LIST ALERTHISTORY WHERE endtime=null AND alerttype=stateful and alertShortName=Hardware and severity=Critical'"
            _domu_filter = '|'.join(_domu_filter for _domu_filter in _domu_filter_list)
            _filter_cmd = " | grep -vE '%s'" %(_domu_filter)
            _cmd = _dbmcli_cmd + _filter_cmd
        elif aTargetType in [ self.PATCH_CELL ]:
            _cellcli_cmd = "cellcli -e 'LIST ALERTHISTORY WHERE endtime=null AND alerttype=stateful and alertShortName=Hardware and severity=Critical'"
            _cell_filter = '|'.join(_cell_filter for _cell_filter in _cell_filter_list)
            _filter_cmd = " | grep -vE '%s'" %(_cell_filter)
            _cmd = _cellcli_cmd + _filter_cmd

        _hw_alert_flag = False

        # Detect H/W alert on all nodes.
        for aNode in _list_of_nodes:
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=aNode)
            _i, _o, _e = _node.mExecuteCmd(_cmd)
            _out = _o.readlines()
            _node.mDisconnect()

            # Genuine H/W alert found.
            if _out:
                ebLogWarn("Found HardWare alert on %s %s:" %(aTargetType, aNode))
                ebLogWarn("%s" %(_out))
                _hw_alert_flag |= True

        ebLogInfo("Critical hardware alerts verification completed.")

        return _hw_alert_flag

    def _mCheckAdditionalOptions(self, aPatchmgrCmd, aTaskType, ttype=None):
        """
        Check to see if any additional option passed to add to
        patchmgr. Basically, we might need to have some workaround to
        over-come the error or warning situation. 
        """
        # Bug31982131 - Do not ignore real hardware alert
        _real_hw_alert_found = False
        if aTaskType not in [self.PATCH_IBSWITCH, self.PATCH_ROCESWITCH]:
            if (self.__additional_options and 'IgnoreAlerts' in self.__additional_options[0]\
               and self.__additional_options[0]['IgnoreAlerts'] == 'yes'):
                ebLogWarn("User specified to ignore hardware alert. Proceeding with patch operation.")
            else:
                _real_hw_alert_found = self._mCheckHwCriticalAlert(aTaskType, ttype)
                if _real_hw_alert_found:
                    ebLogError("Detected Critical Hardware alert on Target Type: %s." % aTaskType)
                    raise Exception("Detected Critical Hardware alert on Target type = %s. Fix the Hardware alert and proceed." % aTaskType)

        # Bug30208068 - To automatically select additional
        # options in case additional options are to be used.
        _ignore_alert_flag = self._mCheckKnownAlertHistory(aTaskType, ttype)

        if self.__additional_options and 'AllowActiveNfsMounts' in self.__additional_options[0]\
           and ( aTaskType in [self.PATCH_DOM0, self.PATCH_DOMU] )\
           and self.__additional_options[0]['AllowActiveNfsMounts'] == 'yes': 
            ebLogWarn("Warning: Allowing active networks mounts option on Target Type : %s." % aTaskType)
            aPatchmgrCmd += " -allow_active_network_mounts"

        if (self.__additional_options and 'IgnoreAlerts' in self.__additional_options[0]\
          and ( aTaskType in [self.PATCH_DOM0, self.PATCH_DOMU, self.PATCH_CELL] )\
          and self.__additional_options[0]['IgnoreAlerts'] == 'yes') or _ignore_alert_flag:
            ebLogWarn("Warning: ignoring all the hardware alerts on Target Type : %s." % aTaskType)
            aPatchmgrCmd += " -ignore_alerts"

        if self.__additional_options and 'ForceRemoveCustomRpms' in self.__additional_options[0]\
           and ( aTaskType in [self.PATCH_DOM0, self.PATCH_DOMU] )\
           and self.__additional_options[0]['ForceRemoveCustomRpms'] == 'yes':
            ebLogWarn("Warning: Removing all the custom RPMs on Target Type : %s." % aTaskType)
            aPatchmgrCmd += " -force_remove_custom_rpms"

        if self.__additional_options and 'ModifyAtPrereq' in self.__additional_options[0]\
           and ( aTaskType in [self.PATCH_DOM0, self.PATCH_DOMU] )\
           and self.__additional_options[0]['ModifyAtPrereq'] == 'yes':
            ebLogWarn("Warning: RPMs related changes at prerequisite check on Target Type : %s." % aTaskType)
            aPatchmgrCmd += " -modify_at_prereq"

        return aPatchmgrCmd

    def mUpdatePluginsMetadata(self):
        """
        Update to indicate whether plugins needs to be run on which targets 
        """

        if self.__enable_plugins.lower() == 'yes': 
            self.__run_user_plugins = self.__run_plugins_enable 
            ebLogInfo("Exadata user plugins enable to run on cluster %s "
                       % self.mGetRackName())

        # Valid plugins types for each target
        _valid_plugin_types_for_domu      = ['domu']
        _valid_plugin_types_for_dom0      =  ['dom0', 'dom0+dom0domu', 'dom0domu+dom0']
        _valid_plugin_types_for_dom0_domu =  ['dom0domu', 'dom0+dom0domu', 'dom0domu+dom0']

        # Remove trailings in plugins types which is provided by user
        if self.__plugin_types:
            self.__plugin_types = self.__plugin_types.strip()
            self.__plugin_types = self.__plugin_types.replace(" ", "")
            self.__plugin_types = self.__plugin_types.lower()

        # Update to indicate whether domu plugins needs to be run 
        if self.__run_user_plugins and self.PATCH_DOMU in self.__target_type:
            if self.__plugin_types in _valid_plugin_types_for_domu:
                self.__run_user_plugins_on_domu_node = self.__run_plugins_enable
                ebLogInfo("Exadata user plugins enable to run on domU upgrade on cluster %s "
                     % self.mGetRackName())
        # Update to indicate whether dom0 plugins needs to be run and also from dom0's domU
        elif self.__run_user_plugins and self.PATCH_DOM0 in self.__target_type:
            if self.__plugin_types in _valid_plugin_types_for_dom0:
                self.__run_user_plugins_on_dom0_node = self.__run_plugins_enable
                ebLogInfo("Exadata user plugins enable to run on dom0 upgrade on cluster %s "
                           % self.mGetRackName())

            if self.__plugin_types in _valid_plugin_types_for_dom0_domu:
                self.__run_user_plugins_on_dom0s_domu_node = self.__run_plugins_enable
                ebLogInfo("Exadata user plugins enable to run on domU during dom0 upgrade on cluster %s "
                          % self.mGetRackName())

    def mPatchDom0sOrDomus(self, aTargetType, aTaskType):
        """
        Depending on the TargetType either patch dom0s or domus.
        """

        ebLogInfo("\n---------------> Starting %s in %ss <---------------\n" % (
                  aTaskType, aTargetType))

        ret = 0
        _no_action_taken = 0

        # List of launch nodes to update patch state metadata
        _launch_nodes = []

        # Add to executed targets
        self.__executed_targets.append(aTargetType)

        # Set current patch. Information necessary to update status in db
        self.__current_target_type = aTargetType

        # Update status
        self.mUpdatePatchStatus(True, self.STEP_PREP_ENV)

        if (aTargetType == self.PATCH_DOM0):
            _nodes_to_patch_except_initial = list(
                set(self.__all_dom0s) - set([self.__dom0_to_patch_dom0]))
            _initial_node_list = [self.__dom0_to_patch_dom0]
            _initial_node = self.__dom0_to_patch_dom0
            _next_node    = self.__dom0_to_patch_initial_dom0    
            _all_nodes    = self.__all_dom0s
            _launch_nodes = [self.__dom0_to_patch_dom0, self.__dom0_to_patch_initial_dom0]
            self.__patch_states_base_dir = os.path.join(self.__dom0_patch_base_after_unzip, "patch_states_data")
            self.__plugins_log_path_on_launch_node = (self.__dom0_patch_base_after_unzip+ "plugins_log_" +self.mGetMasterReqId())
        if (aTargetType == self.PATCH_DOMU):
            _nodes_to_patch_except_initial = list(
                set(self.__all_domus) - set([self.__domu_to_patch_domus]))
            _initial_node_list = [self.__domu_to_patch_domus]
            _initial_node = self.__domu_to_patch_domus
            _next_node    = self.__domu_to_patch_initial_domu    
            _all_nodes    = self.__all_domus 
            _launch_nodes = [self.__domu_to_patch_domus, self.__domu_to_patch_initial_domu]
            self.__patch_states_base_dir = os.path.join(self.__domu_patch_base_after_unzip, "patch_states_data")
            self.__plugins_log_path_on_launch_node = (self.__domu_patch_base_after_unzip+ "plugins_log_" +self.mGetMasterReqId())
        
        # check if any patchmgr session running arround in the patch retry and
        # if so, let's wait for it.
        if self.mPatchRequestRetried(): 
            _p_ses_exist = 1
            _p_active_node = None
            _p_ses_exist, _p_active_node = self.mCheckPatchmgrSessionExistence(self.__patchmgr_log_path_on_launch_node,
                                                                                                aLaunchNode = None,
                                                                                                aNodeList = _all_nodes)
            # Wait for patchmgr to complete
            if _p_ses_exist != 0:
                _exit_code = 1
                _exit_code = int(self.mReadPatchmgrConsoleOut(_p_active_node, self.__patchmgr_log_path_on_launch_node))
                if _exit_code == 0:
                    ebLogInfo("Patch manager session found and completed successfully in patch retry")
                else:
                    ebLogError("Patch manager failed during patch retry. Exit code = %s" % _exit_code)
                    self.__choice_collect_final_notification = self.__no_collect_final_notification
                    ret = ebError(0x0612)
                    return ret, _no_action_taken

        # Layout initial patch progress report/metadata if patch req is new and not retried.
        if aTaskType in [self.TASK_PATCH, self.TASK_ROLLBACK]:
            self.__metadata_json_file = os.path.join(self.__patch_states_base_dir, 
                                                     self.mGetMasterReqId()+"_patch_progress_report.json")
            ebLogInfo("Patch metadata file = %s" % self.__metadata_json_file)
            if not self.mPatchRequestRetried():
                self.mCreateDirOnNodes(_launch_nodes, self.__patch_states_base_dir) 
                mWritePatchInitialStatesToLaunchNodes(aTargetType, _all_nodes,
                                                  _launch_nodes, self.__metadata_json_file)

        # Get list of all the nodes in the cluster
        _list_of_nodes, _discarded = self._mFilterNodesToPatch(
            _all_nodes, aTargetType, aTaskType)

        _err_msg_template = "%s %s failed. Errors printed to screen and logs"

        # Update user plugins flags to run
        self.mUpdatePluginsMetadata()

        # Run post plugins if needed on already completed nodes
        if len(_discarded) > 0 and aTaskType in [self.TASK_PATCH, self.TASK_ROLLBACK]:
            ebLogDebug("Run patch manager and plugins for already upgraded nodes if required")
            # If new patch req, then mark completed for upgraded nodes.
            if not self.mPatchRequestRetried():
                ebLogDebug("Set completed for already upgraded nodes")
                for _n in _discarded:
                    mUpdateAllPatchStatesForNode(_launch_nodes, _n, self.__metadata_json_file, self.PATCH_COMPLETED)
            elif self.mPatchRequestRetried():
                #Verifiy last attempted patchmgr and resume if required.
                _exit_code = 1
                for _n in _discarded:
                    _read_patch_state = mGetPatchStatesForNode(_launch_nodes, self.__metadata_json_file, _n, self.PATCH_MGR)
                    if _read_patch_state == self.PATCH_RUNNING:
                        _active_launch_node = mGetLaunchNodeForTargetType(_launch_nodes, self.__metadata_json_file, aTargetType)
                        ebLogInfo("Launch node where last patchmgr was run = %s and log path = %s" % 
                                   (_active_launch_node, self.__patchmgr_log_path_on_launch_node))
                        _exit_code = int(self.mReadPatchmgrConsoleOut(_active_launch_node, self.__patchmgr_log_path_on_launch_node))
                        if _exit_code == 0: 
                            ebLogInfo("Patch manager success during patch retry")
                            mUpdatePatchMetadata(aTargetType, _launch_nodes, _n,
                                                 self.__metadata_json_file, self.PATCH_MGR, self.PATCH_COMPLETED)
                        else:
                            mUpdatePatchMetadata(aTargetType, _launch_nodes, _n,
                                                 self.__metadata_json_file, self.PATCH_MGR, self.PATCH_FAILED)
                            ebLogError("Patch manager failed during patch retry. Exit code = %s" % _exit_code)
                            self.__choice_collect_final_notification = self.__no_collect_final_notification
                            ret = ebError(0x0612)
                            return ret, _no_action_taken
                     
                #Verifiy last attempted post plugins and resume if required.
                if self.__run_user_plugins:
                    ebLogInfo("Launch nodes = %s" % _launch_nodes)
                    for _n in _discarded:
                        _read_patch_state = ""
                        ebLogInfo("Getting post patch status on node %s." % _n)
                        try:
                            _read_patch_state = mGetPatchStatesForNode(_launch_nodes, self.__metadata_json_file,
                                                                   _n, self.POST_PATCH) 
                            ebLogInfo("Post plugin patch status: %s" %  _read_patch_state)
                        except Exception as e:
                            ebLogWarn('Failed to get the post patch state: %s' % str(e))

                        if not _read_patch_state:
                            ebLogError("Invalid patch state found during patch = %s" % _read_patch_state)
                            self.__choice_collect_final_notification = self.__no_collect_final_notification
                            ret = ebError(0x0779)
                            return ret, _no_action_taken

                        if _read_patch_state in [self.PATCH_PENDING, self.PATCH_RUNNING]:
                            if not self._mPrePostPluginsRun(_n, aTargetType, self.POST_PATCH,
                                                            (aTaskType == self.TASK_ROLLBACK)):
                                mUpdatePatchMetadata(aTargetType, _launch_nodes, _n,
                                                     self.__metadata_json_file, self.POST_PATCH, self.PATCH_FAILED)
                                self.mAddError(_n, 1016)
                                self.__choice_collect_final_notification = self.__no_collect_final_notification
                                ret = ebError(0x0779)
                                return ret, _no_action_taken

                            mUpdatePatchMetadata(aTargetType, _launch_nodes, _n,
                                                 self.__metadata_json_file, self.POST_PATCH, self.PATCH_COMPLETED)

        if len(_discarded) > 0 and aTaskType not in [ self.TASK_POSTCHECK ]:
            _ret = self.mCustomCheck(aTargetType ,_discarded, aTaskType)
            if _ret != 0:
                ebLogError("Although '%s' nodes %s are on requested version, required services are not running." % (("DomU" if (aTargetType == self.PATCH_DOMU) else "Dom0"), _discarded))
                for aNode in _discarded:
                    self.mAddError(aNode, 1015)
                self.__choice_collect_final_notification = self.__no_collect_final_notification
                ret = ebError(0x0778)

                return ret, _no_action_taken

        if len(_list_of_nodes) <= 0:
            ebLogInfo("No available %ss to run the patchmgr. Nothing to do here." %(aTargetType.upper()))

            # No need to check CNS at the end of cluster operation.
            self.__choice_collect_final_notification = self.__no_collect_final_notification

            # We need to populate more info about the patching operation when 
            # no action is required and it requires to update ecra rack status
            # to previous status.
            self.mAddError(self.mGetRackName(), 1017)

            return ret, _no_action_taken

        #set ssh keys from node patchers to the nodes they will be patching
        _ssh_env_setup = ebCluSshSetup(self.__cluctrl)
        _ssh_env_setup.mSetSSHPasswordless(_initial_node, 
                                           _nodes_to_patch_except_initial)
        _ssh_env_setup.mSetSSHPasswordless(_next_node, _initial_node_list)

        # monitor patch notifications for status change
        self.mMonitorCNSEvents()

        # Dom0 Independent Postchecks
        if (aTargetType == self.PATCH_DOM0 and aTaskType == self.TASK_POSTCHECK):
            ret = self.mCustomCheck(self.PATCH_DOM0, _all_nodes, aTaskType)
        # DomU Independent Postchecks
        elif (aTargetType == self.PATCH_DOMU and aTaskType == self.TASK_POSTCHECK):
            ret = self.mCustomCheck(self.PATCH_DOMU, _all_nodes, aTaskType)
 
        # Bug27643008 - Enhance to support image backup
        if aTaskType == self.TASK_BACKUP_IMAGE:
            ret = self._mPatchDom0UsBackup(aTargetType, 
                                              aOperationStyle=self.__op_style)
            if ret != 0:
                ebLogError("_mPatchDom0UsBackup fails. Return value = %s" % ret)
                ebLogError(_err_msg_template % (aTargetType.upper(), "backup_image"))
                ret = ebError(0x0612)

        if aTaskType == self.TASK_PREREQ_CHECK:
            ret = self._mPatchDom0UsPreChecks(aTargetType) 

            if ret != 0:
                if ret == self.NO_ACTION_REQUIRED:
                    _no_action_taken+=1
                    ret = 0

                    # We need to populate more info about the patching
                    # operation when no action is required  
                    self.mAddError(self.mGetRackName(), 1017)
                else:
                    ebLogError(_err_msg_template % (
                                aTargetType.upper(), "precheck") )
                    ret = ebError(0x0612)

        # Fetch user specified exadata env type (like, ecs (is default), adw, atp, fa, higgs, etc).
        if self.__additional_options and 'EnvType' in self.__additional_options[0]:
            self.__exadata_env_type = self.__additional_options[0]['EnvType'].lower()

        if aTaskType == self.TASK_PATCH:
            ret = self._mPatchDom0Us(aTargetType, 
                                     aOperationStyle=self.__op_style, 
                                     aBackupMode=self.__backup_mode, 
                                     aRollback=False)
            if ret != 0:
                if ret == self.NO_ACTION_REQUIRED:
                    _no_action_taken+=1
                    ret = 0
                    # We need to populate more info about the patching
                    # operation when no action is required and need to 
                    # update ecra rack status to previous status.
                    self.mAddError(self.mGetRackName(), 1017)
                elif (ret == self.DOM0_POSTCHECKS_FAILED or
                      ret == self.DOMU_POSTCHECKS_FAILED):
                    ebLogError(_err_msg_template % (
                                aTargetType.upper(), "upgrade postchecks" ))
                    ret = ebError(0x0611)
                else:
                    ebLogError(_err_msg_template % (
                                aTargetType.upper(), "upgrade" ))
                    # 25115417 DOM0 PATCHING AND ROLLBACK FAILURE FALSELY RETURNS SUCCESS
                    ret = ebError(0x0612)

        # TODO: This rollback precheck doesnt exist for dom0s. 
        # Maybe theres something we can manually check
        if aTaskType == self.TASK_ROLLBACK_PREREQ_CHECK:
            # Check if current version is already lower than target version
            _intended_version_flag = True
            for _node_to_patch in _all_nodes:
                if (self.__clupatchcheck.mCheckTargetVersion(_node_to_patch, 
                            aTargetType,
                            self.__target_version) >= 0):
                    _intended_version_flag = False

                    # No need to checking CNS at the end of cluster
                    self.__choice_collect_final_notification = self.__no_collect_final_notification
                    break

            if _intended_version_flag:
                _no_action_taken+=1

            ebLogInfo("Rollback precheck for '%s's is not available in this version"%(
                       aTargetType.upper()))
            ret = 0

        if aTaskType == self.TASK_ROLLBACK:
            ret = self._mPatchDom0Us(aTargetType, 
                                     aOperationStyle=self.__op_style, 
                                     aBackupMode=self.__backup_mode, 
                                     aRollback=True)
            if ret != 0:
                if ret == self.NO_ACTION_REQUIRED:
                    _no_action_taken+=1
                    ret = 0
                    # We need to populate more info about the patching
                    # operation when no action is required and need to 
                    # update ecra rack status to previous status.
                    self.mAddError(self.mGetRackName(), 1017)
                elif ret == self.DOM0_POSTCHECKS_FAILED:
                    ebLogError(_err_msg_template % (
                                aTargetType.upper(),"rollback postchecks" ))
                    ret = ebError(0x0611)
                elif ret == self.DOM0_ROLLBACK_NOT_ALLOWED:
                    ebLogError(_err_msg_template % (aTargetType.upper(),
                        "rollback unavailable because it would cause "
                        "inconsistencies with versions on Dom0 and its DomU" ))
                    ret = ebError(0x0618)
                else:
                    ebLogError("_mPatchDom0Us fails. Return value = %s" % ret)
                    ebLogError(_err_msg_template % (
                                                aTargetType.upper(), "rollback"))
                    # 25115417 DOM0 PATCHING AND ROLLBACK FAILURE FALSELY RETURNS SUCCESS
                    ret = ebError(0x0612)

        _ssh_env_setup.mCleanSSHPasswordless(_initial_node, 
                _nodes_to_patch_except_initial)
        _ssh_env_setup.mCleanSSHPasswordless(_next_node, _initial_node_list)
        ebLogInfo("Log files are in %s" % self.__log_path)

        return ret, _no_action_taken

    def _mPatchImageBackupNode(self, aNode, aTargetType, aListOfNodesToPatch,
                             aPatchInitNode=False):
        """
        Returns 0, if patchmgr takes backup. 
        Returns non-zero, if backup is not taken or failed. 
        """
        _node_patcher = aNode
        _all_nodes = None

        ebLogInfo('Launch node = %s, List of Nodes to work on = %s' % (
                  aNode, aListOfNodesToPatch))

        ##### TBD: check if all vms are in the cluster (heartbeat). 
        for  _dom0u_to_patch in aListOfNodesToPatch[:]:
            # check if all dom[0u]s are healthy/pingable first
            if not self.__clupatchcheck.mPingNode(_dom0u_to_patch):
                aListOfNodesToPatch.remove(_dom0u_to_patch)
                ebLogWarn("%s %s is not pingable." % (
                                     aTargetType.upper(), _dom0u_to_patch))

        if not aListOfNodesToPatch:
            ebLogWarn("No %ss to take image backup." % aTargetType.upper())
            # No need to check CNS at the end of cluster since no image
            # backup is taken on nodes
            self.__choice_collect_final_notification = self.__no_collect_final_notification
            return self.NO_DOM0U_LIST_RUN

        # Update status
        if not aPatchInitNode:
            self.mUpdatePatchStatus(True,
                    self.STEP_FILTER_NODES+'_'+aTargetType+'_1')
        else:
            self.mUpdatePatchStatus(True,
                    self.STEP_FILTER_NODES+'_'+aTargetType+'_2')

        if (aTargetType == self.PATCH_DOM0):
            if not aPatchInitNode:
                self.mUpdatePatchStatus(True, self.STEP_RUN_PATCH_DOM0)
                _update_msg = self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_1'
            else:
                self.mUpdatePatchStatus(True,self.STEP_RUN_PATCH_SECOND_DOM0)
                _update_msg = self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_2'

            _input_file = self._mCreateNodesFile(
                            self.__dom0_patch_base_after_unzip,
                            _node_patcher, aListOfNodesToPatch)
            self.__dom0_patchmgr_intput_file = _input_file
            _input_file_name = _input_file.split("/")[-1]
            _patch_backup_cmd = self.__patchmgr_cmd % (
                        self.__dom0_patch_base_after_unzip, _input_file_name,
                        self.__patchmgr_log_path_on_launch_node,
                        self.__patchmgr_log_path_on_launch_node)

            # All  nodes required for checking presence of patchmgr session 
            _all_nodes = self.__all_dom0s
        elif (aTargetType == self.PATCH_DOMU):
            if not aPatchInitNode:
                self.mUpdatePatchStatus(True, self.STEP_RUN_PATCH_DOMU)
                _update_msg = self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_1'
            else:
                self.mUpdatePatchStatus(True,self.STEP_RUN_PATCH_SECOND_DOMU)
                _update_msg = self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_2'
                                    
            _input_file = self._mCreateNodesFile(
                            self.__domu_patch_base_after_unzip,
                            _node_patcher, aListOfNodesToPatch)
            self.__domu_patchmgr_intput_file = _input_file
            _input_file_name = _input_file.split("/")[-1]
            _patch_backup_cmd = self.__patchmgr_cmd % (
                        self.__domu_patch_base_after_unzip,_input_file_name,
                        self.__patchmgr_log_path_on_launch_node,
                        self.__patchmgr_log_path_on_launch_node)

            # All  nodes required for checking presence of patchmgr session 
            _all_nodes = self.__all_domus
       
        # If there are no patchmgr sessions running, then run patchmgr command
        _pacthmgr_session_exit = 1
        _patchmgr_active_node = None

        _pacthmgr_session_exit, _patchmgr_active_node = self.mCheckPatchmgrSessionExistence(self.__patchmgr_log_path_on_launch_node,
                                                                                            aLaunchNode = None, 
                                                                                            aNodeList = _all_nodes)
        # 1.- Run patchmgr backup
        if _pacthmgr_session_exit == 0: # No patchmgr session found in any of the nodes, so re-execute 
                                        # with same launch/_node_patcher
            self.mExecutePatchmgrCmd(_node_patcher, self.__patchmgr_log_path_on_launch_node, _patch_backup_cmd)
            # Monitor console log 
            _exit_code = int(self.mReadPatchmgrConsoleOut(_node_patcher, self.__patchmgr_log_path_on_launch_node))
        else:
            # TODO: We need to handle patch non-retry in future. Time being we are forcibly stopping.
            if not self.mPatchRequestRetried():
                ebLogError('mPatchImageBackupNode: Found older patchmgr session. Forcibly terminating patching request')
                _exit_code = 1
                return _exit_code

            # Already patchmgr is running, just monitor patchmgr console on the node.
            _exit_code = int(self.mReadPatchmgrConsoleOut(_patchmgr_active_node, self.__patchmgr_log_path_on_launch_node))
            _node_patcher = _patchmgr_active_node

        if len(aListOfNodesToPatch) > 0:
            # 2 .- Update status
            self.mUpdatePatchStatus(True, _update_msg)

            # 3.- Get patchmgr backup logs
            _precheck_log = str(
                self._mGetDom0FileCode(_node_patcher,
                                    self.__patchmgr_log_path_on_launch_node))
            self._mGetPatchMgrOutFiles(_node_patcher,
                                    self.__patchmgr_log_path_on_launch_node,
                                    _precheck_log)
            self._mGetPatchMgrDiagFiles(_node_patcher,
                                    aTargetType,
                                    aListOfNodesToPatch,
                                    self.__patchmgr_log_path_on_launch_node)

        # 4. Remove temporary patchmgr log files
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=_node_patcher)
        _node.mExecuteCmdLog("rm -f %s" % _input_file)

        # Moving log_dir to log_dir_<launch_node>, before starting another one
        _node.mExecuteCmdLog("mv -f %s %s_%s" % (self.__patchmgr_log_path_on_launch_node, 
                                                 self.__patchmgr_log_path_on_launch_node, 
                                                 _node_patcher.split(".")[0]))
        _node.mDisconnect()

        return _exit_code


    def _mPatchDom0UsBackup(self, aTargetType, aOperationStyle):
        """
        Runs the dom[0U]s image backup in rolling or non-rolling mode.

        Returns 0 if patchmgr ran without issues and the dom[0U]s is patched,
        successfully.
        Returns != 0 if patchmgr found problems on the nodes during backup
        """

        if (aTargetType == self.PATCH_DOM0):
            _node_to_patch_nodes = self.__dom0_to_patch_dom0
            _node_to_patch_initial_node = self.__dom0_to_patch_initial_dom0
            _nodes_to_patch_except_initial = list(set(self.__all_dom0s) -
                                              set([self.__dom0_to_patch_dom0]))
            _initial_node_list = [self.__dom0_to_patch_dom0]
            _cns_string = self.CNS_DOM0_PATCHER

        if (aTargetType == self.PATCH_DOMU):
            _node_to_patch_nodes = self.__domu_to_patch_domus
            _node_to_patch_initial_node = self.__domu_to_patch_initial_domu
            _nodes_to_patch_except_initial = list(set(self.__all_domus) -
                                              set([self.__domu_to_patch_domus]))
            _initial_node_list = [self.__domu_to_patch_domus]
            _cns_string = self.CNS_DOMU_PATCHER

        self.__callbacks = [self.mReadCallback, None, self.mErrorCallback, None]

        ebLogDebug('_node_to_patch_nodes = %s, _node_to_patch_initial_node = %s' %(
                   _node_to_patch_nodes, _node_to_patch_initial_node))
        ebLogDebug('_nodes_to_patch_except_initial = %s, _initial_node_list= %s' %(
                   str(_nodes_to_patch_except_initial), str(_initial_node_list)))

        _ec_node_backup = 0
        _ec_initial_node_backup = 0
        self.__patchmgr_cmd = ("cd %s; nohup ./patchmgr -dbnodes %s -backup "
                                                    "-log_dir %s")

        if aOperationStyle == self.OP_STYLE_ROLLING:
            self.__patchmgr_cmd += " -rolling"
         
        # check for additional option if any and add to patchmgr cmd
        self.__patchmgr_cmd = self._mCheckAdditionalOptions(self.__patchmgr_cmd, aTargetType, self.TASK_BACKUP_IMAGE)

        # For the patchmgr command to run in background
        self.__patchmgr_cmd += ' </dev/null > %s/PatchmgrConsole.out 2>&1 &'

        # update current node being used to upgrade i.e., __dom0_to_patch_dom0
        # or domu_to_patch_domus
        _node_patch_progress = os.path.join(self.__log_path, _cns_string)
        try:
            with open(_node_patch_progress, "w") as write_nodestat:
                write_nodestat.write("%s:%s" % (_node_to_patch_nodes,
                        self.__patchmgr_log_path_on_launch_node))
        except Exception as e:
            ebLogWarn('Failed to write %s: %s' %
                      (_node_patch_progress, str(e)))

        # Run the image backup in all the dom[0U]s except one
        _ec_node_backup = self._mPatchImageBackupNode(
                            aNode=_node_to_patch_nodes,
                            aTargetType=aTargetType,
                            aListOfNodesToPatch=_nodes_to_patch_except_initial,
                            aPatchInitNode=False)

        # Extract and post notification (CNS), if anything left out on 
        # __dom0_to_patch_dom0, before it moves to __dom0_to_patch_initial_dom0
        self.mMonitorPatchReqForCNS(
                               aCollectCnsOnce = self.__instant_collect_of_cns)

        # update current node being used to upgrade i.e., to 
        # __dom0_to_patch_initial_dom0  or __domu_to_patch_initial_domu
        try:
            with open(_node_patch_progress, "w") as write_nodestat:
                write_nodestat.write("%s:%s" % (_node_to_patch_initial_node,
                                     self.__patchmgr_log_path_on_launch_node))
        except Exception as e:
            ebLogWarn('Failed to write %s: %s' %
                      (_node_patch_progress, str(e)))

        # Run the image backup in the inital dom[0U]s
        _ec_initial_node_backup = self._mPatchImageBackupNode(
                            aNode=_node_to_patch_initial_node,
                            aTargetType=aTargetType,
                            aListOfNodesToPatch=_initial_node_list,
                            aPatchInitNode=True)

        return _ec_node_backup | _ec_initial_node_backup

    def _mPatchDom0UsPreChecks(self, aTargetType):
        """
        Runs the dom[0U]s prerequisite check in rolling or non-rolling  mode.

        Returns  NO_ACTION_REQUIRED if no nodes requiere patching
        Returns 0 if patchmgr ran without issues and the dom[0U]s should be 
        patched.
        Returns != 0 if patchmgr found problems on the nodes
        """

        if (aTargetType == self.PATCH_DOM0):
            _node_to_patch_nodes = self.__dom0_to_patch_dom0
            _node_to_patch_initial_node = self.__dom0_to_patch_initial_dom0
            _nodes_to_patch_except_initial = list(set(self.__all_dom0s) - 
                                              set([self.__dom0_to_patch_dom0]))
            _initial_node_list = [self.__dom0_to_patch_dom0]
            _cns_string = self.CNS_DOM0_PATCHER
            
        if (aTargetType == self.PATCH_DOMU):
            _node_to_patch_nodes = self.__domu_to_patch_domus
            _node_to_patch_initial_node = self.__domu_to_patch_initial_domu
            _nodes_to_patch_except_initial = list(set(self.__all_domus) - 
                                              set([self.__domu_to_patch_domus]))
            _initial_node_list = [self.__domu_to_patch_domus]
            _cns_string = self.CNS_DOMU_PATCHER
            

        if not _node_to_patch_nodes and _node_to_patch_initial_node:
            raise ebLogError(aTargetType.upper + 
                             " patching is unavailable, " + aTargetType.upper +
                             " patch files" +
                             " were not provided at initialization")

        _callbacks = [self.mReadCallback, None, self.mErrorCallback, None]

        ebLogDebug('_node_to_patch_nodes = %s, _node_to_patch_initial_node = %s' %(
                   _node_to_patch_nodes, _node_to_patch_initial_node))
        ebLogDebug('_nodes_to_patch_except_initial = %s, _initial_node_list= %s' %(
                   str(_nodes_to_patch_except_initial), str(_initial_node_list)))

        _ec_node_precheck = 0
        _ec_initial_node_precheck = 0
        _patchmgr_precheck_cmd = ("cd %s; nohup ./patchmgr -dbnodes %s -precheck "
                                                    " -iso_repo %s "
                                                    "-target_version %s "
                                                    "-log_dir %s")

        # check for additional option if any and add to patchmgr cmd
        _patchmgr_precheck_cmd = self._mCheckAdditionalOptions(_patchmgr_precheck_cmd, aTargetType, self.TASK_PREREQ_CHECK)

        # For the patchmgr command to run in background
        _patchmgr_precheck_cmd += ' </dev/null > %s/PatchmgrConsole.out 2>&1 &'

        def _patch_precheck_node(aNode, aTargetType, aListOfNodesToPatch, 
                                 aPatchInitNode=False):
            _dom0Us_count =  len(aListOfNodesToPatch)
            _domOUs_count_on_same_target_version = 0

            # Initial launch node is what it has passed, but it can change if
            # patchmgr session already exist in case of patch retry. 
            _node_patcher = aNode
            _all_nodes = None

            ebLogInfo('Launch node = %s, List of Nodes to work on = %s' % (
                      aNode, str(aListOfNodesToPatch)))

            # Update status
            if not aPatchInitNode:
                self.mUpdatePatchStatus(True, 
                        self.STEP_FILTER_NODES+'_'+aTargetType+'_1')
            else:
                self.mUpdatePatchStatus(True, 
                        self.STEP_FILTER_NODES+'_'+aTargetType+'_2')

            ##### TBD: check if all vms are in the cluster (heartbeat). 
            for  _dom0u_to_patch in aListOfNodesToPatch[:]:
                # check if all dom[0u]s are healthy/pingable first
                if not self.__clupatchcheck.mPingNode(_dom0u_to_patch):
                    ebLogWarn("%s %s is not pingable. Discarding for precheck" % (
                                         aTargetType.upper(), _dom0u_to_patch))
                    aListOfNodesToPatch.remove(_dom0u_to_patch)
                    continue

                #Bug 23149472 - PATCHMGR INTERNAL ERROR PREREQ CHECK IF A NODE
                #               IS ALREADY AT TARGET VERSION
                #  to work around this, we will manually check to see if the 
                #  requested precheck version is already the installed version 
                #  on every node to precheck
                if (self.__clupatchcheck.mCheckTargetVersion(_dom0u_to_patch, 
                                 aTargetType, self.__target_version) >= 0):
                    ebLogInfo("%s is already at the requested version %s (or higher)"\
                              % (_dom0u_to_patch, self.__target_version))
                    # Remove this node from the list that we will run pre-checks 
                    # with patchmgr
                    aListOfNodesToPatch.remove(_dom0u_to_patch)
                    _domOUs_count_on_same_target_version += 1

            if (aListOfNodesToPatch and
                ((_dom0Us_count - len(aListOfNodesToPatch)) != 
                  _domOUs_count_on_same_target_version)):
                  ebLogWarn("Cluster is not coherent. Expected %s %ss, but got %s"
                             % (str(_dom0Us_count), aTargetType.upper(), 
                               str(len(aListOfNodesToPatch))))

            ebLogDebug("ebCluPatchControl._mPatchDom0UsPreChecks: "
                       "_dom0Us_count = %s, "
                       "aListOfNodesToPatch = %s, "
                       "doums_count_on_same_target_version = %s"
                       % (_dom0Us_count, len(aListOfNodesToPatch),
                          _domOUs_count_on_same_target_version))

            # if we removed all of the nodes to run pre-check, because they were 
            # already at the requested version just return success
            if (not aListOfNodesToPatch and
                _dom0Us_count == _domOUs_count_on_same_target_version):
                ebLogInfo("All the DOMUs are in the requested version. "
                          "No action required")
                return self.NO_ACTION_REQUIRED

            # Return failure if no dom0Us to precheck 
            if not aListOfNodesToPatch:
                # No need to check CNS at the end of cluster since no precheck 
                # is done 
                self.__choice_collect_final_notification = self.__no_collect_final_notification
                ebLogWarn("No %ss to run precheck." % aTargetType.upper())
                return self.NO_DOM0U_LIST_RUN

            if (aTargetType == self.PATCH_DOM0):
                if not aPatchInitNode:
                    self.mUpdatePatchStatus(True, self.STEP_RUN_PATCH_DOM0)
                    _update_msg = self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_1'
                else:
                    self.mUpdatePatchStatus(True,self.STEP_RUN_PATCH_SECOND_DOM0)
                    _update_msg = self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_2'

                _input_file = self._mCreateNodesFile(
                                self.__dom0_patch_base_after_unzip, 
                                aNode, aListOfNodesToPatch)
                self.__dom0_patchmgr_intput_file = _input_file 
                _input_file_name = _input_file.split("/")[-1]
                _patch_precheck_cmd = _patchmgr_precheck_cmd % (
                            self.__dom0_patch_base_after_unzip,_input_file_name,
                            self.__dom0_patch_zip2_name, self.__target_version, 
                            self.__patchmgr_log_path_on_launch_node,
                            self.__patchmgr_log_path_on_launch_node)
                # Get all dom0 list for checking the patchmgr session exist
                _all_nodes = self.__all_dom0s
            elif (aTargetType == self.PATCH_DOMU):
                if not aPatchInitNode:
                    self.mUpdatePatchStatus(True, self.STEP_RUN_PATCH_DOMU)
                    _update_msg = self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_1'
                else:
                    self.mUpdatePatchStatus(True,self.STEP_RUN_PATCH_SECOND_DOMU)
                    _update_msg = self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_2'
                _input_file = self._mCreateNodesFile(
                                self.__domu_patch_base_after_unzip, 
                                aNode, aListOfNodesToPatch)
                self.__domu_patchmgr_intput_file = _input_file     
                _input_file_name = _input_file.split("/")[-1]
                _patch_precheck_cmd = _patchmgr_precheck_cmd % (
                            self.__domu_patch_base_after_unzip,_input_file_name,
                            self.__domu_patch_zip2_name, self.__target_version,
                            self.__patchmgr_log_path_on_launch_node,
                            self.__patchmgr_log_path_on_launch_node)
                # Get all domu list for checking the patchmgr session exist
                _all_nodes = self.__all_domus

            # 1.- Run pre_check
            # If there are no patchmgr sessions running, then run patchmgr command
            _pacthmgr_session_exit = 1
            _patchmgr_active_node = None

            _pacthmgr_session_exit, _patchmgr_active_node = self.mCheckPatchmgrSessionExistence(self.__patchmgr_log_path_on_launch_node,
                                                                                                aLaunchNode = None,
                                                                                                aNodeList = _all_nodes)
                                                            
            if _pacthmgr_session_exit == 0: # No patchmgr session found in any of the nodes, so re-execute 
                                            # with same launch/_node_patcher
                self.mExecutePatchmgrCmd(_node_patcher, self.__patchmgr_log_path_on_launch_node, _patch_precheck_cmd)
                # Monitor console log 
                _exit_code = self.mReadPatchmgrConsoleOut(_node_patcher, self.__patchmgr_log_path_on_launch_node)
            else:
                # TODO: We need to handle patch non-retry in future. Time being we are forcibly stopping.
                if not self.mPatchRequestRetried():
                    ebLogError('PatchDom0UsPreChecks: Found older patchmgr session. Forcibly terminating patching request')
                    _exit_code = 1
                    return _exit_code

                # Already patchmgr is running, just monitor patchmgr console on the node.
                _exit_code = self.mReadPatchmgrConsoleOut(_patchmgr_active_node, self.__patchmgr_log_path_on_launch_node)
                _node_patcher = _patchmgr_active_node

            if len(aListOfNodesToPatch) > 0:
                # 2 .- Update status
                self.mUpdatePatchStatus(True, _update_msg)

                # 3.- Get patchmgr pre-check logs
                _precheck_log = str(
                    self._mGetDom0FileCode(_node_patcher,
                                        self.__patchmgr_log_path_on_launch_node))
                self._mGetPatchMgrOutFiles(_node_patcher,
                                        self.__patchmgr_log_path_on_launch_node,
                                        _precheck_log)
                self._mGetPatchMgrDiagFiles(_node_patcher, 
                                        aTargetType,
                                        aListOfNodesToPatch,
                                        self.__patchmgr_log_path_on_launch_node)
                self._mGetPatchMgrMiscLogFiles(_node_patcher,
                                               self.__patchmgr_log_path_on_launch_node)
   
            # 4. Remove temporary patchmgr log files  
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=_node_patcher)
            _node.mExecuteCmdLog("rm -f %s" % _input_file)

            # Moving log_dir to log_dir_<launch_node>, before starting another one
            _node.mExecuteCmdLog("mv -f %s %s_%s" % (self.__patchmgr_log_path_on_launch_node, 
                                                     self.__patchmgr_log_path_on_launch_node, 
                                                     _node_patcher.split(".")[0]))
            _node.mDisconnect()

            return _exit_code
            # end of _patch_precheck_node

        # update current node being used to upgrade i.e., __dom0_to_patch_dom0
        # or domu_to_patch_domus
        _node_patch_progress = os.path.join(self.__log_path, _cns_string) 
        try:
            with open(_node_patch_progress, "w") as write_nodestat:
                write_nodestat.write("%s:%s" % (_node_to_patch_nodes,
                        self.__patchmgr_log_path_on_launch_node))
        except Exception as e:
            ebLogWarn('Failed to write %s: %s' %
                      (_node_patch_progress, str(e)))

        # Run the pre_check in all the dom[0U]s except one
        _ec_node_precheck  = _patch_precheck_node(
                            aNode=_node_to_patch_nodes,
                            aTargetType=aTargetType,
                            aListOfNodesToPatch=_nodes_to_patch_except_initial,
                            aPatchInitNode=False)

        # Extract and post notification (CNS), if anything left out on 
        # __dom0_to_patch_dom0, before it moves to __dom0_to_patch_initial_dom0
        self.mMonitorPatchReqForCNS(
            aCollectCnsOnce = self.__instant_collect_of_cns)

        # update current node being used to upgrade i.e., to 
        # __dom0_to_patch_initial_dom0  or __domu_to_patch_initial_domu
        try:
            with open(_node_patch_progress, "w") as write_nodestat:
                write_nodestat.write("%s:%s" % (_node_to_patch_initial_node,
                                     self.__patchmgr_log_path_on_launch_node))
        except Exception as e:
            ebLogWarn('Failed to write %s: %s' %
                      (_node_patch_progress, str(e)))

        # Run the pre_check in the inital dom0 or domU
        _ec_initial_node_precheck = _patch_precheck_node(
                            aNode=_node_to_patch_initial_node,
                            aTargetType=aTargetType,
                            aListOfNodesToPatch=_initial_node_list,
                            aPatchInitNode=True)

        if (_ec_node_precheck ==  self.NO_ACTION_REQUIRED or 
            _ec_initial_node_precheck == self.NO_ACTION_REQUIRED):
            if (_ec_node_precheck ==  self.NO_ACTION_REQUIRED and 
                _ec_initial_node_precheck == self.NO_ACTION_REQUIRED):
                return self.NO_ACTION_REQUIRED
            if _ec_node_precheck ==  self.NO_ACTION_REQUIRED:
                return _ec_initial_node_precheck
            else:
                return _ec_node_precheck

        return _ec_node_precheck | _ec_initial_node_precheck

    def mExecutePatchmgrCmd(self, aNode, aPatchmgLogPathLaunchNode, aPatchMgrCmd):
        """
          This method helps create a log directory prior to running a patchmgr 
          and starts the command in nohup mode 
        """
         
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aNode)
        
        ebLogInfo("\nPatchmgr Command running in the background : \n\n%s\n" % aPatchMgrCmd)
        _cmd_mkdir = 'mkdir -p %s' % (aPatchmgLogPathLaunchNode)
        _node.mExecuteCmd(_cmd_mkdir)
        _node.mExecuteCmdLog(aPatchMgrCmd)
        _node.mDisconnect()

    def mCreateDirOnNodes(self, aNodeList, aDirPath):
        """
          Create directory 'aDirPath' on given list of aNodeList.
        """
        _cmd_mkdir = 'mkdir -p %s' % (aDirPath)
        for _node in aNodeList:
            _node_ctx = exaBoxNode(get_gcontext())
            _node_ctx.mConnect(aHost=_node)
            _node_ctx.mExecuteCmd(_cmd_mkdir)
            _node_ctx.mDisconnect()

    def mReadPatchmgrConsoleOut(self, aNode, aPatchmgLogPathLaunchNode):  
        """
         Here we connect to the launch node and try to check for progress reading 
          Patchmgr Console out file. It returns:

             zero     --> when patchmgr end with success
             non-zero --> when patchmgr end with failure

          Since the patchmgr is run in the background using nohup, the below section
           of code monitors the log file for completion and returns the exit status of the
          patchmgr command.
        """ 

        ebLogDebug("Read patchmgr console from node = %s and log loc = %s" % (aNode, aPatchmgLogPathLaunchNode))
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aNode)
        _patch_mgr_run = True
        _patchmgr_prev = None

        _current_time_in_sec = 0
        _exit_code = 1
 
        # TODO: We might miss few lines if patchmgr written more lines to the
        #       patchmgr console quicker than what we read in this loop. 
        #       So, we need to handle this case in future.  

        _patchmgr_find = 'egrep -i "Working|SUCCESS|INFO|WARNING|ERROR" %s/PatchmgrConsole.out | tail -1' % (aPatchmgLogPathLaunchNode)
        _patchmgr_seek = 'grep -i "Exit status" %s/PatchmgrConsole.out' % (aPatchmgLogPathLaunchNode)

        while _patch_mgr_run and _current_time_in_sec < self.EXADATA_PATCHMGR_CONSOLE_READ_TIMEOUT_SEC:
            _i, _o, _e = _node.mExecuteCmd(_patchmgr_find)
            _out = _o.readlines()
                            
            for _output in _out:
                _output = _output.strip() 
                if _patchmgr_prev != _output: 
                    ebLogInfo("%s" % _output)
                    _patchmgr_prev = _output                                                               
                                                                                                            
            _i, _o, _e = _node.mExecuteCmd(_patchmgr_seek)
            _exit_check = _node.mGetCmdExitStatus()
            _out = _o.readlines()
                                                                                                            
            if _exit_check == 0:
                _patch_mgr_run = False
                for _output in _out:
                    ebLogInfo("%s" % _output)
                    if "Exit status:0" in _output:
                        _exit_code = 0
                    _node.mDisconnect()
                    return _exit_code
            sleep(1)
            _current_time_in_sec += 1

        _node.mDisconnect()
        return _exit_code

    def _mValidateIbSwitchNTPdata(self, aListOfNodes):
        """
           Validate NTP synchronisation detail for all the
           NTP hosts added in ntp.conf file on all of the
           Ibswitches in the Exadata rack.
        """

        _rc = True
        for aIBswitch in aListOfNodes:
            #Get the NTP server entries on the node.
   
            _cmd = 'grep ^server /etc/ntp.conf | awk "{print $2}"'
   
            _ibsw = exaBoxNode(get_gcontext())
            _ibsw.mConnect(aHost=aIBswitch)
            _in, _out, _err = _ibsw.mExecuteCmd(_cmd)
            _ibntp_nodes = _out.readlines()
   
            if not _ibntp_nodes:
                ebLogError("No NTP server details found in ntp.conf on %s" % (aIBswitch))
                _rc = False
                _ibsw.mDisconnect()
                break
  
            # The below command tried to check the synchronization between the NTP servers and Ibswitches for success. 
            _cmd = 'for aNtp in `grep ^server /etc/ntp.conf | awk "{print $2}"`; do ntpdate -d $aNtp | grep "adjust time server"; done'
         
            _ibs = exaBoxNode(get_gcontext())
            _ibs.mConnect(aHost=aIBswitch)
            _in, _out, _err = _ibs.mExecuteCmd(_cmd)
            _ibntp_List = _out.readlines()
            _ibs.mDisconnect()
   
            for ibnodes in _ibntp_nodes:
                ibnodes = ibnodes.strip()
                if ibnodes in str(_ibntp_List):
                    ebLogInfo("Time syncronization between NTP Server : [%s] and Ibswitch : [%s] is good." % (ibnodes, aIBswitch))
                else:
                    ebLogError("No NTP synchronization found for NTP Server : [%s] on ibswitch : [%s]" % (ibnodes, aIBswitch))
                    _rc = False
        return _rc

    def _mPatchCellsIBSwitchesRolling(self, aNodeType, aTask, aListOfNodes, 
                                      aListFilePath, aCallbacks):
        """
        Runs the cells/ibswitches patch operations in rolling mode.
        """

        if not self.__dom0_to_patch_cells_ibswitches:
            raise ebError(aNodeType + " patching is unavailable, "
                          "patch files were not provided at initialization")
        _exit_code = 0
        _patchmgr_cmd = ""
        _input_file_name = aListFilePath.split("/")[-1]

        if aNodeType == self.PATCH_CELL:
            if aTask == self.TASK_PREREQ_CHECK:
                _patchmgr_cmd = "cd %s; nohup ./patchmgr -cells %s -patch_check_prereq"
            elif aTask == self.TASK_PATCH:
                _patchmgr_cmd = "cd %s; nohup ./patchmgr -cells %s -patch"
            elif aTask == self.TASK_ROLLBACK_PREREQ_CHECK:
                _patchmgr_cmd = "cd %s; nohup ./patchmgr -cells %s -rollback_check_prereq"
            elif aTask == self.TASK_ROLLBACK:
                _patchmgr_cmd = "cd %s; nohup ./patchmgr -cells %s -rollback"

            # use log_dir option so that all logs generates at definite location 
            _patchmgr_cmd+=" -log_dir %s"

            if self.__op_style == self.OP_STYLE_ROLLING:
                _patchmgr_cmd+=" -rolling"

            # check for additional option if any and add to patchmgr cmd
            _patchmgr_cmd = self._mCheckAdditionalOptions(_patchmgr_cmd, aNodeType, aTask)

            # For the patchmgr command to run in background
            _patchmgr_cmd += ' </dev/null > %s/PatchmgrConsole.out 2>&1 &'
 
            # Update status
            self.mUpdatePatchStatus(True, self.STEP_RUN_PATCH_CELL)

        if aNodeType == self.PATCH_IBSWITCH:
            # The below called method validates for the NTP synchronization
            # on all of the Ibswitches.
            _rc = self._mValidateIbSwitchNTPdata(aListOfNodes)
            if not _rc:
                _exit_code = 1
            if aTask == self.TASK_PREREQ_CHECK:
                _patchmgr_cmd = "cd %s; nohup ./patchmgr -ibswitches %s -upgrade -ibswitch_precheck -force"
            elif aTask == self.TASK_PATCH:
                _patchmgr_cmd = "cd %s; nohup ./patchmgr -ibswitches %s -upgrade -force"
            elif aTask == self.TASK_ROLLBACK_PREREQ_CHECK:
                _patchmgr_cmd = "cd %s; nohup ./patchmgr -ibswitches %s -downgrade -ibswitch_precheck -force"
            elif aTask == self.TASK_ROLLBACK:
                _patchmgr_cmd = "cd %s; nohup ./patchmgr -ibswitches %s -downgrade -force" 

            # use log_dir option so that all logs generates at definite location 
            _patchmgr_cmd += " -log_dir %s"

            # For the patchmgr command to run in background
            _patchmgr_cmd+= ' </dev/null > %s/PatchmgrConsole.out 2>&1 &'

            # Update status
            self.mUpdatePatchStatus(True, self.STEP_RUN_PATCH_IBSWITCH)

        # Run patchmgr
        _patchmgr_cmd = _patchmgr_cmd % (
            self.__cells_ibswitches_patch_base_after_unzip,
            _input_file_name, self.__patchmgr_log_path_on_launch_node,
            self.__patchmgr_log_path_on_launch_node)
    
        #run patchmgr
        self.mExecutePatchmgrCmd(self.__dom0_to_patch_cells_ibswitches, self.__patchmgr_log_path_on_launch_node, _patchmgr_cmd)
        # Monitor console log
        _exit_code = int(self.mReadPatchmgrConsoleOut(self.__dom0_to_patch_cells_ibswitches, self.__patchmgr_log_path_on_launch_node))

        ebLogInfo('Patchmgr exit_code = %d' % _exit_code)

        return _exit_code

    def _mManageRPMs(self, aRPMList, aNode=None, aNodeConnection=None,
                     aAction='install'):
        """
        Function to add or remove a set of RPMs.

        Currently used to remove the krb5-workstation. 
        It is installated by ExaCloud for the BDCS and stuff. 
        It  hinders the patching. So the idea is to remove it before the 
        patching and install it again after patching.

        TODO:  to be removed once we have the 
        functionality that allows one to extend patching by means
        of pre and post clustom scripts execution per each patch
        action for these type of tweaks.
        """

        _ret = True
        _cmd_template = ""
        _node = None

        if aAction in 'install':
            _cmd_template = "rpm -Uvh %s;"

        if aAction in 'remove':
           _cmd_template = "rpm -ev %s;"
        
        if not aNodeConnection:
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=aNode)
        else:
            _node=aNodeConnection
 
        for rpm in aRPMList:
            _cmd = _cmd_template % rpm 
            _in, _out, _err = _node.mExecuteCmd(_cmd)
            _output = _out.readlines()
            if _output:
                ebLogInfo("\n".join(_output))
            else:
                _errors = _err.readlines()
                ebLogError("\n".join(_errors))
                _ret = False
    
        if not aNodeConnection:
            _node.mDisconnect()

        return _ret

    def _mPatchDom0Us(self, aTaskType, aOperationStyle, aBackupMode, aRollback):
        """
        Runs the dom[0U]s patch(upgrade)/rollback(downgrade) operation in 
          rolling or non-rolling mode.
        Returns 0 if the pre-checks, patch, and post-checks run fine.
        Returns the patchmgr exit code (usualy 1) if there were any errors 
          running patchmgr.
        Returns DOM[0U]_POSTCHECKS_FAILED if there were problems running 
          post-checks.
        Returns NO_ACTION_REQUIRED if no dom0s were patched or rolled back

        NOTE : ExaData expects one to install user RPMs only after 
               exadata-sun-vm-computenode-exact RPM was removed. Else, patching
               may fail. At present following RPMs are user installed ones.
                  krb5-workstation.x86_64
                  libxenstore.x86_64
                  dbaastools_exa.x86_64
                  perl-JSON.noarch
                  dnsmasq.x86_64
                  cx_Oracle.x86_64

        TODO : In order to handle user installed RPMs and what not
               It will be better to create a configuration parameter to 
               control those and just pass those. 
               It may be something in its own conf file or in exabox.conf:
               "exadata_patch_domu_options", "exadata_patch_cell_options" etc..
        """

        if (aTaskType == self.PATCH_DOM0):
            _node_to_patch_nodes = self.__dom0_to_patch_dom0
            _node_to_patch_initial_node = self.__dom0_to_patch_initial_dom0
            _nodes_to_patch_except_initial = list(set(self.__all_dom0s) - 
                                              set([self.__dom0_to_patch_dom0]))
            _initial_node_list = [self.__dom0_to_patch_dom0]
            _all_nodes  = self.__all_dom0s
            
        if (aTaskType == self.PATCH_DOMU):
            _node_to_patch_nodes = self.__domu_to_patch_domus
            _node_to_patch_initial_node = self.__domu_to_patch_initial_domu
            _nodes_to_patch_except_initial = list(set(self.__all_domus) - 
                                              set([self.__domu_to_patch_domus]))
            _initial_node_list = [self.__domu_to_patch_domus]
            _all_nodes  = self.__all_domus

        if not _node_to_patch_nodes and _node_to_patch_initial_node:
            raise ebLogError(aTaskType.upper + 
                             " patching is unavailable, " + aTaskType.upper +
                             " patch files" +
                             " were not provided at initialization")

        ebLogDebug('_node_to_patch_nodes = %s, _node_to_patch_initial_node = %s' %(
                   _node_to_patch_nodes, _node_to_patch_initial_node))
        ebLogDebug('_nodes_to_patch_except_initial = %s, _initial_node_list= %s' %(
                   str(_nodes_to_patch_except_initial), str(_initial_node_list)))

        #Update status
        self.mUpdatePatchStatus(True, self.STEP_FILTER_NODES+'_'+aTaskType)

        _dont_rollback = False
        #get the list of the dom0s that actually requiere patching
        _nodes_that_requiere_patching = []

        for _node in _all_nodes:
            if not aRollback:
                if (self.__clupatchcheck.mCheckTargetVersion(_node, 
                            aTaskType, self.__target_version) >= 0):
                    ebLogInfo("%s [%s] is already at the requested (or higher) version %s"
                              % (aTaskType.upper(), _node, 
                                 self.__target_version))
                    continue
            if aRollback:
                if self._mRollbackIsAvailable(_node):
                    #if the dbnode is at a lower version than the requested 
                    # version, dont attempt to rollback.
                    # This is to stop doing a rollback after a rollback 
                    # (ie: you can/should only rollback once)
                    # after a sucessfull upgrade
                    if (self.__clupatchcheck.mCheckTargetVersion(_node, 
                                    aTaskType, self.__target_version) < 0):
                        ebLogInfo("%s [%s] cannot be rolled back, its version is lower than the target version" % (
                                  aTaskType.upper(),_node))
                        continue

                    #Bug:23499655 Block Dom0 rollback if fresh service created after patch
                    if (aTaskType == self.PATCH_DOM0):
                        if self.EXACLOUD_DO_DOM0_ROLLBACK_EVEN_IF_DOMU_MODIFIED_POST_PATCH:
                            ebLogInfo("Skipping creation/modification time check on for domU's on %s" % (_node))
                        #check to make sure no new domU were created or modified after a previous dom0 patch
                        else:
                            _dom0_node = exaBoxNode(get_gcontext())
                            _dom0_node.mConnect(aHost=_node)
                            _i, _o, _e = _dom0_node.mExecuteCmd("date '+%s' -d \"`imageinfo -activated`\"")
                            _dom0_activation_date = self.mFormatOut(_o).strip()
    
                            _i, _o, _e = _dom0_node.mExecuteCmd(r"stat -c '%Y' /EXAVMIMAGES/GuestImages/*/vm.cfg | sort -n | tail -n 1")
                            _oldest_domU_modification_date = self.mFormatOut(_o).strip()
    
                            _dom0_node.mDisconnect()
    
                            ebLogInfo("Dom0 activation date: '%s' latest domU vm.cfg modification date: '%s'"
                                      % (_dom0_activation_date, _oldest_domU_modification_date))
                            try:
                                _oldest_domU_modification_date = int(_oldest_domU_modification_date)
                                _dom0_activation_date = int(_dom0_activation_date)
                            except (ValueError, TypeError) as e:
                                ebLogInfo(("No vm.cfg were detected or errors parsing vm.cfg modification time to int for "
                                           "domU on dom0: '%s'. This check will be skipped for this dom0. Exception: %s")
                                           % (_node, str(e)))
                                _oldest_domU_modification_date, _dom0_activation_date = 0, 0
    
                            if _oldest_domU_modification_date > _dom0_activation_date:
                                ebLogError("one or more domUs were created (or had vm.cfg settings modified) after %s has "
                                           "been patched. unable to rollback any dom0." % (_node) )
                                self.mAddError(_node, 1012)
                                #even though we can just return here and stop the rollback action, lets check the next dom0
                                #  for a more complete error report
                                _dont_rollback = True
                                continue

                else: #rollback is not available, just skip it
                    ebLogInfo("%s [%s] cannot be rolled back, rollback is not available" % (
                              aTaskType, _node))
                    continue
            _nodes_that_requiere_patching.append(_node)

        if _dont_rollback:
            return self.DOM0_ROLLBACK_NOT_ALLOWED

        if len(_nodes_that_requiere_patching) == 0:
            return self.NO_ACTION_REQUIRED

        #  contains tuples of the form [(patcher_node, [nodes_to_patch]), .. ]
        _node_patcher_and_node_patch_list  = [] 

        #if the dom[0U] that patches all other dom[0U]s (except itself) requieres
        # patching, then add it and add the node that will patch it to the list
        if _node_to_patch_nodes in _nodes_that_requiere_patching:
            _node_patcher_and_node_patch_list.append(
                (_node_to_patch_initial_node, [_node_to_patch_nodes]))
            _nodes_that_requiere_patching.remove(_node_to_patch_nodes)

        #if any more dom[0U]s requiere patching, use the dom[0U] designated to 
        #patch all other dom[0U]
        if _nodes_that_requiere_patching:
            _node_patcher_and_node_patch_list.append(
                (_node_to_patch_nodes, _nodes_that_requiere_patching))

        _rc = 0

        # TODO: This is a one time hack. When we implement the extensible
        #       patching infrastructure which allows one to run custom
        #       pre and post patching actions by means of placing the
        #       scripts in right dirs (pre or post) in lexically ordered
        #       manner. Till then we use this. ie. remove krb5-workstation
        if (not aRollback and aTaskType == self.PATCH_DOMU):
            for _node_patcher, _node_patch_list in _node_patcher_and_node_patch_list:
                for _domu in _node_patch_list:
                    self._mManageRPMs(aNode=_domu, aNodeConnection=None, 
                                     aRPMList=['krb5-workstation.x86_64'], 
                                     aAction='remove')
    

        if aOperationStyle == self.OP_STYLE_ROLLING:
            _rc = self._mPatchDom0UsRolling(
                    aTaskType,
                    aBackupMode,
                    aNodePatcherAndPatchList=_node_patcher_and_node_patch_list,
                    aRollback=aRollback)
        elif aOperationStyle == self.OP_STYLE_NON_ROLLING:
            _rc = self._mPatchDom0UsNonrolling(
                    aTaskType,
                    aBackupMode,
                    aNodePatcherAndPatchList=_node_patcher_and_node_patch_list,
                    aRollback=aRollback)
        else:
            _msg = "%s patching operation style [%s] not recognized or unsupported" % (aTaskType.upper(), aOperationStyle)
            ebLogError(_msg)
            raise Exception(_msg)

        return _rc

    def _mPatchDom0UsNonrolling(self, aTaskType, aBackupMode,
                                aNodePatcherAndPatchList, aRollback):
        """
        patch dom[0U]s in non-rolling fashion
        """

        # List of launch nodes to update patch state metadata
        _launch_nodes = []

        _callbacks = [self.mReadCallback, None, self.mErrorCallback, None]
        _rc = 0

        if aRollback:
            _patch_cmd_template = ("cd %s; nohup ./patchmgr -dbnodes %s "
                                           "-rollback")
            aTask = self.TASK_ROLLBACK
        else:
            _patch_cmd_template = ("cd %s; nohup ./patchmgr -dbnodes %s "
                                           "-upgrade "
                                           "-iso_repo %s "
                                           "-target_version %s ")
            aTask = self.TASK_PATCH

        _patch_cmd_template += " -log_dir %s"

        # Default option with patchmgr on dom0U is to take backup. If
        # specified not to take backup, then do the same for upgrade only. 
        if aBackupMode == ebCluPatchControl.OP_BACKUPMODE_NO and not aRollback:
            _patch_cmd_template += " -nobackup"

        # check for additional option if any and add to patchmgr cmd
        _patch_cmd_template = self._mCheckAdditionalOptions(_patch_cmd_template, aTaskType, aTask)

        # For the patchmgr command to run in background
        _patch_cmd_template += ' </dev/null > %s/PatchmgrConsole.out 2>&1 &'

        if (aTaskType == self.PATCH_DOM0):
            _node_to_patch_nodes = self.__dom0_to_patch_dom0
            _node_to_patch_initial_node = self.__dom0_to_patch_initial_dom0
            _nodes_to_patch_except_initial = list(set(self.__all_dom0s) - 
                                              set([self.__dom0_to_patch_dom0]))
            _initial_node_list = [self.__dom0_to_patch_dom0]
            _all_nodes  = self.__all_dom0s
            _cns_string = self.CNS_DOM0_PATCHER
            _node_patch_base_after_unzip = self.__dom0_patch_base_after_unzip
            _node_patch_zip2_name = self.__dom0_patch_zip2_name
            self._mPreDom0UPatchCheck(_all_nodes)
            
            _launch_nodes = [self.__dom0_to_patch_dom0, self.__dom0_to_patch_initial_dom0]

        if (aTaskType == self.PATCH_DOMU):
            _node_to_patch_nodes = self.__domu_to_patch_domus
            _node_to_patch_initial_node = self.__domu_to_patch_initial_domu
            _nodes_to_patch_except_initial = list(set(self.__all_domus) - 
                                              set([self.__domu_to_patch_domus]))
            _initial_node_list = [self.__domu_to_patch_domus]
            _all_nodes  = self.__all_domus
            _cns_string = self.CNS_DOMU_PATCHER
            _node_patch_base_after_unzip = self.__domu_patch_base_after_unzip
            _node_patch_zip2_name = self.__domu_patch_zip2_name

            _launch_nodes = [self.__domu_to_patch_domus, self.__domu_to_patch_initial_domu]

        _node_stat_index = 0

        if (len(aNodePatcherAndPatchList) == 1 and 
            aNodePatcherAndPatchList[0][0] == _node_to_patch_nodes):
            _node_stat_index = 1

        # Set log dir with master request id tagged. Once upgrade is completed, 
        # we would move and append with node name.
        self.__patchmgr_log_path_on_launch_node = (
                _node_patch_base_after_unzip + "patchmgr_log_" + 
                self.mGetMasterReqId())

        _single_node_upgrade = False
        _single_node_name = None
        for _node_patcher, _node_patch_list in aNodePatcherAndPatchList:
            _node_stat_index +=1

            # Check for Single Node Name Upgrade only in Dom0 mode and update _node_patch_list accordingly
            # Example with Half Rack 4 dom0 aNodePatcherAndPatchList = [("n2", ["n1"]) , ("n1", ["n2","n3","n4"])]
            # Example with Quad Rack 2 dom0 aNodePatcherAndPatchList = [("n2", ["n1"]) , ("n1", ["n2"])]
            if self.mCheckSingleNodeUpgradeEnable():
                _single_node_name = self.mGetSingleNodeUpgradeName()
                if not _single_node_name:
                    ebLogError("Single Node Name not specified")
                    _rc = ebError(0x0610)

                ebLogInfo("Requested single node patch for dom0 %s in non rolling style." % _single_node_name)
                if _single_node_name in _node_patch_list:
                    _single_node_upgrade = True
                    # Modify node_patch_list to have that node only
                    _node_patch_list = [_single_node_name]
                else:
                    continue

            _dom0 = exaBoxNode(get_gcontext())
            _dom0.mConnect(aHost=_node_patcher)
            ebLogInfo("%s %s will be used to patch %s non-rolling" % (
                      aTaskType.upper(), _node_patcher, str(_node_patch_list)))

            # update with current node patcher which will be used in CNS monitor
            _node_patch_progress = os.path.join(self.__log_path, _cns_string)
            with open(_node_patch_progress, "w") as write_nodestat:
                write_nodestat.write("%s:%s" %(_node_patcher, 
                    self.__patchmgr_log_path_on_launch_node))

            # Update with launch node in the patch metadata json 
            mUpdateMetadataLaunchNode(_launch_nodes, self.__metadata_json_file, aTaskType, _node_patcher)

            #gather the data which we will need for the post patch checks
            _domU_up_per_dom0 = {} #  key is Dom0, value is list of DomU
            #  key is Dom[0U], value is version prior to patching
            _node_prepatch_version = {} 
            '''
             The below list captures the status of CRS on all DomU passed
             as per the iteration.
            '''
            self.__crs_config_enable_stat = {}
            for _node_to_patch in _node_patch_list:
                # Update status
                self.mUpdatePatchStatus(True, 
                            (self.STEP_GATHER_NODE_DATA+'_'
                            +aTaskType+'_[%d]' % _node_stat_index),
                            _node_to_patch)

                '''
                 Below code snippet validates if CRS is enabled or disabled.
                 if CRS is enabled it would validate if CRS is ONLINE before
                 the start of patch or rollback activity.
                '''
                if (aTaskType == self.PATCH_DOMU):
                    self.__crs_config_enable_stat[_node_to_patch] = self.__clupatchcheck.mCheckCrsIsEnabled(_node_to_patch)
                    if self.__clupatchcheck.mCheckCrsIsUp(_node_to_patch):
                        ebLogDebug("CRS services is up during '%s' precheck on domU : %s" \
                                    % (self.__op_style,_node_to_patch))
                    else:
                        ebLogDebug("CRS services is down during '%s' precheck on domU  : %s" \
                                    % (self.__op_style,_node_to_patch))

                if (aTaskType == self.PATCH_DOM0):
                    _domU_listed_by_xm_list = \
                        self.__clupatchcheck.mCheckVMsUp(_node_to_patch)
                    _domU_up_per_dom0[_node_to_patch] = _domU_listed_by_xm_list
                    ebLogInfo("Dom0 %s has %s domU up" % (_node_to_patch, 
                               str(_domU_listed_by_xm_list)))
    
                _pre_patch_version = self.__clupatchcheck.mCheckTargetVersion(
                                          _node_to_patch, aTaskType)
                _node_prepatch_version[_node_to_patch] = _pre_patch_version
                ebLogInfo("%s %s is at version %s" % (aTaskType.upper(),
                            _node_to_patch, _pre_patch_version))
            # end of for

            _input_file = self._mCreateNodesFile(
                            _node_patch_base_after_unzip, 
                            _node_patcher, _node_patch_list)
            _input_file_name = _input_file.split("/")[-1]

            if aRollback:
                _patch_cmd = _patch_cmd_template % (
                    _node_patch_base_after_unzip, _input_file_name,
                    self.__patchmgr_log_path_on_launch_node,
                    self.__patchmgr_log_path_on_launch_node)
            else:
                _patch_cmd = _patch_cmd_template % (
                    _node_patch_base_after_unzip, _input_file_name,
                    _node_patch_zip2_name, self.__target_version,
                    self.__patchmgr_log_path_on_launch_node,
                    self.__patchmgr_log_path_on_launch_node)

            # Update status
            if (aTaskType == self.PATCH_DOM0):
                self.mUpdatePatchStatus(True, 
                   (self.STEP_SHUTDOWN_VMS+'_'+self.PATCH_DOM0+'_[%d]' % (
                        _node_stat_index)))
    
                #shutdown all of the domU on all the dom0 that will be patched 
                #or else patchmgr will complain
                for _dom0_to_patch in _node_patch_list:
                    self.__clupatchcheck.mManageVMs(_dom0_to_patch, 
                        _domU_up_per_dom0[_dom0_to_patch], 'shutdown')

            #update patch status with the amount of dom0s we are patching
            if (aTaskType == self.PATCH_DOM0):
                if _node_stat_index == 1:
                    self.mUpdatePatchStatus(True, 
                                        self.STEP_RUN_PATCH_SECOND_DOM0+'_[1]',
                                        _node_patcher)
                else:
                    self.mUpdatePatchStatus(True, 
                          self.STEP_RUN_PATCH_DOM0+'_[%d]' % _node_stat_index)
            elif(aTaskType == self.PATCH_DOMU):
                if _node_stat_index == 1:
                    self.mUpdatePatchStatus(True, 
                                        self.STEP_RUN_PATCH_SECOND_DOMU+'_[1]',
                                        _node_patcher)
                else:
                    self.mUpdatePatchStatus(True, 
                          self.STEP_RUN_PATCH_DOMU+'_[%d]' % _node_stat_index)

            # Run exacloud plugins on each node before patchmgr cmd
            if (self.__run_user_plugins and aTaskType == self.PATCH_DOM0):
                ebLogInfo("Running dom0 pre exacloud plugins on %s" % _node_patch_list)
                for _dom0_to_patch in _node_patch_list:
                    _read_patch_state = mGetPatchStatesForNode(_launch_nodes, self.__metadata_json_file,
                                                               _dom0_to_patch, self.PRE_PATCH) 
                    ebLogInfo("Dom0 pre plugin patch status: %s" % _read_patch_state)
                    if not _read_patch_state:
                        _rc = self.DOM0_PRECHECKS_FAILED
                        ebLogError("Invalid patch state found during non-rolling patch = %s" % _read_patch_state)
                        break

                    # If anything left at last run of pre plugin and patchmgr is still 
                    # running, then re-run plugin too. 
                    if _read_patch_state in [self.PATCH_PENDING, self.PATCH_RUNNING]: 
                        if _read_patch_state == self.PATCH_PENDING:
                            # Update patch metadata status progress for pre plugins
                            mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _dom0_to_patch,
                                                 self.__metadata_json_file, self.PRE_PATCH, self.PATCH_RUNNING)

                        if not self._mPrePostPluginsRun(_dom0_to_patch,
                                                 self.PATCH_DOM0, self.PRE_PATCH,
                                                 aRollback = aRollback):
                            mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _dom0_to_patch,
                                                 self.__metadata_json_file, self.PRE_PATCH, self.PATCH_FAILED)
                            _rc = self.DOM0_PRECHECKS_FAILED
                            break

                        mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _dom0_to_patch,
                                             self.__metadata_json_file, self.PRE_PATCH, self.PATCH_COMPLETED)
                    elif _read_patch_state == self.PATCH_FAILED: 
                        _rc = self.DOM0_PRECHECKS_FAILED
                        break
                    elif _read_patch_state != self.PATCH_COMPLETED: 
                        _rc = self.DOM0_PRECHECKS_FAILED
                        ebLogInfo("_read_patch_state (rolling): %s" % _read_patch_state)
                        break

            elif (self.__run_user_plugins and aTaskType == self.PATCH_DOMU):
                ebLogInfo("Running domu pre exacloud plugins on %s" % _node_patch_list)
                for _domu_to_patch in _node_patch_list:
                    _read_patch_state = mGetPatchStatesForNode(_launch_nodes, self.__metadata_json_file,
                                                               _domu_to_patch, self.PRE_PATCH) 
                    ebLogInfo("DomU pre plugin patch status: %s" % _read_patch_state)
                    if not _read_patch_state:
                        _rc = self.DOMU_PRECHECKS_FAILED
                        ebLogError("Invalid patch state found during non-rolling patch = %s" % _read_patch_state)
                        break

                    # If anything left at last run of pre plugin and patchmgr is still 
                    # running, then re-run plugin too. 
                    if _read_patch_state in [self.PATCH_PENDING, self.PATCH_RUNNING]: 
                        if _read_patch_state == self.PATCH_PENDING:
                            # Update patch metadata status progress for pre plugins
                            mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _domu_to_patch,
                                                 self.__metadata_json_file, self.PRE_PATCH, self.PATCH_RUNNING)
                        if not self._mPrePostPluginsRun(_domu_to_patch,
                                                 self.PATCH_DOMU, self.PRE_PATCH,
                                                 aRollback = aRollback):
                            mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _domu_to_patch,
                                                 self.__metadata_json_file, self.PRE_PATCH, self.PATCH_FAILED)
                            _rc = self.DOMU_PRECHECKS_FAILED
                            break

                        mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _domu_to_patch,
                                             self.__metadata_json_file, self.PRE_PATCH, self.PATCH_COMPLETED)
                    elif _read_patch_state == self.PATCH_FAILED: 
                        _rc = self.DOMU_PRECHECKS_FAILED
                        break

            if _rc != 0:
                _patch_failed_message = ("Error running pre exacloud plugins. Return code was %s. Errors"
                                         " on screen and in logs") % (str(_rc))
                ebLogError(_patch_failed_message)
                _dom0.mDisconnect()
                break

            # Run patch command
            # If there are no patchmgr sessions running, then run patchmgr command
            _pacthmgr_session_exit = 1
            _patchmgr_active_node = None

            _pacthmgr_session_exit, _patchmgr_active_node = self.mCheckPatchmgrSessionExistence(self.__patchmgr_log_path_on_launch_node, aLaunchNode = None, aNodeList = _all_nodes)

            if _pacthmgr_session_exit == 0: # No patchmgr session found in any of the nodes, so re-execute 
                                            # with same launch/_node_patcher
                # Update patch metadata status progress for patchmgr 
                for _n in _node_patch_list:
                    mUpdatePatchMetadata(aTaskType, _launch_nodes, _n,
                                         self.__metadata_json_file, self.PATCH_MGR, self.PATCH_RUNNING)
                self.mExecutePatchmgrCmd(_node_patcher, self.__patchmgr_log_path_on_launch_node, _patch_cmd)
                # Monitor console log
                _rc = int(self.mReadPatchmgrConsoleOut(_node_patcher, self.__patchmgr_log_path_on_launch_node))
            else:
                # TODO: We need to handle patch non-retry in future. Time being we are forcibly stopping.
                if not self.mPatchRequestRetried():
                    ebLogError('mPatchDom0UsNonrolling: Found older patchmgr session. Forcibly terminating patching request')
                    _rc = 1
                    return _rc 

                # Already patchmgr is running, just monitor patchmgr console on the node.
                ebLogInfo("Patchmanager session exists and return code = %s, Patchmgr session active node = %s" % (_pacthmgr_session_exit, _patchmgr_active_node))
                _rc = int(self.mReadPatchmgrConsoleOut(_patchmgr_active_node, self.__patchmgr_log_path_on_launch_node))
                _node_patcher = _patchmgr_active_node

            # Update patch metadata progress status for patchmgr status
            _patch_metadata_status = ""
            if _rc != 0:
                _patch_metadata_status = self.PATCH_FAILED
            else:
                _patch_metadata_status = self.PATCH_COMPLETED 

            for _n in _node_patch_list:
                mUpdatePatchMetadata(aTaskType, _launch_nodes, _n,
                                     self.__metadata_json_file, self.PATCH_MGR, _patch_metadata_status)

            _dom0.mConnect(aHost=_node_patcher)
            self.mUpdatePatchStatus(True, 
                (self.STEP_CLEAN_ENV+'_'+aTaskType+'_[%d]' % (_node_stat_index)))

            # Extract and post notification (CNS), if anything left
            # out on dom0[u], before it shift to initial dom0[u]
            ebLogDebug("Before instant collect of patching notification by patch process")
            self.mMonitorPatchReqForCNS(
                               aCollectCnsOnce = self.__instant_collect_of_cns)
            ebLogDebug("After instant collect of patching notification by patch process")

            # Get the logs, diags and so on
            _patch_log = str(
                self._mGetDom0FileCode(_node_patcher,
                                       self.__patchmgr_log_path_on_launch_node))
            self._mGetPatchMgrOutFiles(_node_patcher,
                                       self.__patchmgr_log_path_on_launch_node,
                                       _patch_log)
            self._mGetPatchMgrDiagFiles(_node_patcher, 
                                        aTaskType,
                                        _node_patch_list,
                                        self.__patchmgr_log_path_on_launch_node)

            self._mGetPatchMgrMiscLogFiles(_node_patcher,
                                           self.__patchmgr_log_path_on_launch_node)

            _dom0.mExecuteCmdLog("rm -f %s" % _input_file)

            # Moving log_dir to log_dir_<node_patched>, before starting another one
            _dom0.mExecuteCmdLog("mv -f %s %s_%s" % (self.__patchmgr_log_path_on_launch_node, 
                                                     self.__patchmgr_log_path_on_launch_node, 
                                                     _node_patcher.split(".")[0]))

            if _rc != 0:
                _patch_failed_message = ("Error patching one of %s using %s to patch it. return code was %s. Errors"
                                         " on screen and in logs") % (str(_node_patch_list), _node_patcher, str(_rc))
                ebLogError(_patch_failed_message)
                _dom0.mDisconnect()
                break

            #post checks on each node
            _post_patch_failed_nodes = []
            if (aTaskType in [ self.PATCH_DOM0 ] ):
                # Update status
                self.mUpdatePatchStatus(True,
                    (self.STEP_POSTCHECKS+'_'+self.PATCH_DOM0+'_[%d]' % (
                        _node_stat_index)))

                for _dom0_to_patch in _node_patch_list:
                    if not self._mPostDom0PatchCheck(aDom0=_dom0_to_patch,
                            aCellAlertLogMark=None,
                            aDomUList=_domU_up_per_dom0[_dom0_to_patch],
                            aPrePatchVersion=_node_prepatch_version[_dom0_to_patch],
                            aPostPatchTargetVersion=self.__target_version,
                            aRollback=aRollback):
                        _post_patch_failed_nodes.append(_dom0_to_patch)
                        _rc = self.DOM0_POSTCHECKS_FAILED
            elif (aTaskType in [ self.PATCH_DOMU ] ):
                # Update status
                self.mUpdatePatchStatus(True,
                    (self.STEP_POSTCHECKS+'_'+self.PATCH_DOMU+'_[%d]' % (
                        _node_stat_index)))

                for _domu_to_patch in _node_patch_list:
                    if not self._mPostDomUPatchCheck(aDomU=_domu_to_patch,
                            aPrePatchVersion=_node_prepatch_version[_domu_to_patch],
                            aPostPatchTargetVersion=self.__target_version,
                            aRollback=aRollback):
                        _post_patch_failed_nodes.append(_domu_to_patch)
                        _rc = self.DOMU_POSTCHECKS_FAILED
    
            if _post_patch_failed_nodes:
                _patch_failed_message = ("%s %s patching succeded, but post-patch checks failed. Return code was = %s "
                                         % (aTaskType.upper(),
                                            str(_post_patch_failed_nodes), str(_rc)))
                ebLogError(_patch_failed_message)
                _dom0.mDisconnect()
                break

            # Run exacloud plugins on each node after patchmgr cmd
            if (self.__run_user_plugins and aTaskType == self.PATCH_DOM0):
                ebLogInfo("Running dom0 post exacloud plugins on %s" % _node_patch_list)
                for _dom0_to_patch in _node_patch_list:
                    # Update patch metadata status progress for pre plugins
                    mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _dom0_to_patch,
                                         self.__metadata_json_file, self.POST_PATCH, self.PATCH_RUNNING)
                    if not self._mPrePostPluginsRun(_dom0_to_patch,
                                             self.PATCH_DOM0, self.POST_PATCH,
                                             aRollback = aRollback):
                        mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _dom0_to_patch,
                                             self.__metadata_json_file, self.POST_PATCH, self.PATCH_FAILED)
                        _rc = self.DOM0_POSTCHECKS_FAILED
                        break

                    mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _dom0_to_patch,
                                         self.__metadata_json_file, self.POST_PATCH, self.PATCH_COMPLETED)
            elif (self.__run_user_plugins and aTaskType == self.PATCH_DOMU):
                ebLogInfo("Running domu post exacloud plugins on %s" % _node_patch_list)
                for _domu_to_patch in _node_patch_list:
                    mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _domu_to_patch,
                                         self.__metadata_json_file, self.POST_PATCH, self.PATCH_RUNNING)
                    if not self._mPrePostPluginsRun(_domu_to_patch,
                                             self.PATCH_DOMU, self.POST_PATCH,
                                             aRollback = aRollback):
                        mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _domu_to_patch,
                                             self.__metadata_json_file, self.POST_PATCH, self.PATCH_FAILED)
                        _rc = self.DOMU_POSTCHECKS_FAILED
                        break

                    mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _domu_to_patch,
                                         self.__metadata_json_file, self.POST_PATCH, self.PATCH_COMPLETED)

            if _rc != 0:
                _patch_failed_message = ("Patching succeded, but error running post exacloud plugins. Return code was %s. Errors"
                                         " on screen and in logs") % (str(_rc))
                ebLogError(_patch_failed_message)

            _dom0.mDisconnect()

            #if return code of previous patch operation is non-zero, 
            #we had an issue so dont do any more patching
            if _rc != 0:
                break

            # In case of a single node upgrade for DOM0, just perform the single node upgrade and exit the loop
            if _single_node_upgrade:
                break

        # Capture return payload if no nodes attempted to upgrade. This is
        # required for updating ecra rack status to previous status in ecra layer
        if not _single_node_upgrade:
            self.mAddError(self.mGetRackName(), 1017)

        return _rc

    def _mPatchDom0UsRolling(self, aTaskType, aBackupMode, aNodePatcherAndPatchList, 
                            aRollback):
        """
        Patch/rollback rolling is handled by us 
        (ie: we dont rely on  patchmgr with rolling option) since we need to
        to some checks before and after each patch/rollback on every dom[0U].

        If patching any dom0 fails the rest of the (not yet patched) dom[0U]s 
        will not be attempted to be patched.
        """

        _callbacks = [self.mReadCallback, None, self.mErrorCallback, None]

        # List of launch nodes to update patch state metadata
        _launch_nodes = []
        
        if aRollback:
            _patch_cmd_template = ("cd %s; nohup ./patchmgr -dbnodes %s -rollback "
                                                     "-rolling")
            aTask = self.TASK_ROLLBACK
        else:
            _patch_cmd_template = ("cd %s; nohup ./patchmgr -dbnodes %s -upgrade "
                                              "-iso_repo %s "
                                              "-target_version %s -rolling")
            aTask = self.TASK_PATCH

        _patch_cmd_template += " -log_dir %s"
       
        # Default option with patchmgr on dom0U is to take backup. If
        # specified not to take backup, then do the same for upgrade only. 
        if aBackupMode == ebCluPatchControl.OP_BACKUPMODE_NO and not aRollback:
            _patch_cmd_template += " -nobackup"

        # check for additional option if any and add to patchmgr cmd
        _patch_cmd_template = self._mCheckAdditionalOptions(_patch_cmd_template, aTaskType, aTask)

        # For the patchmgr command to run in background
        _patch_cmd_template += ' </dev/null > %s/PatchmgrConsole.out 2>&1 &'

        _nodes_successfuly_patched = []
        _node_patch_failed = None
        _patch_failed_message = ""
        _rc = 0
        _node_stat_index = 0
        _round = 0
        _count_nodes = 0
        _num_nodes_to_patch = 0
        _nodes_attempted_to_upgrade_flag = False 

        if (aTaskType == self.PATCH_DOM0):
            _node_to_patch_nodes = self.__dom0_to_patch_dom0
            _node_to_patch_initial_node = self.__dom0_to_patch_initial_dom0
            _nodes_to_patch_except_initial = list(set(self.__all_dom0s) - 
                                              set([self.__dom0_to_patch_dom0]))
            _initial_node_list = [self.__dom0_to_patch_dom0]
            _all_nodes  = self.__all_dom0s
            _cns_string = self.CNS_DOM0_PATCHER
            _node_patch_base_after_unzip = self.__dom0_patch_base_after_unzip
            _node_patch_zip2_name = self.__dom0_patch_zip2_name
            _nodes_not_patched = list(self.__all_dom0s)
            self._mPreDom0UPatchCheck(_all_nodes)

            _launch_nodes = [self.__dom0_to_patch_dom0, self.__dom0_to_patch_initial_dom0] 
            
        if (aTaskType == self.PATCH_DOMU):
            _node_to_patch_nodes = self.__domu_to_patch_domus
            _node_to_patch_initial_node = self.__domu_to_patch_initial_domu
            _nodes_to_patch_except_initial = list(set(self.__all_domus) - 
                                              set([self.__domu_to_patch_domus]))
            _initial_node_list = [self.__domu_to_patch_domus]
            _all_nodes  = self.__all_domus
            _cns_string = self.CNS_DOMU_PATCHER
            _node_patch_base_after_unzip = self.__domu_patch_base_after_unzip
            _node_patch_zip2_name = self.__domu_patch_zip2_name
            _nodes_not_patched = list(self.__all_domus)

            _launch_nodes = [self.__domu_to_patch_domus, self.__domu_to_patch_initial_domu] 

        if (len(aNodePatcherAndPatchList) == 1 and 
            aNodePatcherAndPatchList[0][0] == _node_to_patch_nodes):
            _node_stat_index = 1
            _round = 1

        for _, _l in aNodePatcherAndPatchList:
            _num_nodes_to_patch+=len(_l)

        for _node_patcher, _node_patch_list in aNodePatcherAndPatchList:
            _round += 1

            # We are not suppose to continue further node upgrade if we found 
            # any failure
            if _rc:
                ebLogError("Failure detected in the earlier node upgrade. Return code = %s" % _rc)
                break
      
            ebLogInfo("%s %s will be used to patch %s rolling" % (
                      aTaskType.upper(), _node_patcher, str(_node_patch_list)))

            # Set log dir with master request id tagged. Once upgrade is completed, 
            # we would move and append with node name.
            self.__patchmgr_log_path_on_launch_node = (
                _node_patch_base_after_unzip + "patchmgr_log_" + 
                self.mGetMasterReqId())

            '''
             The below __crs_config_enable_stat captures the status of CRS on 
             all DomU passed as per the iteration.
            '''
            self.__crs_config_enable_stat = {}

            # Update with launch node in the patch metadata json
            mUpdateMetadataLaunchNode(_launch_nodes, self.__metadata_json_file, aTaskType, _node_patcher)

            for _node_to_patch in _node_patch_list:
                _count_nodes+=1
                _node_stat_index += 1
                _comment = "[%s/%s]_%s" % (_count_nodes, _num_nodes_to_patch,
                                           _node_to_patch)

                '''
                 Below code snippet validates if CRS is enabled or disabled.
                 if CRS is enabled it would validate if CRS is ONLINE before
                 the start of patch or rollback activity.
                '''
                if (aTaskType == self.PATCH_DOMU):
                    self.__crs_config_enable_stat[_node_to_patch] = self.__clupatchcheck.mCheckCrsIsEnabled(_node_to_patch)
                    if self.__clupatchcheck.mCheckCrsIsUp(_node_to_patch):
                        ebLogDebug("CRS services is up during '%s' precheck on domU : %s" \
                                    % (self.__op_style, _node_to_patch))
                    else:
                        ebLogDebug("CRS services is down during '%s' precheck on domU  : %s" \
                                    % (self.__op_style,_node_to_patch))

                if self.mCheckSingleNodeUpgradeEnable():
                    ebLogInfo("Requested single node patch.")
                    _single_node_name = self.mGetSingleNodeUpgradeName()
                    if _single_node_name and _single_node_name != _node_to_patch:
                        ebLogInfo("Skipping node '%s' to patch. Actual requested node '%s'." % \
                                  (_node_to_patch, _single_node_name))
                        continue
                    else:
                        # Indicates that it's attempting to ugprade single node 
                        _nodes_attempted_to_upgrade_flag = True 

                # Update status
                self.mUpdatePatchStatus(True, 
                    (self.STEP_GATHER_NODE_DATA+'_'+aTaskType+'_[%d]' % (
                                        _node_stat_index)), _comment)

                _domU_listed_by_xm_list = []
                if (aTaskType == self.PATCH_DOM0):
                    #we get domus from 'xm list' command to check heartbeat 
                    # betweeen domU -> cell after patch operation
                    _domU_listed_by_xm_list = self.__clupatchcheck.mCheckVMsUp(
                                                    _node_to_patch)
                _pre_patch_version = self.__clupatchcheck.mCheckTargetVersion(
                        _node_to_patch, aTaskType)

                #since we will do operations between dom[0U] upgrades, 
                #create an input file per dom0 to patch
                _input_file = self._mCreateNodesFile(
                        _node_patch_base_after_unzip, _node_patcher,
                        [_node_to_patch])
                _input_file_name = _input_file.split("/")[-1]

                # update with current dom[0u] patcher which will be used in 
                # CNS monitor
                _node_patch_progress = os.path.join(self.__log_path, _cns_string)
                with open(_node_patch_progress, "w") as write_nodestat:
                    write_nodestat.write("%s:%s" % (_node_patcher,
                        self.__patchmgr_log_path_on_launch_node)) 

                if aRollback:
                    _patch_cmd = _patch_cmd_template % (
                            _node_patch_base_after_unzip, 
                            _input_file_name,self.__patchmgr_log_path_on_launch_node,
                            self.__patchmgr_log_path_on_launch_node)
                else:
                    _patch_cmd = _patch_cmd_template % (
                            _node_patch_base_after_unzip,_input_file_name,
                            _node_patch_zip2_name,self.__target_version,
                            self.__patchmgr_log_path_on_launch_node,
                            self.__patchmgr_log_path_on_launch_node)

                if (aTaskType == self.PATCH_DOM0):
                    #mark all the cell alert logs so we know where to look for the 
                    #domU heartbeat
                    _cell_alert_log_mark = "Exadata_Cloud_Service_CellHeartbeatCheck_"+_node_to_patch+ "_" + str(hex(int(time.time()*10000000))[2:])
                    # bug 27263414 : add human readable time to heartbeat mark
                    _cell_alert_log_mark_tz = "%+4.4d" % (time.timezone / -(60*60) * 100)
                    _current_time_in_iso_format = datetime.datetime.now().isoformat()
                    _cell_alert_log_mark_2 = "%s%s" % (_current_time_in_iso_format,_cell_alert_log_mark_tz)
                    ebLogDebug("Write LogMark to cell alert log: "
                               " Cell Alert Log Mark_1 = %s,"
                               " Cell Alert Log Mark_2 = %s,"
                               " CELL_ALERT_LOG = %s " % (
                               _cell_alert_log_mark, 
                               _cell_alert_log_mark_2, self.CELL_ALERT_LOG))

                    for _cell_name in  self._mGetCellList():
                        _cell = exaBoxNode(get_gcontext())
                        _cell.mConnect(aHost=_cell_name)
                        _cell.mExecuteCmd("echo %s %s >> %s"  % (
                            _cell_alert_log_mark, _cell_alert_log_mark_2, self.CELL_ALERT_LOG))
                        _cell.mDisconnect()
    
                # Update status
                if (aTaskType == self.PATCH_DOM0):
                    if _round == 1:
                        self.mUpdatePatchStatus(True, 
                            (self.STEP_RUN_PATCH_SECOND_DOM0+'_[%d]' % (
                                                _node_stat_index)), _comment)
                    else:
                        self.mUpdatePatchStatus(True, 
                            (self.STEP_RUN_PATCH_DOM0+'_[%d]' % (
                                                _node_stat_index)), _comment)
                elif (aTaskType == self.PATCH_DOMU):
                    if _round == 1:
                        self.mUpdatePatchStatus(True, 
                            (self.STEP_RUN_PATCH_SECOND_DOMU+'_[%d]' % (
                                                _node_stat_index)), _comment)
                    else:
                        self.mUpdatePatchStatus(True, 
                            (self.STEP_RUN_PATCH_DOMU+'_[%d]' % (
                                                _node_stat_index)), _comment)

                # Run Pre Post Plugins
                if (self.__run_user_plugins and aTaskType == self.PATCH_DOM0):
                    _read_patch_state = mGetPatchStatesForNode(_launch_nodes, self.__metadata_json_file,
                                                               _node_to_patch, self.PRE_PATCH)

                    ebLogInfo("Dom0 pre plugin patch status: %s" % _read_patch_state)
                    if not _read_patch_state:
                        _rc = self.DOM0_PRECHECKS_FAILED
                        ebLogError("Invalid patch state found during rolling patch = %s" % _read_patch_state)
                        break

                    # If anything left at last run of pre plugin and patchmgr is still 
                    # running, then re-run plugin too. 
                    if _read_patch_state in [self.PATCH_PENDING, self.PATCH_RUNNING]:
                        if _read_patch_state == self.PATCH_PENDING:
                           # Update patch metadata status progress for pre plugins
                            mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _node_to_patch,
                                                 self.__metadata_json_file, self.PRE_PATCH, self.PATCH_RUNNING)
                        if not self._mPrePostPluginsRun(_node_to_patch, 
                                                 self.PATCH_DOM0, self.PRE_PATCH,
                                                 aRollback = aRollback):
                            mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _node_to_patch,
                                                 self.__metadata_json_file, self.PRE_PATCH, self.PATCH_FAILED)
                            _rc = self.DOM0_PRECHECKS_FAILED
                            break

                        mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _node_to_patch,
                                             self.__metadata_json_file, self.PRE_PATCH, self.PATCH_COMPLETED)
                    elif _read_patch_state == self.PATCH_FAILED: 
                        _rc = self.DOM0_PRECHECKS_FAILED
                        break

                elif (self.__run_user_plugins and aTaskType == self.PATCH_DOMU):
                    _read_patch_state = mGetPatchStatesForNode(_launch_nodes, self.__metadata_json_file,
                                                               _node_to_patch, self.PRE_PATCH)
                    ebLogInfo("DomU pre plugin patch status: %s" % _read_patch_state)
                    if not _read_patch_state:
                        _rc = self.DOMU_PRECHECKS_FAILED
                        ebLogError("Invalid patch state found during rolling patch = %s" % _read_patch_state)
                        break
                    # If anything left at last run of pre plugin and patchmgr is still 
                    # running, then re-run plugin too. 
                    if _read_patch_state in [self.PATCH_PENDING, self.PATCH_RUNNING]:
                        if _read_patch_state == self.PATCH_PENDING:
                            # Update patch metadata status progress for pre plugins
                            mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _node_to_patch,
                                                 self.__metadata_json_file, self.PRE_PATCH, self.PATCH_RUNNING)
                        if not self._mPrePostPluginsRun(_node_to_patch, 
                                                 self.PATCH_DOMU, self.PRE_PATCH,
                                                 aRollback = aRollback):
                            mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _node_to_patch,
                                                 self.__metadata_json_file, self.PRE_PATCH, self.PATCH_FAILED)
                            _rc = self.DOMU_PRECHECKS_FAILED
                            break

                        mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _node_to_patch,
                                             self.__metadata_json_file, self.PRE_PATCH, self.PATCH_COMPLETED)
                    elif _read_patch_state == self.PATCH_FAILED: 
                        _rc = self.DOMU_PRECHECKS_FAILED
                        break

                # Run patch command
                # If there are no patchmgr sessions running, then run patchmgr command
                _pacthmgr_session_exit = 1
                _patchmgr_active_node = None

                _pacthmgr_session_exit, _patchmgr_active_node = self.mCheckPatchmgrSessionExistence(self.__patchmgr_log_path_on_launch_node,
                                                                                                    aLaunchNode=None, 
                                                                                                    aNodeList = _all_nodes)
                if _pacthmgr_session_exit == 0: # No patchmgr session found in any of the nodes,
                                                # so re-execute with same launch/_node_patcher
                    # Update patch metadata status progress for patchmgr 
                    mUpdatePatchMetadata(aTaskType, _launch_nodes, _node_to_patch,
                                         self.__metadata_json_file, self.PATCH_MGR, self.PATCH_RUNNING)
                    self.mExecutePatchmgrCmd(_node_patcher, self.__patchmgr_log_path_on_launch_node, _patch_cmd)
                    # Monitor console log
                    _rc = int(self.mReadPatchmgrConsoleOut(_node_patcher, self.__patchmgr_log_path_on_launch_node))
                else:
                    # TODO: We need to handle patch non-retry in future. Time being we are forcibly stopping.
                    if not self.mPatchRequestRetried():
                        ebLogError('mPatchDom0UsRolling: Found older patchmgr session. Forcibly terminating patching request')
                        _rc = 1
                        return _rc

                    # Already patchmgr is running, just monitor patchmgr console on the node.
                    ebLogInfo("Patchmanager session exists and return code = %s, Patchmgr session active node = %s" % (_pacthmgr_session_exit, _patchmgr_active_node))
                    _rc = int(self.mReadPatchmgrConsoleOut(_patchmgr_active_node, self.__patchmgr_log_path_on_launch_node))
                    _node_patcher = _patchmgr_active_node

                if _rc != 0:
                    # Update patch metadata status progress for patchmgr 
                    mUpdatePatchMetadata(aTaskType, _launch_nodes, _node_to_patch,
                                         self.__metadata_json_file, self.PATCH_MGR, self.PATCH_FAILED)
                else:
                    # Update patch metadata status progress for patchmgr 
                    mUpdatePatchMetadata(aTaskType, _launch_nodes, _node_to_patch,
                                         self.__metadata_json_file, self.PATCH_MGR, self.PATCH_COMPLETED)
 
                self.mUpdatePatchStatus(True, 
                    (self.STEP_CLEAN_ENV+'_'+aTaskType+'_[%d]' % (
                                       _node_stat_index)), _comment)

                # Extract and post notification (CNS), if anything left
                # out on dom0[u]s, before it shift to initial dom0[u]
                ebLogDebug("Before instant collect of patching notification by patch process")
                self.mMonitorPatchReqForCNS(
                    aCollectCnsOnce = self.__instant_collect_of_cns)
                ebLogDebug("After instant collect of patching notification by patch process")

                # Get the logs, diags and so on
                _patch_log = str(
                    self._mGetDom0FileCode(_node_patcher,
                        self.__patchmgr_log_path_on_launch_node))
                self._mGetPatchMgrOutFiles(_node_patcher,
                        self.__patchmgr_log_path_on_launch_node,
                        _patch_log)
                self._mGetPatchMgrDiagFiles(_node_patcher, 
                        aTaskType,
                        [_node_to_patch],
                        self.__patchmgr_log_path_on_launch_node)
   
                self._mGetPatchMgrMiscLogFiles(_node_patcher,
                                               self.__patchmgr_log_path_on_launch_node)

                _dom0 = exaBoxNode(get_gcontext())
                _dom0.mConnect(aHost=_node_patcher) 
                _dom0.mExecuteCmdLog("rm -f %s" % _input_file)

                # Moving log_dir to log_dir_<node_patched>, before starting another one
                _dom0.mExecuteCmdLog("mv -f %s %s_%s" % (self.__patchmgr_log_path_on_launch_node, 
                                                         self.__patchmgr_log_path_on_launch_node, 
                                                         _node_to_patch.split(".")[0]))
                _dom0.mDisconnect()

                if _rc != 0:
                    _node_patch_failed = _node_to_patch
                    _patch_failed_message = (
                        "Error patching %s using %s to patch it. "
                        "return code was %s. "
                        "Errors on screen and in logs") % (
                            _node_patch_failed, _node_patcher, str(_rc))
                    break

                _nodes_successfuly_patched.append(_node_to_patch)
                _nodes_not_patched.remove(_node_to_patch)

                # We need this data for the plugins
                self._last_node_patched = _node_to_patch

                self.mUpdatePatchStatus(True, 
                    (self.STEP_POSTCHECKS+'_'+aTaskType+'_[%d]' % (
                                       _node_stat_index)), _comment)
                
                if (aTaskType in [ self.PATCH_DOM0 ]):
                    if not self._mPostDom0PatchCheck(aDom0=_node_to_patch,
                            aCellAlertLogMark=_cell_alert_log_mark,
                            aDomUList=_domU_listed_by_xm_list,
                            aPrePatchVersion=_pre_patch_version,
                            aPostPatchTargetVersion=self.__target_version,
                            aRollback=aRollback):
                        _node_patch_failed = _node_to_patch
                        _patch_failed_message = ("dom0 [%s] patching succeded, "
                                                 "but post-patch checks failed"
                                                 % (_node_to_patch))
                        _rc = self.DOM0_POSTCHECKS_FAILED
                        break

                    if self.__run_user_plugins:
                        # Update patch metadata status progress for post plugins
                        mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _node_to_patch,
                                             self.__metadata_json_file, self.POST_PATCH, self.PATCH_RUNNING)
                        if not self._mPrePostPluginsRun(_node_to_patch, 
                                                        self.PATCH_DOM0, self.POST_PATCH,
                                                        aRollback = aRollback):
                            mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _node_to_patch,
                                                 self.__metadata_json_file, self.POST_PATCH, self.PATCH_FAILED)
                            _rc = self.DOM0_POSTCHECKS_FAILED
                            break

                        mUpdatePatchMetadata(self.PATCH_DOM0, _launch_nodes, _node_to_patch,
                                             self.__metadata_json_file, self.POST_PATCH, self.PATCH_COMPLETED)
                elif (aTaskType in [ self.PATCH_DOMU ]): 
                    if not self._mPostDomUPatchCheck(aDomU=_node_to_patch,
                            aPrePatchVersion=_pre_patch_version,
                            aPostPatchTargetVersion=self.__target_version,
                            aRollback=aRollback):
                        _node_patch_failed = _node_to_patch
                        _patch_failed_message = ("domu [%s] patching succeded, "
                                                 "but post-patch checks failed"
                                                 % (_node_to_patch))
                        _rc = self.DOMU_POSTCHECKS_FAILED
                        break
                
                    if self.__run_user_plugins: 
                        # Update patch metadata status progress for post plugins
                        mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _node_to_patch,
                                             self.__metadata_json_file, self.POST_PATCH, self.PATCH_RUNNING)
                        if not self._mPrePostPluginsRun(_node_to_patch, 
                                                        self.PATCH_DOMU, self.POST_PATCH,
                                                        aRollback = aRollback):
                            mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _node_to_patch,
                                                 self.__metadata_json_file, self.POST_PATCH, self.PATCH_FAILED)
                            _rc = self.DOMU_POSTCHECKS_FAILED
                            break

                        mUpdatePatchMetadata(self.PATCH_DOMU, _launch_nodes, _node_to_patch,
                                             self.__metadata_json_file, self.POST_PATCH, self.PATCH_COMPLETED)
  
            #if any dom[0U] patch or post-patch failed, we cant risk patching 
            #another node and it having issues also
            if _node_patch_failed:
                break

        ebLogInfo("\n%ss patched: %s\n%ss not patched: %s"
                  % (aTaskType.upper(), " ".join(_nodes_successfuly_patched), 
                     aTaskType.upper(), " ".join(_nodes_not_patched)))
        if _node_patch_failed:
            ebLogError(_patch_failed_message)
            ebLogError("%s patching or post-patching failed on: %s" % (
                       aTaskType.upper(), str(_node_patch_failed)))

        # Capture return payload if no nodes attempted to upgrade. This is
        # required for updating ecra rack status to previous status in ecra layer.
        if not _nodes_attempted_to_upgrade_flag: 
            self.mAddError(self.mGetRackName(), 1017)

        return _rc

    def _mRollbackIsAvailable(self, aNode): 
        """
        Looks for an available image to rollback in aNode.
        """

        def _mRunCheckRollbackCmd(aNode):
            check_rollback_cmd = ('/opt/oracle.SupportTools/dbserver_backup.sh '
                                  '--ignore-nfs-smbfs-mounts '
                                  '--check-rollback '
                                  '| grep -i "rollback is available"')
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=aNode)
            _i, _o, _e = _node.mExecuteCmd(check_rollback_cmd)
            _node.mDisconnect()
            if _o:
                return True
            else:
                return False

        if aNode in self._mGetDom0List():
            return _mRunCheckRollbackCmd(aNode)
        elif aNode in self._mGetCellList():
            #TODO can easily check with imageinfo
            raise NotImplementedError("Checking if rollback is available for "
                                      "cells [%s] is not implemented" % aNode)
        elif aNode in self._mGetIBSwitchList():
            raise NotImplementedError("Checking if rollback is available for "
                                      "ibswitch [%s] is not implemented" % aNode)
        elif aNode in self._mGetDomUList():
            return _mRunCheckRollbackCmd(aNode)
        else:
            raise NotImplementedError("Checking if rollback is available for "
                                      "%s failed. Unable to determine host type"
                                      % aNode)

    def mReadPluginScriptConsoleOut(self, aNode, aPluginLogPathLaunchNode, aNodeType):
        """
         Here we connect to the target node and try to check for progress of plugin
         scripts reading Console out file. It returns:

             True  --> when plugins run ends with success
             False --> when plugins run ends with failure

          Since the plugin scripts are run in the background using nohup, the below section
          of code monitors the log file for completion and returns the exit status of the
          plugin script output.
        """

        _connected_as_non_root_user = False 
        _sudo_str = ''
        _exit_code = False

        try:
            ebLogInfo("Read plugin console from %s node = %s and log loc = %s" % (aNodeType, aNode, aPluginLogPathLaunchNode))

            _node = exaBoxNode(get_gcontext())

            if aNodeType == self.PATCH_DOMU and self.mIsOpcUserExist(aNode):
                _node.mSetUser('opc')
                ebLogInfo("mReadPluginScriptConsoleOut: Connecting as opc user to '%s' '%s' to run plugins." % 
                           (aNodeType, aNode))
                _node.mConnect(aHost=aNode) 
                _connected_as_non_root_user = True
            else:
                _node.mConnect(aHost=aNode) 
                ebLogInfo("mReadPluginScriptConsoleOut: Connecting as root user to '%s' '%s' to run plugins" % 
                           (aNodeType, aNode))

            PLUGIN_READ_SLEEP_IN_SECONDS = 3
            _plugin_output_read = True

            _current_time_in_sec = 0

            # Need to run as sudo for all non root user
            if _connected_as_non_root_user:
                _sudo_str = 'sudo '

            _plugin_exit_seek_cmd = _sudo_str+'grep -i "Exit status" %s' % (aPluginLogPathLaunchNode)
            ebLogInfo("Grep plugin console cmd = %s" % _plugin_exit_seek_cmd)

            while _plugin_output_read and _current_time_in_sec < self.EXADATA_PATCHMGR_CONSOLE_READ_TIMEOUT_SEC:
                _i, _o, _e = _node.mExecuteCmd(_plugin_exit_seek_cmd)
                _exit_check = _node.mGetCmdExitStatus()
                _out = _o.readlines()

                if _exit_check == 0:
                    _plugin_output_read = False
                    for _output in _out:
                        ebLogInfo("%s" % _output)
                        '''
                         Sample log output below :

                           This script runs in nohup mode and hence i have added sleep commands here to
                           track and read console output.
                           ill end this script in another 20 seconds
                           existing script
                           [INFO] : [Custom Plugin Message] : Custom plugin script run successfully.
                           Exit status:0

                        '''
                        if "Exit status:0" in _output:
                            _exit_code = True
                        _node.mDisconnect()
                        return _exit_code
                sleep(3)
                # We are incrementing the counter by 3 as we are 
                # putting the current thread in sleep mode every
                # 3 seconds unit it exits.
                _current_time_in_sec += PLUGIN_READ_SLEEP_IN_SECONDS

            _node.mDisconnect()
            return _exit_code
        except Exception as e:
            ebLogError("Exception in reading plugin console log: "+str(e))
            return _exit_code

    def _mCopyPluginsToTargetNode (self, aDom0UNode, aNodeType, aPluginsToCopy): 
        """ 
        Check existence of plugins on local node and copy them to target node,
        if it's dom0 and aAdwAtpFA Env, then even copy to dom0's domU.
        Return: 
            True  - if copy success
            False - if copy is failed
        """ 

        _connected_as_non_root_user = False
        _sudo_str = ''
        _node_type_name = ("DOMU" if (aNodeType == self.PATCH_DOMU) else "DOM0")

        try:
            _dbnu_plugins_loc_dir = aPluginsToCopy['dbnu_plugins']['plugin_loc_dir']
            _dbnu_plugins_remote_dir = aPluginsToCopy['dbnu_plugins']['plugin_remote_dir']

            _loc_dom0stxt_fname = os.path.join(_dbnu_plugins_loc_dir, "dom0s.txt") 

            ebLogInfo("Copying plugins to %s '%s':" % (_node_type_name, aDom0UNode))
            _dom0U = exaBoxNode(get_gcontext())   
            if aNodeType == self.PATCH_DOMU and self.mIsOpcUserExist(aDom0UNode):
                _dom0U.mSetUser('opc')
                _dom0U.mConnect(aHost=aDom0UNode)
                _connected_as_non_root_user = True
            else:
                _dom0U.mConnect(aHost=aDom0UNode)

            # Need to run as sudo for all non root user
            if _connected_as_non_root_user:
                _sudo_str = 'sudo '

            # Copy all plugins to target node
            for _plugin_type, _plugin_list in aPluginsToCopy.items():
                ebLogInfo("Copy %s to %s '%s':" % \
                           (_plugin_type.upper(), _node_type_name, aDom0UNode))
                _plugin_loc_dir = _plugin_list ['plugin_loc_dir'] 
                _plugin_remote_dir = _plugin_list ['plugin_remote_dir'] 
                if os.path.isdir(_plugin_loc_dir) and os.listdir(_plugin_loc_dir):
                    # Connect as opc for domU case if opc user exist
                    if aNodeType == self.PATCH_DOMU and _connected_as_non_root_user:
                        _dom0U.mExecuteCmdLog(_sudo_str+"mkdir -p "+_plugin_remote_dir)
                        # Need write access for non root user
                        _dom0U.mExecuteCmdLog(_sudo_str+"chmod 777 "+_plugin_remote_dir)
                    # as a root user for dom0/domU 
                    else:
                        _dom0U.mExecuteCmdLog("mkdir -p "+_plugin_remote_dir)
                 
                    for _entry_file in os.listdir(_plugin_loc_dir):
                        ebLogInfo("Copy plugins: Source = %s, Destination file = %s" % \
                                   (os.path.join(_plugin_loc_dir, _entry_file), 
                                    os.path.join(_plugin_remote_dir, _entry_file)))
                        # if listed entry is diretory, then we skip it, since we expect
                        # all files in plugin directory itself.
                        if os.path.isdir(os.path.join(_plugin_loc_dir, _entry_file)):
                            ebLogInfo("The '%s' is a directory, we skip to copy directory." % \
                                       os.path.join(_plugin_loc_dir, _entry_file))
                            continue 
                        else:
                            _dom0U.mCopyFile(os.path.join(_plugin_loc_dir, _entry_file), 
                                             os.path.join(_plugin_remote_dir, _entry_file))
                    _dom0U.mExecuteCmdLog(_sudo_str+"chmod +x -R "+_plugin_remote_dir)
                else:
                    ebLogInfo("No %s scripts to copy from '%s'" % (_plugin_type.upper(), _plugin_loc_dir))

            _dom0U.mDisconnect()

            # We need to also generate list of dom0s (dom0s.txt) and copy to all 
            # dom0x nodes. This requires to run dbnu plugins only for dom0 and env is ADW and ATP
            if self.__run_user_plugins_on_dom0s_domu_node and aNodeType == self.PATCH_DOM0: 
                ebLogInfo("Create list of dom0s file on exacloud. Loc: '%s'" % _dbnu_plugins_loc_dir)
                # purge dom0 files if already exit
                self.__cluctrl.mExecuteLocal("/bin/rm -f "+_loc_dom0stxt_fname)
                # Get generate dom0s.txt file on exacloud
                _dom0_list = self._mGetDom0List()
                for _dom0 in _dom0_list:
                    with open(_loc_dom0stxt_fname, 'w') as _file_desc:
                        _file_desc.write("echo "+_dom0)

                # Copy new dom0s.txt to all dom0 nodes. It's required for 
                # running dbnu_pluings scripts via patchmgr->dbnodeupdate.sh->dbnu_plugins.sh (dom0.sh -> domu.sh)
                # This will be only used for ADW or ATP where we might migrate PDB/CDB from domU
                # before dom0 upgrade.
                if os.path.isfile(_loc_dom0stxt_fname):
                    for _dom0 in _dom0_list:
                        _dom0U = exaBoxNode(get_gcontext())
                        _dom0U.mConnect(aHost=_dom0)
                        _dom0U.mExecuteCmdLog("mkdir -p "+_dbnu_plugins_remote_dir)
                        _dom0U.mCopyFile(_loc_dom0stxt_fname, os.path.join(_dbnu_plugins_remote_dir, "dom0s.txt"))
                        _dom0U.mDisconnect()
                else:
                    ebLogInfo("The list of dom0s dom0s.txt file does not exist on exacloud: '%s'" % _dbnu_plugins_loc_dir)
            return True
        except Exception as e:
            ebLogError("Exception in copying plugins: "+str(e))
            return False
        # end of _mCopyPluginsToTargetNode 

    def _mGetpluginsLog (self, aDom0UNode, aNodeType, aStage):
        """
        Get plugin logs from target node (where plugins run) to local ecra/exacloud node.
        """

        _connected_as_non_root_user = False
        _sudo_str = ''
        _node_type_name = ("DOMU" if (aNodeType == self.PATCH_DOMU) else "DOM0")

        # The same log file is used by exacloud and dbnu-plugin.sh plugins.
        _PLUGINS_LOG_LOC = self.__plugins_log_path_on_launch_node
        ebLogInfo("Copying plugin logs to ecra node from %s '%s'" % (_node_type_name, aDom0UNode))
        try:
            _dom0U_local = exaBoxNode(get_gcontext())   
            # Connect as opc for domU if exist, otherwise, as root user
            if aNodeType == self.PATCH_DOMU and self.mIsOpcUserExist(aDom0UNode):
                _dom0U_local.mSetUser('opc')
                _dom0U_local.mConnect(aHost=aDom0UNode) 
                _connected_as_non_root_user = True
            else:
                _dom0U_local.mConnect(aHost=aDom0UNode) 

            ebLogDebug("mGetpluginsLog: Connected as %s user to %s '%s' to run plugins." % 
                        (("opc" if (_connected_as_non_root_user) else "root"), _node_type_name, aDom0UNode))

            # Need to run as sudo for all non root user
            if _connected_as_non_root_user:
                _sudo_str = 'sudo '

            _plugin_log_file = "plugin_%s_%s_console.out" % (aStage, aDom0UNode) 
            if aNodeType == self.PATCH_DOMU and _connected_as_non_root_user: 
                 # Need to access plugin log as opc user to copy to ecra node
                _cmd = _sudo_str+"cp "+os.path.join(_PLUGINS_LOG_LOC,_plugin_log_file)+" "+os.path.join('/tmp',_plugin_log_file)
                _dom0U_local.mExecuteCmdLog(_cmd)
                _cmd = _sudo_str+"chmod 777 "+os.path.join("/tmp",_plugin_log_file)
                _dom0U_local.mExecuteCmdLog(_cmd)
                ebLogInfo("Downloading plugin log from %s '%s'. Location : %s to %s" % 
                           (_node_type_name, aDom0UNode, os.path.join('/tmp',_plugin_log_file), os.path.join(self.__log_path, _plugin_log_file))) 
                _dom0U_local.mCopy2Local(os.path.join('/tmp',_plugin_log_file), os.path.join(self.__log_path, _plugin_log_file))
            else:
                ebLogInfo("Downloading plugin log from %s  '%s'. Location : From %s to %s" % 
                           (_node_type_name, aDom0UNode, os.path.join(_PLUGINS_LOG_LOC,_plugin_log_file), os.path.join(self.__log_path, _plugin_log_file))) 
                _dom0U_local.mCopy2Local(os.path.join(_PLUGINS_LOG_LOC,_plugin_log_file), os.path.join(self.__log_path, _plugin_log_file))

            _dom0U_local.mDisconnect()

            ebLogInfo("Get plugin logs from '%s' completed." % aDom0UNode)
        except Exception as e:
            ebLogError("Exception Copying plugin logs: "+str(e))
        # end of _mGetpluginsLog  

    def _mCleanupPluginsfromTargetNode (self, aDom0UNode, aNodeType, aPluginsDir, aStage):
        """
        Cleanup DBNU plugins only at the end of patcmmgr run which is typically
        during post operation.i.e,
         1. By Default clean up only parents exacloud scripts in both pre and post stage
         2. Cleanup scripts from aPluginsDbnuDir(dbnu plugins) only when post stage 
        """

        _connected_as_non_root_user = False
        _sudo_str = ''
        _node_type_name = ("DOMU" if (aNodeType == self.PATCH_DOMU) else "DOM0")

        ebLogInfo("Cleaning up plugins from %s '%s'" % (_node_type_name, aDom0UNode))
        try:
            _dom0U = exaBoxNode(get_gcontext())   
            # Connect as opc user for domU if opc user exist
            if aNodeType == self.PATCH_DOMU and self.mIsOpcUserExist(aDom0UNode):
                _dom0U.mSetUser('opc')
                _dom0U.mConnect(aHost=aDom0UNode) 
                _connected_as_non_root_user = True 
            else:
                _dom0U.mConnect(aHost=aDom0UNode) 
            ebLogDebug("_mCleanupPluginsfromTargetNode: Connected as %s user to %s '%s':" % 
                        (("opc" if (_connected_as_non_root_user)  else "root"), _node_type_name, aDom0UNode))

            # Need to run as sudo for all nont root user
            if _connected_as_non_root_user: 
                _sudo_str = 'sudo ' 

            # Cleanup plugins for all types 
            for _plugin_type, _plugin_list in aPluginsDir.items():
                _plugin_loc_dir    = _plugin_list ['plugin_loc_dir']
                _plugin_remote_dir = _plugin_list ['plugin_remote_dir']
                # Clean up dbnu plugins only when post patch, usually there will be dom0.sh only,
                # but deleting all parents scripts in case if those executed in future.
                if _plugin_type == self.PLUGIN_DBNU and aStage ==  self.POST_PATCH:
                    # Remove dom0s.txt from remote node 
                    _dom0U.mExecuteCmdLog("%s rm -rf %s" % (_sudo_str, _plugin_remote_dir))
                    # Remove dom0s.txt from ecra/exacloud  
                    _loc_dom0stxt_fname = os.path.join(_plugin_loc_dir, "dom0s.txt")
                    self.__cluctrl.mExecuteLocal("/bin/rm -f "+_loc_dom0stxt_fname) 
                elif not _plugin_type == self.PLUGIN_DBNU:
                    _dom0U.mExecuteCmdLog("%s rm -rf %s" % (_sudo_str, _plugin_remote_dir))
            _dom0U.mDisconnect()

            ebLogInfo("Cleanup plugins done.") 
        except Exception as e:
            ebLogError("Exception _mCleanupPluginsfromTargetNode: "+str(e))

    def _mPrePostPluginsHelper(self, aNode, aNodeType, aRemotePluginDir, aPluginsToRun, aStage, aRollback):
        """
          # Connect to a node (dom0 and domU) and run require plugins.
            True: when successful
            False: when fails
        """

        try: 
            _connected_as_non_root_user = False
            _sudo_str = ''
            _node_type_name = ("DOMU" if (aNodeType == self.PATCH_DOMU) else "DOM0")

            _dom0U_local = exaBoxNode(get_gcontext())   
            # Try to connect as opc user to domu. If not exist, then try with root user
            if aNodeType == self.PATCH_DOMU and self.mIsOpcUserExist(aNode):
                _dom0U_local.mSetUser('opc')
                ebLogInfo("_mPrePostPluginsHelper: Connecting as opc user to '%s' '%s' to run plugins." % 
                           (_node_type_name, aNode))
                _dom0U_local.mConnect(aHost=aNode) 
                _connected_as_non_root_user = True
            else:
                _dom0U_local.mConnect(aHost=aNode) 
                ebLogInfo("_mPrePostPluginsHelper: Connecting as root user to '%s' '%s' to run plugins" % 
                           (_node_type_name, aNode))

            _plugin_file_to_exec = os.path.join(aRemotePluginDir, aPluginsToRun)
            if _dom0U_local.mFileExists(_plugin_file_to_exec):
                ebLogDebug("Parent %s script '%s' found for %s." % 
                          (aStage.upper(), _plugin_file_to_exec, _node_type_name))
            else:
                ebLogError("Parent %s script '%s' not found for %s." % 
                          (aStage.upper(), _plugin_file_to_exec, _node_type_name)) 
                # Nothing can be done for plugins to run, so error out to let
                #  user know this
                _dom0U_local.mDisconnect()
                return False 

            ebLogInfo("%s plugins are running on %s '%s'" % \
                       (aStage.upper(), _node_type_name, _dom0U_local.mGetHostname()))

            # Need to run as sudo for all nont root user
            if _connected_as_non_root_user: 
                _sudo_str = 'sudo ' 
           
            # call the plugin with stage or phase as an argument
            # we are also validating if the script is already running.
            
            _plugin_log_file = "%s/plugin_%s_%s_console.out" % (self.__plugins_log_path_on_launch_node, aStage, aNode)

            if not _dom0U_local.mFileExists(_plugin_log_file):
                if not aRollback:
                    _cmd = "%snohup sh %s patch %s %s %s &" % (_sudo_str, _plugin_file_to_exec,aStage,_plugin_log_file, self._last_node_patched)
                else:
                    _cmd = "%snohup sh %s rollback %s %s %s &" % (_sudo_str, _plugin_file_to_exec,aStage,_plugin_log_file, self._last_node_patched)

                # Run the plugin command in nohup.
                ebLogInfo("%s script executing cmd: %s" % (aStage.upper(), _cmd))
                _cmd_mkdir = 'mkdir -p %s' % (self.__plugins_log_path_on_launch_node)
                _dom0U_local.mExecuteCmd(_cmd_mkdir)
                _dom0U_local.mExecuteCmdLog(_cmd)
            else:
                ebLogInfo("Plugin session is still active: %s" % _plugin_log_file)

            _dom0U_local.mDisconnect()

            # Read plugins console log output.
            if self.mReadPluginScriptConsoleOut(aNode ,_plugin_log_file, aNodeType):
                ebLogInfo("%s plugins on %s '%s' completed successfully" % \
                            (aStage.upper(), _node_type_name, _dom0U_local.mGetHostname()))
                return True
            else:
                ebLogError("The execution of plugin script failed")
                return False

        except Exception as e:
            ebLogError("Exception in executing exadata plugins: "+str(e))
            return False
        #end of _mPrePostPluginsHelper 
   
    def _mPrePostPluginsRun(self, aNode, aNodeType, aStage, aRollback = False):
        """
          Returns True if all checks pass, False if any of the checks failed.
          This method helps to: 
          1) Do nothing if there are no plugins to run
          2) Copy dbnu plugins to target nodes and helps to run during dbnu/patchmgr session.
          3) Copy exacloud pre-post scripts to dom0/domU and can be used before and after patchmgr run. 
             Args passed:
             aNode => Node on which plugins needs to run
             aNodeType => type of node (dom0/domU) 
             aStage => Patch phase - pre or post stage 
             aRollback => The operation type is rollback or not 
        """

        # Set both dbnu and exacloud plugin locations 
        _plugins_base_dir = "exadataPrePostPlugins"
        if os.path.isdir(_plugins_base_dir) and os.listdir(_plugins_base_dir):
            _plugins_dbnu_dir = os.path.join(_plugins_base_dir, "dbnu_plugins")
            _plugins_exacloud_dir = os.path.join(_plugins_base_dir, "exacloud_plugins")
        else:
            ebLogError("Plugins directory not found at exacloud layer")
            return False 

        # Location of exacloud and dbnu plugins (on exacloud and on target node)
        _plugins_to_run = { "dbnu_plugins"    : {'plugin_loc_dir': _plugins_dbnu_dir, 'plugin_remote_dir': '/opt/exacloud/customs/plugins/dbnu_plugins/'},
                            "exacloud_plugins": {'plugin_loc_dir': _plugins_exacloud_dir, 'plugin_remote_dir': '/opt/exacloud/customs/plugins/exacloud_plugins/'}
                          }
        # commenting time being
        """
        _plugins_dir_dbnu       = _plugins_to_run['dbnu_plugins']['plugin_loc_dir'] 
        _remote_plugin_dir_dbnu = _plugins_to_run['dbnu_plugins']['plugin_remote_dir'] 
        _plugins_dir_exacloud   = _plugins_to_run['exacloud_plugins']['plugin_loc_dir']
        """
        _remote_plugin_dir_exacloud =  _plugins_to_run['exacloud_plugins']['plugin_remote_dir']

        _flag_plugins_exist = False
        _pre_post_str = None
        _rc = True

        ebLogInfo("\nRunning '%s' plugins during '%s' on '%s' : '%s'" % \
                  (("PRE" if (aStage == self.PRE_PATCH) else "POST"), 
                   ("ROLLBACK" if (aRollback) else "UPGRADE"), 
                   ("DomU" if (aNodeType == self.PATCH_DOMU) else "Dom0"), 
                   aNode))
        try:
            for _plugin_type, _plugin_list in _plugins_to_run.items():
                if os.path.isdir(_plugin_list['plugin_loc_dir']) and os.listdir(_plugin_list['plugin_loc_dir']):
                    _flag_plugins_exist = True

            if not _flag_plugins_exist:
                ebLogError("No exadata parent plugins to run from %s '%s'. Please ensure to have parents plugins script. Plugins location: '%s'" %\
                          (("DomU" if (aNodeType == self.PATCH_DOMU) else "DOM0"), aNode, _plugins_to_run))
                return False 
        except Exception as e:
            ebLogError("Exception: Validating presence of plugins: "+str(e))

        try: 
            # 1. Copy dbnu plugins. These plugins will be run by patchmgr->dbnodeupdate.sh
            # during patchmgr/patching  
            _dom0U_list = self._mReturnPatchingDom0DomUList()

            if (aNodeType == self.PATCH_DOM0):
                if (self.__run_user_plugins_on_dom0_node):
                    if not self._mCopyPluginsToTargetNode(aNode, aNodeType, _plugins_to_run): 
                        return False
                # Copy plugins to domu of it's own dom0, like in FA, ADW, ATP env.
                if self.__run_user_plugins_on_dom0s_domu_node:
                    ebLogInfo("Copying plugins to Dom0's DomU")
                    for _node_pair in _dom0U_list:
                        # if first node in a pair is dom0 then copy corresponding domU
                        if aNode == _node_pair[0]:
                               _dom0s_domU = _node_pair[1] 
                               if not self._mCopyPluginsToTargetNode(_dom0s_domU, self.PATCH_DOMU, _plugins_to_run):
                                   return False
            elif (aNodeType == self.PATCH_DOMU and self.__run_user_plugins_on_domu_node):
                if not self._mCopyPluginsToTargetNode(aNode, aNodeType, _plugins_to_run): 
                    return False

            # Prepare required script to be executed from infra patching
            if aNodeType == self.PATCH_DOMU: 
                _pre_post_str = "domu.sh"
            elif aNodeType == self.PATCH_DOM0:
                _pre_post_str = "dom0.sh"
            # Get pre post pattern for dom0_domu, and user require this on adw/atp/fa env to run
            if aNodeType == self.PATCH_DOM0 and self.__run_user_plugins_on_dom0s_domu_node:
                _pre_post_dom0_domU_str = "dom0_domu.sh"
        except Exception as e:
            ebLogError("Exception: Copying Plugins: "+str(e))

        try:
            # Run plugins on domu (if anything exist) when upgrading dom0 and only when 
            # user asked to run dom0's domu node 
            if aNodeType == self.PATCH_DOM0 and self.__run_user_plugins_on_dom0s_domu_node: 
                ebLogInfo("Executing Dom0's DomU scripts:") 
                for _node_pair in _dom0U_list:
                    # first node in a pair is dom0 and copy corresponding domU
                    if aNode == _node_pair[0]:
                           _dom0s_domU = _node_pair[1] 
                           if not self._mPrePostPluginsHelper(_dom0s_domU, self.PATCH_DOMU, _remote_plugin_dir_exacloud,
                                                              _pre_post_dom0_domU_str, aStage, aRollback):
                                # Copy dbnu and exacloud plugins to local node
                                self._mGetpluginsLog (_dom0s_domU, self.PATCH_DOMU, aStage)
                                # Cleanup plugins from required domU 
                                self._mCleanupPluginsfromTargetNode (_dom0s_domU, self.PATCH_DOMU, _plugins_to_run, aStage)
                                return False # script failed
                           else:
                                # We need to get dbnu and exacloud plugins logs to local ecra node even in case of success.
                                self._mGetpluginsLog (_dom0s_domU, self.PATCH_DOMU, aStage)
                                # Cleanup plugins from required domU 
                                self._mCleanupPluginsfromTargetNode (_dom0s_domU, self.PATCH_DOMU, _plugins_to_run, aStage)

            # Run plugins for domu if user requested 
            if aNodeType == self.PATCH_DOMU and self.__run_user_plugins_on_domu_node: 
                _rc = self._mPrePostPluginsHelper(aNode, self.PATCH_DOMU, _remote_plugin_dir_exacloud, _pre_post_str, aStage, aRollback)
                # Copy dbnu and exacloud plugins to local node
                self._mGetpluginsLog (aNode, self.PATCH_DOMU, aStage)
                # Cleanup plugins from required nodes 
                self._mCleanupPluginsfromTargetNode (aNode, self.PATCH_DOMU, _plugins_to_run, aStage)
            # Run plugins for dom0 if user requested 
            elif aNodeType == self.PATCH_DOM0 and self.__run_user_plugins_on_dom0_node: 
                _rc = self._mPrePostPluginsHelper(aNode, self.PATCH_DOM0, _remote_plugin_dir_exacloud, _pre_post_str, aStage, aRollback)
                # Copy dbnu and exacloud plugins to local node
                self._mGetpluginsLog (aNode, self.PATCH_DOM0, aStage)
                # Cleanup plugins from required nodes 
                self._mCleanupPluginsfromTargetNode (aNode, self.PATCH_DOM0, _plugins_to_run, aStage)

            ebLogInfo("\nCompleted '%s' plugins during '%s' on '%s' : '%s'\n" % \
                       (("PRE" if (aStage == self.PRE_PATCH) else "POST"), 
                       ("ROLLBACK" if (aRollback) else "UPGRADE"), 
                       ("DomU" if (aNodeType == self.PATCH_DOMU) else "Dom0"), 
                        aNode))
            return _rc
        except Exception as e:
            ebLogError("Exception: Executing plugins: "+str(e))


    def _mPostDomUPatchCheck(self,aDomU, aPrePatchVersion, 
                             aPostPatchTargetVersion, aRollback,aTaskType=None):
        """
        Returns True if all checks pass, False if any of the checks failed.
        checks currently done:
        *ping/ssh into the domu
        *verify the image is listed as sucess
        *verify new version is what we expected for upgrade or rollback
        *Restore ATP EXACC specific system settings.
        *check that db has started on domUs. Done by the patchmgr
        *check if the crs is up. Done by the patchmgr.
        """

        ebLogInfo("Starting post patch checks for the domu " + aDomU)

        _ret = True 
        '''
        Check that we can ping and ssh into domU
        In case of indepndent post check option, Its better
        to ping for 2secs before proceeding with other checks.
        '''
        _checked_domu_up_for_secs = 0
        if aTaskType in [ self.TASK_POSTCHECK ]:
            # In case of independent post check, we wait for 
            # the minimum tim possible as most of the detils 
            # in logs are already captured and waiting more 
            # than 5 seconds would not be applicable in this case.
            _timeout_for_domu_up = 3
        else:
            _timeout_for_domu_up = 600
        while _checked_domu_up_for_secs < _timeout_for_domu_up:
            if self.__clupatchcheck.mPingNode(aDomU):
                break
            sleep(10)
            _checked_domu_up_for_secs += 10
        else:
            ebLogError("domu %s did not come back online (not ping-able or "
                       "ssh-able) post patch" % aDomU)
            _ret = False

        #check that the image is seen as success
        if not self.__clupatchcheck.mCheckImageSuccess(aDomU):
            ebLogError("post-patch check: domu %s image is not seen as "
                       "success via imageinfo command" % aDomU)
            _ret = False

        # Restore ATP setting post DomU Upgrade/Rollback
        _domu_list = [ aDomU ]
        if not self.mSetExaccAtpSettingsOnDomU(_domu_list, "postpatch"):
            _ret = False

        '''
        Following code is run as part of regular upgrade
        and rollback flow. Independnet post check option
        cant be used in this case.
        '''
        if aTaskType not in [ self.TASK_POSTCHECK ]:
            #Check that the domu is at the requested version. if it was a rollback 
            # we just check for the version to be lowerthan what it previously was.
            _crs_enable = ""
            _current_domu_version = \
                self.__clupatchcheck.mCheckTargetVersion(aDomU, self.PATCH_DOMU)
            if aRollback:
                if self.__clupatchcheck.mCheckTargetVersion(
                    aDomU, self.PATCH_DOMU, aPrePatchVersion) >= 0:
                    ebLogError("domu rollback was requested but the version seems "
                               "to be unchanged, found version %s, " 
                               "expected to be lower than %s" % (aPrePatchVersion, 
                                                              _current_domu_version))
                    _ret = False
            #if not a rollback, we need to be at the exact requested target version
            elif self.__clupatchcheck.mCheckTargetVersion(aDomU, self.PATCH_DOMU, 
                    aPostPatchTargetVersion) != 0:
                ebLogError("domu is not at the requested upgrade version %s, "
                           "found version %s" % (aPrePatchVersion, 
                                                 _current_domu_version))
                _ret = False

            # Check CRS config enable status on DomU based on 
            # precheck data.

            if self.__crs_config_enable_stat[aDomU]:
                if self.__clupatchcheck.mCheckCrsIsUp(aDomU):
                    ebLogInfo("CRS services is up during '%s' postcheck on domU : %s" \
                                    % (self.__op_style, aDomU))
                else:
                    ebLogInfo("CRS services is down during '%s' postcheck on domU  : %s" \
                                    % (self.__op_style, aDomU))
                    _ret = False
        else:
            if self.__clupatchcheck.mCheckCrsIsEnabled(aDomU) and self.__clupatchcheck.mCheckCrsIsUp(aDomU):
                ebLogInfo("CRS services is up during '%s' postcheck on domU : %s" \
                                        % (self.__op_style, aDomU))
            else:
                ebLogInfo("CRS services is down during '%s' postcheck on domU  : %s" \
                                        % (self.__op_style, aDomU))             
                _ret = False
        return _ret

    def mSetExaccAtpSettingsOnDomU(self, aDomUList, aStage):
        """
         This methods restores the ATP specific system 
         settings prior to and post DomU patch operations.
         These settings were recommnded by exacloud team.
         
         True -> Indicate values were restored successful.
         False -> Failed to restore system settings.
        """

        _sysctl_conf = "/etc/sysctl.conf"
        _sysctl_99_conf = "/etc/sysctl.d/99-sysctl.conf"

        # Below settings are to be modified only if the environment is OCI EXACC.
        _oci_exacc = self.__cluctrl.mCheckConfigOption('ociexacc', 'True')
        if not _oci_exacc:
            ebLogInfo("Environment is not ATP Exacc, no system settings will be restored. ")
            return True
  
        _rc = 0
        for _domU in aDomUList:

            _node = exaBoxNode(get_gcontext())
            try:
                _node.mConnect(aHost=_domU)

                # To set the value in memory.
                _cmd_sysctl_w = "sysctl -w net.ipv4.conf.eth0.rp_filter=0"
                ebLogInfo("System restore command will be run during %s : %s" %(aStage, _cmd_sysctl_w))
                _i,_o,_e = _node.mExecuteCmd(_cmd_sysctl_w)
                _rc = _node.mGetCmdExitStatus()
                if _rc != 0:
                    ebLogError("Unable to set ipv4.conf.eth0.rp_filter values on DomU during %s : %s." % (aStage, _domU))
                    _node.mDisconnect()
                    return False

                # To add settings in sysctl config files for the changes to take effect during next reboot.
                _cmd_set_sysctlconf = "sed -i 's/^net.ipv4.conf.eth0.rp_filter.*/net.ipv4.conf.eth0.rp_filter = 0/' %s" % (_sysctl_conf)
                _cmd_set_99sysctlconf = "sed --follow-symlinks -i 's/^net.ipv4.conf.eth0.rp_filter.*/net.ipv4.conf.eth0.rp_filter = 0/' %s" % (_sysctl_99_conf)

                for _file in [ _sysctl_conf, _sysctl_99_conf ]:
                    if _node.mFileExists(_file):

                        if _file in [ _sysctl_conf ]:
                            _cmd = _cmd_set_sysctlconf
                        else:
                            _cmd = _cmd_set_99sysctlconf

                        ebLogInfo("Running system file restore settings during %s : %s" % (aStage, _cmd))
                        _i,_o,_e = _node.mExecuteCmd(_cmd)
                        _rc = _node.mGetCmdExitStatus()
                        if _rc != 0:
                            ebLogError("Unable to set ipv4.conf.eth0.rp_filter values on DomU during %s : %s." % (aStage, _domU))
                            _node.mDisconnect()
                            return False
                    else:
                        ebLogError("Unable to locate %s file on %s during %s" % (_file, _domU, aStage))
                        _node.mDisconnect()
                        return False

                _node.mDisconnect()
                
            except Exception as e:
                ebLogWarn('Unable to set ipv4.conf.eth0.rp_filter values on DomU : %s during %s.\n %s' % (_domU, aStage, str(e)))
                _node.mDisconnect()
                return False

        return True


    def _mPreDom0UPatchCheck(self, aTargetList):
        """
        Takes a backup of the Audit file to preserve
        fedramp setting post upgrade and Rollback tasks.
        """

        if self.__fedramp == 'ENABLED':
            _Pre_Aud = "/etc/audit/audit.rules"
            _Post_Aud = "/etc/audit/audit.rules_FED"
            ebLogInfo("Executing fedramp file backup operation as the value of Fedamp Enable is set to %s" % self.__fedramp)
            self.mFedrampDom0RestoreConfig(aTargetList, _Pre_Aud, _Post_Aud)

    def mGetStandaloneHeartbeat(self, aCmdPrintFileAfterMatchTemplate, aCmdCheckHeartbeatStartedTemplate, 
                                   aDomUName, aCellName, aCellAlertLogMark, aTempAlertLog, 
                                   aHeartbeatCheckTimeoutSecs):
        """
         This method checks the heartbeat message on all of the alert
         logs in each of the cell nodes and is run in case of independent
         postcheck option.

         -> Return True :
            if cell Marker and the heartbeat message are found in any one of 
            the alert log files.
        
         -> Return False : 
            otherwise.
        """

        ebLogInfo("Checking heartbeat from domU [%s] to cell [%s]" % (aDomUName, aCellName))
        _cmd_print_alert_log_after_mark = aCmdPrintFileAfterMatchTemplate % (aCellAlertLogMark, aTempAlertLog)
        _cmd_heartbeat_started_on_cell = aCmdCheckHeartbeatStartedTemplate % (aDomUName)
        _cmd_check_heartbeat_started =  _cmd_print_alert_log_after_mark + _cmd_heartbeat_started_on_cell
        _cmd_check_heartbeat_grep_cmd = "grep -ai heartbeat %s |  grep -ai start | grep -ai %s | head -4"
        _cell = exaBoxNode(get_gcontext())
        _cell.mConnect(aHost=aCellName)

        if aTempAlertLog.endswith('.log'):
            # Case 1. In case both the marker and the heartbeat are found in the alert.log.
            ebLogDebug("Cell heartbeat check command = %s " % _cmd_check_heartbeat_started)
            ebLogInfo("Checking for heartbeat entries in file : %s based on the filtered cell alert log mark." % aTempAlertLog)
            _checked_for_secs = 0
            while _checked_for_secs <= aHeartbeatCheckTimeoutSecs:
                _i, _o, _e = _cell.mExecuteCmd(_cmd_check_heartbeat_started)
                _heartbeat_started = self.mFormatOut(_o)
                if _heartbeat_started:
                    ebLogInfo("DomU heartbeat details were found in the log : %s" % (aTempAlertLog))
                    ebLogInfo("domU [%s] heartbeat started on cell [%s] " % (aDomUName, aCellName))
                    _cell.mDisconnect()
                    break

                sleep(10)
                _checked_for_secs += 10
            else:
                ebLogError("domU [%s] did not establish a heartbeat with cell [%s] after %s secs"
                        % (aDomUName, aCellName, str(aHeartbeatCheckTimeoutSecs)))
                _cell.mDisconnect()
                return False
        elif re.search(r'\d+$', aTempAlertLog):
            '''
              Case 2 : In case Cell marker is found in rotated alert logs and not in the alert.log file.
                       try searching for hearbeat in the same alert log where marker found.
                       For ex : alert.log.1, alert.log.2,alert.log.3
            '''
            ebLogDebug("Cell heartbeat check command = %s " % _cmd_check_heartbeat_started)
            ebLogInfo("Checking for heartbeat entries in file : %s based on the filtered cell alert log mark." % aTempAlertLog)
            _checked_for_secs = 0
            while _checked_for_secs <= aHeartbeatCheckTimeoutSecs:
                _i, _o, _e = _cell.mExecuteCmd(_cmd_check_heartbeat_started)
                _heartbeat_started = self.mFormatOut(_o)
                if _heartbeat_started:
                    ebLogInfo("DomU heartbeat details were found in the log : %s" % (aTempAlertLog))
                    ebLogInfo("domU [%s] heartbeat started on cell [%s] " % (aDomUName, aCellName))
                    _cell.mDisconnect()
                    break
                sleep(10)
                _checked_for_secs += 10
            else:
                # case 3 : Marker is found in rotated alert.log.<digit>, but heartbeat
                #          can be found in other rotated (alert.log.<digit>).
                _alert_log_count = aTempAlertLog.split(".")[-1].strip()
                if int(_alert_log_count) != 0:
                    for _alert_log_iter in range(_alert_log_count+1):
                        _temp_alert_log = aTempAlertLog.rstrip(aTempAlertLog[-1:]) + str(_alert_log_count)
                        ebLogInfo("Checking for heartbeat entries in file : %s based on the filtered cell alert log mark." % _temp_alert_log)
                        _alert_log_count = int(_alert_log_count)
                        _alert_log_count = _alert_log_count - 1
                        cmd_check_heartbeat_grep_cmd = (_cmd_check_heartbeat_grep_cmd) % (_temp_alert_log, aDomUName)
                        _i, _o, _e = _cell.mExecuteCmd(_cmd_check_heartbeat_grep_cmd)
                        _heartbeat_started = self.mFormatOut(_o)
                        if _heartbeat_started:
                            ebLogInfo("DomU heartbeat details were found in the log : %s" % (_temp_alert_log))
                            ebLogInfo("domU [%s] heartbeat started on cell [%s] " % (aDomUName, aCellName))
                            _cell.mDisconnect()
                            break

                else:
                    # Case 4 :  Cell Marker is found in rotated log and heartbeat message is found 
                    #           in the alert.log as it was not found in any of the rotated alert logs. 
                    _temp_alert_log = self.CELL_ALERT_LOG
                    _cmd_check_heartbeat_grep_cmd = (_cmd_check_heartbeat_grep_cmd) % (_temp_alert_log, aDomUName)
                    _i, _o, _e = _cell.mExecuteCmd(_cmd_check_heartbeat_grep_cmd)
                    _heartbeat_started = self.mFormatOut(_o)
                    ebLogInfo("Checking for heartbeat entries in file : %s based on the filtered cell alert log mark." % _temp_alert_log)
                    if _heartbeat_started:
                        ebLogInfo("DomU heartbeat details were found in the log : %s" % (_temp_alert_log))
                        ebLogInfo("domU [%s] heartbeat started on cell [%s] " % (aDomUName, aCellName))
                        _cell.mDisconnect()
                        return True
                    else:
                        # Case 5 : Cell Marker found in one of alert logs, but Heartbeat message is not 
                        #          found in any of the alert.log file.
                        ebLogError("domU [%s] did not establish a heartbeat with cell [%s] after %s secs"
                                    % (aDomUName, aCellName, str(aHeartbeatCheckTimeoutSecs)))
                        _cell.mDisconnect()
                        return False
        return True

    def mCheckFreshInstall(self, aDom0):
        """
         In case of fresh installation and no upgrade or rollback performed on this environment in the
         past, this method will return True in case the
         TARGET VERSION and the image value on the Dom0 are
         same and will skip the remaining post checks like
         heartbeat etc.
        """

        _cmd_imagehistory_cmd = 'imagehistory | grep "Imaging mode" | wc -l'
        _cmd_get_fresh_image_version = "imagehistory | head -1 | awk '{print $3}'"

        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDom0)
        _i, _o, _e = _node.mExecuteCmd(_cmd_imagehistory_cmd)
        _out = _o.readlines()
        if _out[0] == 1:
            _i, _o, _e = _node.mExecuteCmd(_cmd_get_fresh_image_version)
            _output = _o.readlines()
            if self.__target_version == _output[0]:
                ebLogInfo("Current environment seems like a fresh install. Current Dom0 version : %s , Target Version : %s."
                                                               % (_output[0], self.__target_version))
                _node.mDisconnect()
                return True
        _node.mDisconnect()
        return False

    def _mPostDom0PatchCheck(self,aDom0, aCellAlertLogMark, aDomUList, 
                             aPrePatchVersion, aPostPatchTargetVersion, 
                             aRollback, aTaskType=None,aCellAlertLogList=None):
        """
        Returns True if all checks pass, False if any of the checks failed.
        checks currently done:
        *ping/ssh into the dom0
        *verify the image is listed as sucess
        *verify new version is what we expected for upgrade or rollback
        *check that all domUs are up
        *check db services up on dom0
        *check that db has started on domUs (currently just a sleep)
        """

        ebLogInfo("Starting post patch checks for " + aDom0)

        '''
         Check that we can ping and ssh into dom0
         Check that all the domU that were up before patching have come up
        '''
        _check_dom0_up_for_secs = 0
        _check_domU_up_for_secs = 0
        if aTaskType not in [ self.TASK_POSTCHECK ]:
            _timeout_for_dom0_domU_up = 600
        else:
            _timeout_for_dom0_domU_up = 3

        while _check_dom0_up_for_secs < _timeout_for_dom0_domU_up:
            if self.__clupatchcheck.mPingNode(aDom0):
                break
            sleep(10)
            _check_dom0_up_for_secs += 10
        else:
            ebLogError("dom0 %s did not come back online (not ping-able or ssh-able) post patch" % aDom0)
            return False

        #check that the image is seen as success
        if not self.__clupatchcheck.mCheckImageSuccess(aDom0):
            ebLogError("post-patch check: dom0 %s image is not seen as success via imageinfo command" % aDom0)
            return False
   
        '''
         check if the environment is a fresh installation and 
         skip heartbeat related checks if True.
        '''
        if self.mCheckFreshInstall(aDom0):
            return True

        '''
         Image version checks are not performed as during
         independent postcheck option as we are not aware 
         whether upgrade or rollback was performed.
        '''
        if aTaskType not in [ self.TASK_POSTCHECK ]:    
            # Check that the dom0 is at the requested version. if it was a rollback we just
            # check for the version to be lower than what it previously was.
            _current_dom0_version = self.__clupatchcheck.mCheckTargetVersion(aDom0, self.PATCH_DOM0)
            if aRollback:
                if self.__clupatchcheck.mCheckTargetVersion(aDom0, self.PATCH_DOM0, aPrePatchVersion) >= 0:
                    ebLogError("dom0 rollback was requested but the version seems to be unchanged, found version %s, expected to be lower than %s" % (aPrePatchVersion, _current_dom0_version))
                    return False
            #if not a rollback, we need to be at the exact requested target version
            elif self.__clupatchcheck.mCheckTargetVersion(aDom0, self.PATCH_DOM0, aPostPatchTargetVersion) != 0:
                ebLogError("dom0 is not at the requested upgrade version %s, found version %s"
                           % (aPrePatchVersion, _current_dom0_version))
                return False

        while _check_domU_up_for_secs < _timeout_for_dom0_domU_up:
            if self.__clupatchcheck.mCheckVMsUp(aDom0, aDomUList):
                break
            sleep(10)
            _check_domU_up_for_secs += 10
        else:
            ebLogError("expected all of the following domus %s to be up on %s, but only %s were up"
                       % (str(aDomUList), aDom0, str(self._mGetDomUList(aDom0, aFromXmList=True))))
            return False

        #check that db services are up
        if not self.__clupatchcheck.mCheckDBServices(aDBNode=aDom0, aCheckRunning=True):
            ebLogError("db services were not up on dom0 %s " % aDom0)
            return False

        #Check to make sure the domUs have a heartbeat to all the cells
        if aCellAlertLogMark:
            # bug 27263414
            _cmd_print_file_after_match_template = "sed -ne '/^%s/{s///; :a' -e 'n;p;ba' -e '}' %s"
            _cmd_check_heartbeat_started_template = " | grep -i heartbeat | grep -ai start | grep -ai %s"
            _heartbeat_check_timeout_secs = int(self.EXADATA_PATCH_GRID_HEARTBEAT_TIMEOUT_SEC)
            #for each domU, check if it has started clusterware heartbeat with all the cells
            for _domU_name in aDomUList:
                # bug 26678535: heart beat message in the cell 'alert.log' only 
                # contains the DOMU hostnames without the FQDN. So strip off
                # the FQDN from the DOMU hostname before doing anything.
                _domu_hostname_no_fqdn = _domU_name.split('.')[0]

                #host names are cut to 32 chars on the cell alert logs
                _32_char_domU_name = _domu_hostname_no_fqdn[:32]

                #only check for heartbeat on cells that have griddisks in use by asm
                for _cell_name in self.__clupatchcheck.mVerifyCellsInUseByASM(self._mGetCellList()):
                    # Search marker and cell alert log from the list of cell alert logs.
                    _cmd_get_alert_log_file_using_cellmark = 'grep -ai "%s" `ls -tr %s*` | tail -1' % (aCellAlertLogMark, self.CELL_ALERT_LOG)
                    _cell = exaBoxNode(get_gcontext())
                    _cell.mConnect(aHost=_cell_name)
                    _in,_out,_err = _cell.mExecuteCmd(_cmd_get_alert_log_file_using_cellmark)
                    _output = _out.readlines()
                    
                    '''
                     In case of no log rotation enabled on this environment, only
                     one alert.log exists at all times and hence this below check 
                     is required.
                     
                     [root@slcs27celadm01 trace]# ls -ltr *alert.log* | wc -l
                     1
                     [root@slcs27celadm01 trace]#

                     [root@slcs27celadm02 trace]# ls -ltr *alert.log* | wc -l
                     2
                     [root@slcs27celadm02 trace]#
                    '''

                    _cmd_alert_list_count = 'ls -tr %s* | wc -l' % self.CELL_ALERT_LOG
                    _in_count,_out_count,_err_count = _cell.mExecuteCmd(_cmd_alert_list_count)
                    _output_count = _out_count.readlines()
                    if len(_output) == 0:
                        ebLogInfo("No cell alert marker : %s found in any of the alert logs on Cell : %s" % (aCellAlertLogMark, _cell_name))
                        _cell.mDisconnect()
                        continue
                    elif int(_output_count[0]) == 1:
                        # In case log rotation is disabled in the environment.
                        _temp_alert_log = self.CELL_ALERT_LOG
                        _cell_alert_log_mark = _output[0].strip()
                        _cell.mDisconnect()
                    else:
                        _temp_alert_log = _output[0].split(":")[0]
                        if aTaskType in [ self.TASK_POSTCHECK ]:
                            _cell_alert_log_mark = _output[0].split(":")[1]
                        _cell.mDisconnect()

                    '''
                     In case of independent postcheck option and discarded nodes list check,
                     "aCellAlertLogMark" need to be searched from all the alert log files.
                    '''

                    if aTaskType in [ self.TASK_POSTCHECK ]:
                        _heartbeat_check_timeout_secs = 1

                        if not self.mGetStandaloneHeartbeat(_cmd_print_file_after_match_template ,\
                                                         _cmd_check_heartbeat_started_template ,\
                                                         _32_char_domU_name, _cell_name, _cell_alert_log_mark,\
                                                         _temp_alert_log, _heartbeat_check_timeout_secs):
                            return False
                    else:
                        ebLogInfo("Checking heartbeat from domU [%s] to cell [%s]" % (_domU_name, _cell_name))
                        _cmd_print_alert_log_after_mark = _cmd_print_file_after_match_template % (aCellAlertLogMark,_temp_alert_log)
                        _cmd_heartbeat_started_on_cell = _cmd_check_heartbeat_started_template % (_32_char_domU_name)
                        _cmd_check_heartbeat_started =  _cmd_print_alert_log_after_mark + _cmd_heartbeat_started_on_cell
                        _heartbeat_check_timeout_short_secs = 1
                        _cell = exaBoxNode(get_gcontext())
                        _cell.mConnect(aHost=_cell_name)

                        if _temp_alert_log.endswith('.log'):
                            '''
                             Case 1 : When both Cell Marker and the heartbeat message are found 
                                      in the alert.log file.
                            '''
                            ebLogDebug("Cell heartbeat check command = %s " % _cmd_check_heartbeat_started)
                            _checked_for_secs = 0
                            while _checked_for_secs <= _heartbeat_check_timeout_secs:
                                _i, _o, _e = _cell.mExecuteCmd(_cmd_check_heartbeat_started)
                                _heartbeat_started = self.mFormatOut(_o)
                                if _heartbeat_started:
                                    ebLogInfo("DomU heartbeat details were found in the log : %s" % (_temp_alert_log))
                                    ebLogInfo("domU [%s] heartbeat started on cell [%s] " % (_domU_name, _cell_name))
                                    _cell.mDisconnect()
                                    break

                                sleep(10)
                                _checked_for_secs += 10
                            else:
                                ebLogError("domU [%s] did not establish a heartbeat with cell [%s] after %s secs"
                                           % (_domU_name, _cell_name, str(_heartbeat_check_timeout_secs)))
                                _cell.mDisconnect()
                                return False
                        elif re.search(r'\d+$', _temp_alert_log):
                            '''
                             case 2 : In this case, Cell Marker was found in alert.log.0 and here we 
                                      try to see if heartbeat messages are observed in these files. 
                                      Heartbeat timeout value(_heartbeat_check_timeout_secs) in this 
                                      case is 1 second.
                            '''
                            ebLogInfo("Cell alert log mark found in the log file : %s" % _temp_alert_log)
                            ebLogDebug("Cell heartbeat check command = %s " % _cmd_check_heartbeat_started)
                            _checked_for_secs = 0
                            while _checked_for_secs <= _heartbeat_check_timeout_short_secs:
                                _i, _o, _e = _cell.mExecuteCmd(_cmd_check_heartbeat_started)
                                _heartbeat_started = self.mFormatOut(_o)
                                if _heartbeat_started:
                                    ebLogInfo("DomU heartbeat details were found in the log : %s" % (_temp_alert_log))
                                    ebLogInfo("domU [%s] heartbeat started on cell [%s] " % (_domU_name, _cell_name))
                                    _cell.mDisconnect()
                                    break
                                    sleep(10)
                                    _checked_for_secs += 10
                            else:
                                '''
                                 case 3 : In this case self.CELL_ALERT_LOG that is the alert.log  is
                                          used as an input file because, although the Cell marker
                                          pattern might have been found in alert.log.0, due to
                                          log rotation heartbeat messages would be written into alert log.
                                          Heartbeat timeout value(_heartbeat_check_timeout_secs) in this case is 40 minutes.
                                '''
                                ebLogDebug("Cell heartbeat check command = %s " % _cmd_check_heartbeat_started)
                                _checked_for_secs = 0
                                _cmd_check_heartbeat_started = "grep -ai heartbeat %s | grep -ai start | grep -ai %s" % (self.CELL_ALERT_LOG, _32_char_domU_name)
                                while _checked_for_secs <= _heartbeat_check_timeout_secs:
                                    _i, _o, _e = _cell.mExecuteCmd(_cmd_check_heartbeat_started)
                                    _heartbeat_started = self.mFormatOut(_o)
                                    if _heartbeat_started:
                                        ebLogInfo("DomU heartbeat details were found in the log : %s" % (self.CELL_ALERT_LOG))
                                        ebLogInfo("domU [%s] heartbeat started on cell [%s] " % (_domU_name, _cell_name))
                                        _cell.mDisconnect()
                                        break
                                    sleep(10)
                                    _checked_for_secs += 10
                                else:
                                    '''
                                      Case 4 : When heartbeat is not found in any of the alert.log  
                                              even when Cell Marker was found in one of the alert log.
                                    '''
                                    ebLogError("domU [%s] did not establish a heartbeat with cell [%s] after %s secs"
                                               % (_domU_name, _cell_name, str(_heartbeat_check_timeout_secs)))
                                    _cell.mDisconnect()
                                    return False

        #TODO: here we need to make sure the db is up for vms, but we dont have a reliable way yet so just sleep
        if aTaskType not in [ self.TASK_POSTCHECK ]:
            sleep(120)

        #Fedramp configuation check to restore fedramp configuration
        if self.__fedramp == 'ENABLED':
            ebLogInfo("Executing fedramp file restore operations as the value of Fedamp Enable is set to %s" % self.__fedramp)
            _Pre_Aud = "/etc/audit/audit.rules_FED"
            _Post_Aud = "/etc/audit/audit.rules"
            _aNodesList = self._mGetDom0List()
            self.mFedrampDom0RestoreConfig(_aNodesList, _Pre_Aud, _Post_Aud)

        return True

    def _mGatherCellPreCheckData(self, aCellsList):
        """
        Gets the cells data before running any patch task. This data will be used in the postcheck.
        """

        _data = {}

        for _cell in aCellsList:
            _data[_cell] = {'version':          None,
                            'cell_services':    {}}

            # Update status
            self.mUpdatePatchStatus(True, self.STEP_GATHER_NODE_DATA,_cell)

            ebLogInfo('Starting  basic data check in cell %s' % _cell)

            _data[_cell]['version'] = self.__clupatchcheck.mCheckTargetVersion(_cell, self.PATCH_CELL)
            _data[_cell]['cell_services'] = self.__clupatchcheck.mCheckCellServices(_cell)

        return _data

    def _mGatherIBSwitchPreCheckData(self, aIBSwitchesList):
        """
        Gets the ibswitches data before running any patch task. This data will be used in the postcheck.
        """

        _data = {}

        for _ibswitch in aIBSwitchesList:
            _data[_ibswitch] = {'version':  None,
                                'sm':       None}

            # Update status
            self.mUpdatePatchStatus(True, self.STEP_GATHER_NODE_DATA, _ibswitch)

            ebLogInfo('Starting  basic data check in ibswitch %s' % _ibswitch)
            _data[_ibswitch]['version'] = self.__clupatchcheck.mCheckIBSwitchVersion(_ibswitch)
            _data[_ibswitch]['sm'] = self.__clupatchcheck.mCheckIBSwitchSMState(_ibswitch)
            _data[_ibswitch]['ib_partition_data'] = self.__clupatchcheck.mCheckIBSwitchPartitions(_ibswitch)
        return _data

    def _mDoCellPostCheck(self, aCellsData, aTaskType, aWait=True):
        """
        Runs a basic postcheck in the cells. It compares the data taken before running the patchmgr.
        """

        # Sleep for 5 minutes before checking. Image status check may fail if we don't wait
        if aWait:
            # Update status
            self.mUpdatePatchStatus(True, self.STEP_POSTCHECKS, "waiting for 5 min to start")
            ebLogInfo('Waiting for 5 minutes before running the postcheck')
            sleep(300)

        def _check_cell(aCell, aData):

            # Ping host
            if not self.__clupatchcheck.mPingNode(aCell):
                self.mAddError(aCell, 1006)
                return False

            # Check target version
            _rc = self.__clupatchcheck.mCheckTargetVersion(aCell, self.PATCH_CELL, aData['version'])

            if aTaskType == self.TASK_PATCH:
                if _rc <= 0:
                    ebLogError("Current version was expected to be higher than original version")
                    self.mAddError(aCell, 1007)
                    return False
            elif aTaskType == self.TASK_ROLLBACK:
                if _rc >= 0:
                    ebLogError("Current version was expected to be lower than original version")
                    self.mAddError(aCell, 1007)
                    return False
            else:
                if _rc != 0:
                    ebLogError("Current version was expected to be equal to original version")
                    self.mAddError(aCell, 1007)
                    return False

            # Check image status
            if not self.__clupatchcheck.mCheckImageSuccess(aCell):
                ebLogError("Image status not successful in cell %s" % aCell)

                # Get error messages from /var/log/cellos/validations.log /var/log/cellos/vldrun.*.log
                _errors = 'validations.log/vldrun.*.log output:\n'

                _cell = exaBoxNode(get_gcontext())
                _cell.mConnect(aHost=aCell)
                _i, _o, _e = _cell.mExecuteCmd("grep -as '\[ERROR\|\[FAIL' /var/log/cellos/validations.log"\
                                               " /var/log/cellos/vldrun.*.log")
                _output = _o.readlines()
                if _output:
                    _errors += str("".join(_output))
                _cell.mDisconnect()

                self.mAddError(aCell, 1008, aComment=_errors)
                return False
            
            # Check for Fedramp configurtion and restore relevant files
            if self.__fedramp == 'ENABLED' and aTaskType in [ self.TASK_PATCH, self.TASK_ROLLBACK ]:
                self.mFedrampRestoreConfig("cells")

            # Check cell services"
            if not self.__clupatchcheck.mCheckCellServices(aCell, aData['cell_services']):
                if not self.__clupatchcheck.mCheckCellServices(aCell, aData['cell_services'], aCheckRunning=True):
                    self.mAddError(aCell, 1009)
                    ebLogError('Cell services are not up in %s' % aCell)
                    return False
            return True

        _ret = True

        for _cell in aCellsData.keys():
            # Update status
            self.mUpdatePatchStatus(True, self.STEP_POSTCHECKS, _cell)
            # Start check
            ebLogInfo('Starting basic postcheck in cell %s' % _cell)
            _out = _check_cell(_cell, aCellsData[_cell])
            if _out:
                ebLogInfo("Successful postcheck in cell %s" % _cell)
            _ret &= _out

        return _ret

    def _mDoIBSwitchPostCheck(self, aIBSwitchesData, aTaskType):
        """
        Runs a basic postcheck in the ibswitches. It compares the data taken before running the patchmgr.
        """

        def _check_ibswitch(aIBSwitch, aData):
            # Ping host
            if not self.__clupatchcheck.mPingNode(aIBSwitch):
                self.mAddError(aIBSwitch, 1006)
                return False

            ### Check version
            _ret = self.__clupatchcheck.mCheckIBSwitchVersion(aIBSwitch, aData['version'])

            if aTaskType == self.TASK_PATCH:
                if _ret <= 0:
                    ebLogError("Current version was expected to be higher than original version")
                    self.mAddError(aIBSwitch, 1010)
                    return False
            elif aTaskType == self.TASK_ROLLBACK:
                if _ret >= 0:
                    ebLogError("Current version was expected to be lower than original version")
                    self.mAddError(aIBSwitch, 1010)
                    return False
            else:
                if _ret != 0:
                    ebLogError("Current version was expected to be equal to original version")
                    self.mAddError(aIBSwitch, 1010)
                    return False

            # Check SM state
            if not self.__clupatchcheck.mCheckIBSwitchSMState(aIBSwitch, aData['sm']):
                self.mAddError(aIBSwitch, 1011)
                return False

            # Check smnodes and smpartition list
            if not self.__clupatchcheck.mCheckIBSwitchPartitions(aIBSwitch, aData['ib_partition_data']):
                ebLogError("The output for the command is changed across upgrade or rollback: (1) smnodes list (2) smpartition list active no-page")
                self.mAddError(aIBSwitch, 1013)
                return False
             
            # Check for Fedramp configurtion and restore relevant files
            if self.__fedramp == 'ENABLED' and aTaskType in [ self.TASK_PATCH, self.TASK_ROLLBACK ]:
                self.mFedrampRestoreConfig("ibswitch")

            return True

        _ret = True

        for _ibswitch in aIBSwitchesData.keys():
            # Update status
            self.mUpdatePatchStatus(True, self.STEP_POSTCHECKS, _ibswitch)
            # Start check
            ebLogInfo('Starting basic postcheck in ibswitch %s' % _ibswitch)
            _out = _check_ibswitch(_ibswitch, aIBSwitchesData[_ibswitch])
            if _out:
                ebLogInfo("Successful postcheck in ibswitch %s" % _ibswitch)
            _ret &= _out

        return _ret

    def _mFilterNodesToPatch(self, aNodesList, aNodeType, aTaskType):
        """
        Filters the nodes that must be patched based on the active/inactive
        version and the target version. It returns two lists: one for available 
        nodes and one for discarded nodes:
        [nodes_to_patch, discarded_nodes]
        """

        _nodes_to_patch = []
        _discarded_nodes = []

        # Update status
        self.mUpdatePatchStatus(True, self.STEP_FILTER_NODES)

        for _node in aNodesList:
            _active_version = self.__clupatchcheck.mCheckTargetVersion(_node, 
                                        aNodeType)
            _active_compare = self.__clupatchcheck.mCheckTargetVersion(_node, 
                                        aNodeType, self.__target_version)

            if not _active_version or _active_compare is None:
                ebLogInfo('No version available to compare in %s. Node will be discarded.' % _node)
                _discarded_nodes.append(_node)
                continue
            
            if (aTaskType in [self.TASK_ROLLBACK, self.TASK_ROLLBACK_PREREQ_CHECK]):
                if _active_compare < 0:
                    ebLogInfo('Node %s is already at a lower version. Node will be discarded' % _node)
                    _discarded_nodes.append(_node)
                    continue

                _inactive_version = \
                    self.__clupatchcheck.mCheckTargetVersion(_node, aNodeType, 
                                                                 aInactiveImage=True)

                if not _inactive_version:
                    ebLogInfo('No rollback image available in %s. Node will be discarded' % _node)
                    _discarded_nodes.append(_node)
                    continue

                _inactive_compare = \
                    self.__clupatchcheck.mCheckTargetVersion(_node, aNodeType, 
                                                                _inactive_version)

                if _inactive_compare is None or _inactive_compare <= 0:
                    ebLogInfo('Rollback image version is higher than active version in %s. '\
                                'Node will be discarded' % _node)
                    _discarded_nodes.append(_node)
                    continue
            elif (aTaskType in [self.TASK_POSTCHECK]):
                pass
            else:
                #Bug28126586 - Need to ensure current image status is success,
                # otherwise, no point in continuing further 
                _cmd = 'imageinfo -status' 
                _node_tmp = exaBoxNode(get_gcontext())
                _node_tmp.mConnect(aHost=_node)
                _i, _o, _e = _node_tmp.mExecuteCmd(_cmd)
                _node_tmp.mDisconnect()

                _image_status =  _o.readline()
                if _image_status:
                    if not _image_status.strip().lower() == 'success': 
                        raise Exception("Current image state on %s is invalid. It should be success, but got: %s" % (_node, _image_status.strip()))

                if _active_compare >=  0:
                    ebLogInfo('Node %s is already up to date. Node will be discarded' % _node)
                    _discarded_nodes.append(_node)
                    continue

            ebLogInfo('Adding %s to available nodes list' % _node)
            _nodes_to_patch.append(_node)

        return [_nodes_to_patch, _discarded_nodes]

    def _mFilterIBSwitchesToPatch(self, aIBSwitchList, aTaskType):
        """
        Filters the ibswitches that must be patched based on the active/inactive version and
        the target version. It returns two lists: one for availables switches and one for discarded switches:
        [ibswitches_to_patch, discarded_ibswitches]
        """

        _nodes_to_patch = []
        _discarded_nodes = []

        # Update status
        self.mUpdatePatchStatus(True, self.STEP_FILTER_NODES)

        for _ibswitch in aIBSwitchList:
            if aTaskType in [self.TASK_PATCH, self.TASK_PREREQ_CHECK]:
                _ret = self.__clupatchcheck.mCheckIBSwitchVersion(_ibswitch,self.__ibswitch_upgrade_version)
                if _ret >= 0:
                    ebLogInfo("IBSwitch firmware already up to date in %s. IBSwitch will be discarded." % _ibswitch )
                    _discarded_nodes.append(_ibswitch)
                    continue
            if aTaskType in [self.TASK_ROLLBACK, self.TASK_ROLLBACK_PREREQ_CHECK]:
                _ret = self.__clupatchcheck.mCheckIBSwitchVersion(_ibswitch,self.__ibswitch_rollback_version)
                if _ret <= 0:
                    ebLogInfo("IBSwitch firmware already at a lower version in %s. IBSwitch will be discarded." % \
                               _ibswitch)
                    _discarded_nodes.append(_ibswitch)
                    continue
            ebLogInfo('Adding %s to available ibswitches list' % _ibswitch)
            _nodes_to_patch.append(_ibswitch)

        return [_nodes_to_patch, _discarded_nodes]

    def _mGetIBSwitchTargetVersion(self):
        """
        Gets the ibswitch firmware target version. EXADATA_IMAGE_IBSWITCH_UPGRADE_VERSION and
        EXADATA_IMAGE_IBSWITCH_DOWNGRADE_VERSION are env variables used in the patchmgr to set the ibswitch version.
        This function looks for these variables using printenv. If not found, then it takes the default
        value being used in patchmgr script.
        """

        _cmd1 = 'printenv|grep -a %s'
        _cmd2 = "grep -P 'export\s*%s\s*=' "+self.__cells_ibswitches_patchmgr

        _dom0 = exaBoxNode(get_gcontext())
        _dom0.mConnect(aHost=self.__dom0_to_patch_cells_ibswitches)

        def _parse_patchmgr(aVariable):
            _version = None

            try:
                _in, _out, _err = _dom0.mExecuteCmd(_cmd1 % aVariable)
                _output = _out.readlines()

                if _output:
                    if _output[0].strip() != '':
                        _re_out = re.match('.*%s=(.*)', _output[0].strip())
                        if _re_out:
                            _version = _re_out.groups()[0]

                if not _version:
                    _in, _out, _err = _dom0.mExecuteCmd(_cmd2 % aVariable)
                    _output = _out.readlines()
                    if _output:
                        if _output[0].strip() != '':
                            _re_out = re.match('.*=(.*)', _output[0].strip())
                            if _re_out:
                                _version = _re_out.groups()[0]
            except Exception as e:
                ebLogError("Error while fetching ibswitch target version: "+str(e))

            return _version

        _upgrade_version = _parse_patchmgr('EXADATA_IMAGE_IBSWITCH_UPGRADE_VERSION')
        _rollback_version = _parse_patchmgr('EXADATA_IMAGE_IBSWITCH_DOWNGRADE_VERSION')

        _dom0.mDisconnect()
        return [_upgrade_version, _rollback_version]

    def _mCellsCleanUp(self, aListFilePath, aCallbacks):
        """
        Runs the cell clean up to generate the diagnosis files.
        """

        # Update status
        self.mUpdatePatchStatus(True, self.STEP_CLEAN_UP)

        _exit_code = 0
        _input_file_name = aListFilePath.split("/")[-1]
        _cell_cleanup_cmd = "cd %s;./patchmgr  -cells %s -cleanup" % (self.__cells_ibswitches_patch_base_after_unzip,
                                                                      _input_file_name)
        ebLogInfo("patch_cleanup: " + _cell_cleanup_cmd)

        # Connect to Dom0
        _dom0 = exaBoxNode(get_gcontext())
        _dom0.mConnect(aHost=self.__dom0_to_patch_cells_ibswitches)

        # Execute cleanup
        _dom0.mExecuteCmdAsync(_cell_cleanup_cmd, aCallbacks)
        _exit_code = int(_dom0.mGetCmdExitStatus())

        if _exit_code != 0:
            # Retry cleanup. See bug 23341346
            ebLogInfo("Cleanup failed with exit_code=%d. Waiting for 5 minutes before retry." % _exit_code)
            sleep(300)
            # Execute cleanup again
            _dom0.mExecuteCmdAsync(_cell_cleanup_cmd, aCallbacks)
            _exit_code = int(_dom0.mGetCmdExitStatus())

        # Disconnect Dom0
        _dom0.mDisconnect()

        return _exit_code

    def _mSetLaunchNodeToPatchOtherNondes(self, aOperation):
        """
        Selects and sets 2 bases for dom0 or domU patching. 
        use one to patch all other dom0s or domUs
        and the other to patch initial dom0 or domU
        """

        ebLogInfo("Set Launch Node to patch other nodes.")

        _dom0U_list = self._mReturnPatchingDom0DomUList()
        if (aOperation == self.PATCH_DOM0):
            _launch_node_candidates = list(zip(*_dom0U_list))[0]
            _local_patch_zip        = self.__dom0_local_patch_zip
            _patch_zip_name         = self.__dom0_patch_zip_name
            _patch_zip_size_mb      = self.__dom0_patch_zip_size_mb
            _patch_base             = self.__dom0_patch_base
            _patch_zip              = self.__dom0_patch_zip
            _patchmgr               = self.__dom0_patchmgr
            _patch_necessary_space_mb = self.__dom0_patch_necessary_space_mb
            _local_patch_zip2         = self.__dom0_local_patch_zip2
            _patch_base_after_unzip   = self.__dom0_patch_base_after_unzip
    
        if (aOperation == self.PATCH_DOMU):
            _launch_node_candidates = list(zip(*_dom0U_list))[1]
            _local_patch_zip   = self.__domu_local_patch_zip
            _patch_zip_name    = self.__domu_patch_zip_name
            _patch_zip_size_mb = self.__domu_patch_zip_size_mb
            _patch_base        = self.__domu_patch_base
            _patch_zip         = self.__domu_patch_zip
            _patchmgr          = self.__domu_patchmgr
            _patch_necessary_space_mb = self.__domu_patch_necessary_space_mb
            _local_patch_zip2         = self.__domu_local_patch_zip2
            _patch_base_after_unzip   = self.__domu_patch_base_after_unzip
     
        #need a new list since we will modify it
        _launch_node_candidates = list(_launch_node_candidates) 

        # Bug29305666 - prepare correct launch node list to upgrade/downgrade specified 
        # node
        _valid_node_provided = False
        if self.mCheckSingleNodeUpgradeEnable():
            ebLogInfo("Single node patch is opted.") 
            _single_node_name = self.mGetSingleNodeUpgradeName()
            ebLogInfo("User specified node '%s' for patch." % _single_node_name)
            _launch_node_candidates_for_single_node_upgrade = []
            if self.__clupatchcheck.mPingNode(_single_node_name):
                if _single_node_name in _launch_node_candidates:
                    _launch_node_candidates_for_single_node_upgrade.append(_single_node_name)
                    _launch_node_candidates.remove(_single_node_name)
                    _valid_node_provided = True
                else:
                    _errmsg = ("User specified node '%s' does not exist in the original launch node candidates: '%s'."\
                                % (_single_node_name, _launch_node_candidates))
                    ebLogError(_errmsg)
                    raise Exception(_errmsg)
            else:
                _errmsg = ("User requested node %s upgrade is not pingable." % _single_node_name)
                ebLogError(_errmsg)
                raise Exception(_errmsg)

            if _valid_node_provided:
                for _launch_node in _launch_node_candidates:
                    if self.__clupatchcheck.mPingNode(_launch_node):
                        _launch_node_candidates_for_single_node_upgrade.append(_launch_node)
                        _launch_node_candidates = _launch_node_candidates_for_single_node_upgrade
        else:
            ebLogInfo("Single node patch is not opted.") 
          
        _selected_launch_nodes = []
        _errmsg_template = "Unable to set a %s to act as a patch manager for "
        _msgs = ["other %s",  # msg for lauch node to patch other nodes
                "the initial %s patcher"]  # msg for launch_node to patch initial launch node

        ebLogInfo("Launch node candidates: %s" % (str(_launch_node_candidates))) 

        #loop twice since we need to set 2 dom[0U]s as dom[0U] patchers
        for _msg in _msgs:
            _selected_launch_node = self._mSetLaunchNodeAsPatchBase(
                    aLaunchNodeCandidates=_launch_node_candidates,
                    aLocalPatchZipFile=_local_patch_zip,
                    aPatchZipName=_patch_zip_name,
                    aPatchZipSizeMb=_patch_zip_size_mb,
                    aRemotePatchBase=_patch_base,
                    aRemotePatchZipFile=_patch_zip,
                    aRemotePatchmgr=_patchmgr,
                    aRemoteNecessarySpaceMb=_patch_necessary_space_mb,
                    aSuccessMsg=(_msg % (aOperation.upper())),
                    aMoreFilesToCopy=[(_local_patch_zip2, 
                                       _patch_base_after_unzip)])

            if not _selected_launch_node:
                _errmsg = ((_errmsg_template %(_selected_launch_node))
                          +(_msg %(aOperation)))
                ebLogError(_errmsg)
                raise Exception(_errmsg)
            else:
                for _launch_node in _launch_node_candidates:
                    if (_launch_node in self.__json_status and 
                        'error-1000' in _launch_node):
                        del self.__json_status[_launch_node]['error-1000']

            _selected_launch_nodes.append(_selected_launch_node)
            _launch_node_candidates.remove(_selected_launch_node)

        ebLogInfo("Selected launch nodes %s" % (str(_selected_launch_nodes)))
        return _selected_launch_nodes

    def _mSetDom0ToPatchCellsIBSwitches(self):
        """
        Selects ans sets the necessary files on a dom0 in order to patch cells and ibswitches.
        """

        if (self.mIsClusterLessUpgrade()):
            _dom0s = list(self.mGetCabinetLaunchNode().split()) 
        else:
            _dom0s = self._mGetDom0List()

        _dom0_to_patch_cells_ibswitches = self._mSetLaunchNodeAsPatchBase(
                aLaunchNodeCandidates=_dom0s,
                aLocalPatchZipFile=self.__cells_ibswitches_local_patch_zip,
                aPatchZipName=self.__cells_ibswitches_patch_zip_name,
                aPatchZipSizeMb=self.__cells_ibswitches_patch_zip_size_mb,
                aRemotePatchBase=self.__cells_ibswitches_patch_base,
                aRemotePatchZipFile=self.__cells_ibswitches_patch_zip,
                aRemotePatchmgr=self.__cells_ibswitches_patchmgr,
                aRemoteNecessarySpaceMb=self.__cells_ibswitches_patch_necessary_space_mb,
                aSuccessMsg="cells and ibswitches")

        if not _dom0_to_patch_cells_ibswitches:
            _errmsg = "Unable to set a dom0 to act as patch manager for cells/ibswitches"
            ebLogError(_errmsg)
            raise Exception(_errmsg)
        else:
            for _dom0 in _dom0s:
                if _dom0 in self.__json_status:
                    if 'error-1000' in _dom0:
                        del self.__json_status[_dom0]['error-1000']

        return _dom0_to_patch_cells_ibswitches

    def _mSetLaunchNodeAsPatchBase(self, 
                                   aLaunchNodeCandidates, 
                                   aLocalPatchZipFile, 
                                   aPatchZipName, aPatchZipSizeMb,
                                   aRemotePatchBase, aRemotePatchZipFile, 
                                   aRemotePatchmgr, aRemoteNecessarySpaceMb,  
                                   aSuccessMsg="", aMoreFilesToCopy=None):
        """
        Makes sure the patchmgr is installed alog with any other files for 
        its correct use. Generic method to install patchmgr on a given node to 
        patch cells/ibswitches, dom0s or domus
        """

        # Update db status
        self.mUpdatePatchStatus(True, self.STEP_SELECT_LAUNCH_NODE)

        # In case of Postcheck, ksplice and oneoff operations, we need not
        # to copy any of the patchmgr related files or images.
        if self.__task in [ self.TASK_KSPLICE, self.TASK_ONEOFF, self.TASK_POSTCHECK ]:
            ebLogInfo("Ignoring file copy of exadata patches for task : %s is performed." % (self.__task))
            _launch_node = aLaunchNodeCandidates[0].strip()
            return _launch_node            

        _local_patch_path = os.path.dirname(aLocalPatchZipFile)
        self.mValidateImageCheckSum(aPatchZipName, _local_patch_path, aRemotePatchBase ,aLaunchNodeCandidates , aRemoteNecessarySpaceMb)

        if aMoreFilesToCopy:
            for _file, _copy_to in aMoreFilesToCopy:
                _file_name = _file.split("/")[-1]
                _local_patch_path = os.path.dirname(_file)
                self.mValidateImageCheckSum(_file_name, _local_patch_path, _copy_to ,aLaunchNodeCandidates, aRemoteNecessarySpaceMb)

        for _launch_node in aLaunchNodeCandidates:
            #TODO: fix all the disconnect calls. Can maybe connect/disconnect
            # during each cmd? whats the best way?     
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=_launch_node)

            #make sure we can get the patch to the directory that came out of unziping the patch
            if not _node.mFileExists(aRemotePatchmgr):
                ebLogError("expected patchmgr script %s:%s but it was not found.Patch zip structure may have changed"
                           % (str(_launch_node), aRemotePatchmgr))
                _node.mDisconnect()
                self.mAddError(_launch_node, 1000, 2003)
                #TODO give it another shot on a different  dom0 (continue), or just error out (return None)
                continue

            ebLogInfo("Selecting %s as a patch base for %s. patchmgr is at %s"
                      % (str(_launch_node), aSuccessMsg, aRemotePatchmgr))
            _node.mDisconnect()
            return _launch_node
        else:
            ebLogError("None of %s were eligible bases for the patch manager" % (str(aLaunchNodeCandidates)))
            return None

    # Prepare environment before any operation
    def _mPrepareEnvironment(self, aDom0, aNodesList, aBaseDir):
        """
        Creates the input files and sets passwordless ssh between the dom0 
        and the nodes that will be patched.
        """

        # Update status
        self.mUpdatePatchStatus(True, self.STEP_PREP_ENV)

        # Set passwordless connection between dom0 and cells/ibswitches
        self.__ssh_env_setup = ebCluSshSetup(self.__cluctrl)
        if self.__ssh_env_setup:
            _key = self.__ssh_env_setup.mSetSSHPasswordless(aDom0, aNodesList)

        # Create cells input file
        _input_file = self._mCreateNodesFile(aBaseDir, aDom0, aNodesList)

        return (_key, _input_file)

    # Clean environment after any operation
    def _mCleanEnvironment(self, aDom0, aNodesList, aListFilePath, aBaseDir, aLogDir, aNodeType):
        """
        Deletes input files and passwordless ssh between nodes. It will also 
        copy the log files from the remote dom0 to the local log directory.
        """

        ebLogInfo("Copying diagnostic logs to exacloud: %s" % self.__log_path)

        # Update status
        self.mUpdatePatchStatus(True, self.STEP_CLEAN_ENV+'_'+aNodeType)

        _std_code = ''
        if aNodeType == self.PATCH_DOM0:
            _std_code = str(self._mGetDom0FileCode(aDom0, aBaseDir))

        # Get .stdout and .stderr log files. Patchmgr logs present in -log_dir
        # in case of ibswitch upgrade (aLogDir), otherwise, those present in 
        # base directory which has latest content
        if aNodeType == self.PATCH_IBSWITCH:
            self._mGetPatchMgrOutFiles(aDom0, aLogDir, _std_code)
        else:
            self._mGetPatchMgrOutFiles(aDom0, aBaseDir, _std_code)

        # Get diagnosis .tar files in the cells, domus 
        self._mGetPatchMgrDiagFiles(aDom0, aNodeType, aNodesList, aLogDir)

        # Get patchmgr console that we generate using nohup 
        self._mGetPatchMgrMiscLogFiles(aDom0, aLogDir)
  
        # Get <cellname>.log files from the patchmgr_log_<date> location 
        if aNodeType == self.PATCH_CELL: 
                self._mGetCellLogs(aDom0, aNodesList, aLogDir)

        # Get ibswitch specific logs
        if aNodeType == self.PATCH_IBSWITCH:
            self._mGetUpgradeIBSwitchOutFiles(aDom0, aBaseDir)

        # Clean ssh configuration
        if self.__ssh_env_setup:
            self.__ssh_env_setup.mCleanSSHPasswordless(aDom0, aNodesList)

        # Delete input file
        self._mDeleteNodesFile(aListFilePath, aDom0)


# Private functions that returns the list of nodes in the cluster.

    def _mGetCellList(self):
        """
        Returns the list of cell nodes in the cluster. In case of clusterless
        cabinet, we need to remove the nodes which are specified in the
        excluded list.
        """
        if self.mIsClusterLessUpgrade():
            # Remove excluded nodes from the actual node list
            _orig_node_list = list(self.__cluctrl.mReturnCellNodes(aIsClusterLessXML=True).keys())
            _excluded_node_list = list(self.mGetExcludedList())
            _final_node_list = [_node for _node in _orig_node_list if _node not in _excluded_node_list]
            return _final_node_list
        else:
            return list(self.__cluctrl.mReturnCellNodes().keys())


    def _mReturnPatchingDom0DomUList(self):
        """
        Returns a list of dom0,DomU tuples. In case of clusterless cabinet, we need to
        remove the nodes which are specified in the excluded list.
        """
        if self.mIsClusterLessUpgrade():
            # Remove excluded nodes from the actual node list
            _orig_node_list = self.__cluctrl.mReturnDom0DomUPair(aIsClusterLessXML=True)
            _excluded_node_list = list(self.mGetExcludedList())
            return list(filter(lambda x: x[0] not in _excluded_node_list,_orig_node_list))
        else:
            return self.__cluctrl.mReturnDom0DomUPair()



    def _mGetDom0List(self):
        """
        Returns the list of dom0s nodes. In case of clusterless cabinet, we need to
        remove the nodes which are specified in the excluded list.
        """
        if self.mIsClusterLessUpgrade():
            # Remove excluded nodes from the actual node list
            _orig_node_list = [_dom0 for _dom0, _ in self.__cluctrl.mReturnDom0DomUPair(aIsClusterLessXML=True)]
            _excluded_node_list = list(self.mGetExcludedList())
            _final_node_list = [_node for _node in _orig_node_list if _node not in _excluded_node_list]
            return _final_node_list
        else:
            return [_dom0 for _dom0, _ in self.__cluctrl.mReturnDom0DomUPair()]

    def _mGetDomUList(self, aDom0=None, aFromXmList=False):
        """
        Returns the list of domUs. if aDom0 is provided, only return the domUs on that dom0
        """
        _domUs = []
        _cmd = ""

        if self.mIsKvmEnv():
            '''
            sed added at the end to remove empty line
            Example:
              # virsh list|tail -n+3|awk '{print $2}' | sed '/^$/d'
                scaqan03dv0208.us.oracle.com
                scaqan03dv0204.us.oracle.com
                scaqan03dv0201.us.oracle.com
                scaqan03dv0202.us.oracle.com
                scaqan03dv0203.us.oracle.com
            '''
            _cmd = "virsh list|tail -n+3|awk '{print $2}' | sed '/^$/d'"
        else:
            _cmd = "xm list|tail -n+3|awk '{print $1}'"

        if aDom0:
            if not aFromXmList:
                for _dom0, _domU in self._mReturnPatchingDom0DomUList():
                    if _dom0 == aDom0:
                        _domUs = _domU
                        if type(_domUs) not in (list,set,tuple):
                            _domUs = [_domUs]
                        break
            else:
                _node = exaBoxNode(get_gcontext())
                _node.mConnect(aHost=aDom0)
                _in, _out, _err = _node.mExecuteCmd(_cmd)
                _output = _out.readlines()
                if _output:
                    for _line in _output:
                        _domUs.append(_line.strip())
                _node.mDisconnect()
        else:
            if not aFromXmList:
                _domUs = [_domU for _, _domU in self._mReturnPatchingDom0DomUList()]
            else:
                for _dom0, _ in self._mReturnPatchingDom0DomUList():
                    _node = exaBoxNode(get_gcontext())
                    _node.mConnect(aHost=_dom0)
                    _in, _out, _err = _node.mExecuteCmd(_cmd)
                    _output = _out.readlines()
                    if _output:
                        for _line in _output:
                            _domUs.append(_line.strip())
                    _node.mDisconnect()
        return _domUs

    def _mGetIBSwitchList(self):
        """
        Returns the list of all the ibswitches.
        """

        if self.__fabric:
            _db = ebGetDefaultDB()
            _list = _db.mGetListOfIBFabricIBSwitches(self.__fabric_id)
            if _list:
                return [str(_row[2]) for _row in _list]

        if self.mIsKvmEnv():
            # TODO: We can use this for switch upgrade in future
            return self.__cluctrl.mReturnSwitches(True, True)
        else:
            return self.__cluctrl.mReturnSwitches(True)

    # Functions that handle the input file necessary to run the patchmgr
    def _mCreateNodesFile(self, aPath, aDom0, aHostList, aExclude = ""):
        """
        Creates the input file with the list of nodes to be patched.
        """

        if aPath[-1] != '/':
            _input_nodes_file = aPath + '/'
        else:
            _input_nodes_file = aPath
        _input_nodes_file += "node_list" 

        ebLogInfo("Creating patch input file: %s" % _input_nodes_file)
        aHostList.sort()

        ebLogDebug("Create node list: %s" % aHostList)

        _h_list = [_h for _h in aHostList if _h != aExclude]
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDom0)
        _node.mExecuteCmdLog('printf "%s" > %s' % ("\\n".join(_h_list), _input_nodes_file))
        _node.mDisconnect()
        return _input_nodes_file

    def _mDeleteNodesFile(self, aFilePath, aDom0):
        """
        Deletes the input file with the list of nodes to be patched.
        """

        ebLogInfo("Removing patch input file: %s" % aFilePath)
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDom0)
        _node.mExecuteCmdLog('rm -f %s' % aFilePath)
        _node.mDisconnect()

    def _mGetNodeList(self, aFilePath, aDom0):
        """
        Read the list of nodes which are eligible for patching
        """
        _list_of_nodes = []

        try:
            ebLogInfo("Reading patch input file: %s" % aFilePath)
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=aDom0)
            _i, _o, _e = _node.mExecuteCmd('cat %s' % aFilePath)

            _node_list = _o.readlines()

            if _node_list:
                for _cell_node in _node_list:
                    _list_of_nodes.append(_cell_node.replace("\n", "").strip())
            else:
                ebLogWarn("Warning: No nodes found in the input file")

            _node.mDisconnect()

        except Exception as e:
            _node.mDisconnect()
            raise Exception ('Error while reading list of cell nodes. Node = %s, input file = %s. Error: %s' % (aDom0, aFilePath, str(e)))

        return _list_of_nodes 

    def _mGetPatchMgrOutFiles(self, aDom0, aRemotePath, aCode=''):
        """
        Copies patchmgr.stdout/stderr/trc/log to /log
        """

        if aRemotePath[-1] != '/':
            aRemotePath+='/'
        if self.__log_path[-1] != '/':
            self.__log_path+='/'

        patchmgr_files = [self.PATCH_STDOUT, self.PATCH_STDERR,
                          self.PATCH_TRC,    self.PATCH_LOG]
        if aCode != '':
            for i, patchmgr_file  in enumerate(patchmgr_files):
                patchmgr_files[i] = patchmgr_file + '.' + aCode

        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDom0)

        for patchmgr_file in patchmgr_files:
            try:
                ebLogInfo("Copying %s file from node - %s , location - %s" % (patchmgr_file, aDom0, aRemotePath))
                _node.mCopy2Local(aRemotePath+patchmgr_file, 
                                  self.__log_path+patchmgr_file+'.'+\
                                      self.__current_target_type)
            except Exception as e:
                ebLogWarn('Error while copying %s: %s from node - %s , location - %s' % (patchmgr_file, str(e), aDom0, aRemotePath))
        _node.mDisconnect()

    def _mGetPatchMgrMiscLogFiles(self, aDom0, aRemotePath):
        """
        Copies PatchmgrConsole.out to /log
        """

        if aRemotePath[-1] != '/':
            aRemotePath+='/'
        if self.__log_path[-1] != '/':
            self.__log_path+='/'

        _misc_files = [self.PATCH_CONSOLE_LOG]

        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDom0)

        for _misc_file in _misc_files:
            try:
                ebLogInfo("Copying %s file from node - %s , location - %s" % (_misc_file, aDom0, aRemotePath))
                _node.mCopy2Local(aRemotePath+_misc_file, 
                                  self.__log_path+_misc_file+'.'+\
                                      self.__current_target_type)
            except Exception as e:
                ebLogWarn('Error while copying miscellaneous file console log %s: %s from node - %s , location - %s' % 
                           (_misc_file, str(e), aDom0, aRemotePath))
        _node.mDisconnect()

    def _mGetUpgradeIBSwitchOutFiles(self, aDom0, aRemotePath):
        """
        Copies upgradeIBSwitch.trc and upgradeIBSwitch.log files
        """

        if aRemotePath[-1] != '/':
            aRemotePath+='/'
        if self.__log_path[-1] != '/':
            self.__log_path+='/'

        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDom0)

        try:
            ebLogInfo("Copying %s file from node - %s , location - %s" % (self.IBSWITCH_LOG, aDom0, aRemotePath))
            _node.mCopy2Local(aRemotePath+self.IBSWITCH_LOG, self.__log_path+self.IBSWITCH_LOG)
            ebLogInfo("Copying %s file from node - %s , location - %s" % (self.IBSWITCH_TRC, aDom0, aRemotePath))
            _node.mCopy2Local(aRemotePath+self.IBSWITCH_TRC, self.__log_path+self.IBSWITCH_TRC)
        except Exception as e:
            ebLogWarn('Error while copying %s and %s: %s' % (self.IBSWITCH_LOG,self.IBSWITCH_TRC, str(e)))

        _node.mDisconnect()

    def _mGetDom0FileCode(self, aDom0, aRemotePath):
        """
        Gets the most recent code. File name is patchmgr.stdout.<code>
        """

        if aRemotePath[-1] != '/':
            aRemotePath+='/'
        _cmd_list_files = 'ls -t %s%s*|head -1' % (aRemotePath, self.PATCH_STDOUT)
        _code = ''

        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDom0)

        _in, _out, _err = _node.mExecuteCmd(_cmd_list_files)
        _output = _out.readlines()
        if _output:
            _file = _output[0].strip().split("/")[-1]
            ebLogInfo(_file)
            _re_out = re.match(".*stdout\.([0-9a-f]+)", _file)
            if _re_out:
                _code = int(_re_out.groups()[0])

        _node.mDisconnect()

        return _code

    def _mGetPatchMgrDiagFiles(self, aDom0, aNodeType, aNodeList, aRemotePath):
        """
        Copies the last patchmgr_files found for various node types to /log.
        Presently handles the CELLs and DOMUs
        For CELLS, it copies the files from DOM0 to ExaCloud logs
        For DOMUs, along with the files from DOM0 where patchmrg ran it also
        gets the files from DOMUs.
        """

        if self.__log_path[-1] != '/':
            self.__log_path+='/'

        # First get the files from the DOM0 which ran the patchmgr
        if aNodeType == self.PATCH_CELL:
            if aRemotePath[-1] != '/':
                aRemotePath+='/'

            _cmd_list_diag_files = 'find %s -name "patchmgr_diag_*"' % aRemotePath
            _cell_diag_files = {}
    
            for _cell in aNodeList:
                _cell_diag_files[_cell] = {'path': '',
                                           'group': []}
    
            ### IMPORTANT ###
            # This implementation always will copy the most recent patmgr file 
            # found for a given cell. Is there a certain way to know which files
            # were created during a cleanup task?
            ### -------- ###

            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=aDom0)

            try:
    
                # Find all the patchmgr_diag* files availables. It is possible 
                # that this patchmgr was used before so it is important to get 
                # the last files generated
                _in, _out, _err = _node.mExecuteCmd(_cmd_list_diag_files)
                _output = _out.readlines()
    
                if _output:
                    # For each files, we parse its name (which has the date of 
                    # creation).
                    for _o in _output:
                        _file = _o.strip().split("/")[-1]
                        _re_out = re.match("patchmgr_diag_(.+)_([0-9]{4})-" \
                                       "([0-9]{2})-([0-9]{2})_([0-9]{2})_" \
                                       "([0-9]{2})_([0-9]{2})\.tar\.bz2", _file)
                        if _re_out:
                            _group = _re_out.groups()
                            _current = ''
                            for _cell in aNodeList:
                                if _cell.startswith(_group[0]):
                                    _current = _cell
                                    break
    
                            # For each cell, we get only the most recent 
                            # patchmgr_diag file created
                            if _current:
                                _update = True
                                if _cell_diag_files[_current]['group']:
                                    for _ind in range(1,7):
                                        if _group[_ind] != _cell_diag_files[_current]['group'][_ind]:
                                            if _group[_ind] < _cell_diag_files[_current]['group'][_ind]:
                                                _update = False
                                            break
    
                                if _update:
                                    _cell_diag_files[_current]['path'] = _file
                                    _cell_diag_files[_current]['group'] = _group
    
    
                # Each patchmgr file is copied from the dom0 to the localhost.
                ebLogInfo("Collecting diagnostics logs from: %s to: %s" % (aRemotePath, self.__log_path))
                for _cell in _cell_diag_files:
                    if _cell_diag_files[_cell]['path'] != '':
                        ebLogInfo("Copying diagnosis file '%s' file from %s" % 
                                  (_cell_diag_files[_cell]['path'], aDom0))
                        _node.mCopy2Local(aRemotePath+_cell_diag_files[_cell]['path'],
                                          self.__log_path+_cell_diag_files[_cell]['path'])
                    else:
                        ebLogInfo("No diagnosis files found for cell %s" % _cell)
    
            except Exception as e:
                ebLogWarn('Error while copying cell diagnosis files: %s' % str(e))
            _node.mDisconnect()

        if aNodeType == self.PATCH_DOMU or aNodeType == self.PATCH_DOM0:
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=aDom0)
            aRemotePath = self.__patchmgr_log_path_on_launch_node
            _patchmgr_diag_tar = aRemotePath.split('/')[-1] + ".tar"

            ebLogDebug("aRemotePath = %s\n_patchmgr_diag_tar = %s\n"
                       " dirname = %s\n basename = %s\n" % (
                      aRemotePath, _patchmgr_diag_tar, 
                      os.path.dirname(aRemotePath),
                      os.path.basename(aRemotePath)
                      ))

            # tar the diagnostic files
            try:
                tar_cmd = "cd %s; tar cvf %s %s;" % (
                                                os.path.dirname(aRemotePath),
                                                _patchmgr_diag_tar,
                                                os.path.basename(aRemotePath)
                                                    )
                ebLogDebug("Taring patch manager diagnosis files from "
                           "DOM0 %s\n cmd=%s" % (aDom0, tar_cmd))

                _in, _out, _err = _node.mExecuteCmd(tar_cmd)
            except Exception as e:
                ebLogWarn("Error while taring the diagnosis files(%s) from "
                          "DOM0 %s" % (tar_cmd, str(e)))

            # copy the tar to local
            try:
                ebLogDebug("Copying diagnosis file '%s' file from node - %s , location - %s" % (_patchmgr_diag_tar, aDom0,aRemotePath))
                _node.mCopy2Local(os.path.dirname(aRemotePath)+'/'+_patchmgr_diag_tar, self.__log_path+_patchmgr_diag_tar)
            except Exception as e:
                ebLogWarn("Error while copying the diagnosis files from DOM0 error=%s\n rfile=%s\n lfile=%s" 
                           %(str(e), os.path.dirname(aRemotePath)+'/'+_patchmgr_diag_tar,self.__log_path+_patchmgr_diag_tar))

            # remove the tar file
            try:
                _in, _out, _err = _node.mExecuteCmd("cd %s; rm -f %s;" % \
                                  (os.path.dirname(aRemotePath),_patchmgr_diag_tar))
            except Exception as e:
                ebLogWarn("Error while removing the diagnosis files from "
                          "DOM0 %s" % str(e))
          
            
        # secondly get the files from the individual DOMUs
        if aNodeType == self.PATCH_DOMU:
            for _domu in aNodeList:        
                _node = exaBoxNode(get_gcontext())
                _node.mConnect(aHost=_domu)
                _cmd_list_diag_files = (
                    'find %s -type f -name "*package*"|grep -v tmp' % \
                    ('/var/log/cellos'))
                ebLogInfo("Copying patch manager diagnosis files from DOMU %s" \
                          % _domu)
                try:
                    _in, _out, _err = _node.mExecuteCmd(_cmd_list_diag_files)
                    _output = _out.readlines()

                    if _output:
                        for _o in _output:
                            _file = _o.strip().split("/")[-1]
                            ebLogInfo("Copying diagnosis file '%s' file from %s" % (_file, _domu))
                            _node.mCopy2Local('/var/log/cellos/'+_file, self.__log_path+_domu+'.'+_file)
                except Exception as e:
                    ebLogWarn('Error while copying DOMU diagnosis files: %s from %s node.' % \
                              (str(e), _domu))

                _node.mDisconnect()
        
        return

    # TODO: This is legacy code and will be deleting after review it 
    def _mCleanPatchmgrTmpFiles(self, aDom0, aBaseDir, aInputFile):
        """
        Cleans up all temporary content on the database node(s)
        specified in the node list in non-rolling fashion.
        """

        # Update status
        #self.mUpdatePatchStatus(True, self.STEP_CLEAN_UP)

        _callbacks = [self.mReadCallback, None, self.mErrorCallback, None]

        _exit_code = 0
        _input_file_name = aInputFile
        _cleanup_cmd = "cd %s;./patchmgr  -dbnodes %s -cleanup" % (
                aBaseDir, _input_file_name)

        ebLogInfo("patch_cleanup: " + _cleanup_cmd)

        # Connect to Dom0
        _dom0 = exaBoxNode(get_gcontext())
        _dom0.mConnect(aHost=aDom0)

        # Execute cleanup
        _dom0.mExecuteCmdAsync(_cleanup_cmd, _callbacks)
        _exit_code = int(_dom0.mGetCmdExitStatus())

        if _exit_code != 0:
            # Retry cleanup. See bug 23341346
            ebLogInfo("Cleanup failed with exit_code=%d. "
                      "Waiting for 5 minutes before retry." % _exit_code)
            sleep(300)
            # Execute cleanup again
            _dom0.mExecuteCmdAsync(_cleanup_cmd, _callbacks)
            _exit_code = int(_dom0.mGetCmdExitStatus())

        # Disconnect Dom0
        _dom0.mDisconnect()

        return

    def _mGetCellLogs(self, aDom0, aNodesList, aLogDir):
        """
        Copy cell patching diagnostic files with naming convention as
        <cellhostname>.log and these logs would generated during cell upgrade
        and same needs to be copied toi ECRA from launch node.
        """

        if aLogDir[-1] != '/':
            aLogDir+='/'
        if self.__log_path[-1] != '/':
                self.__log_path+='/'
    
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDom0)
    
        try:
            #Copy <cellnmae>.log files from patchmgr stage location on Dom0 to local node.
            for _cell in aNodesList:
                ebLogInfo("Copying %s.log files from node - %s , location - %s." % (_cell, aDom0, aLogDir))
                _node.mCopy2Local(aLogDir+_cell+'.'+'log',
                                self.__log_path+_cell+'.'+'log')
        except Exception as e:
            ebLogWarn('Error while copying %s.log file from node - %s , location - %s' % (_cell, aLogDir, str(e)))
   
        # Disconnect Dom0 
        _node.mDisconnect()
    
        return


    def mCreateStepList(self):
        """
        Creates the steps list that will allow to update the status request in
        the database.
        """

        _list = [self.STEP_SELECT_LAUNCH_NODE]
        _cell_ibswitch_common_pre_steps = [self.STEP_FILTER_NODES, self.STEP_GATHER_NODE_DATA, self.STEP_PREP_ENV]
        _cell_ibswitch_common_post_steps = [self.STEP_CLEAN_ENV, self.STEP_POSTCHECKS]
        _cell_dom0_shutdown_steps = [self.STEP_SHUTDOWN_VMS, self.STEP_STOP_CELL_SERVICES]
       
        if self.PATCH_CELL in self.__target_type or self.PATCH_ALL in self.__target_type:
            _list+=[_step + '_' + self.PATCH_CELL for _step in _cell_ibswitch_common_pre_steps]
            if self.__shutdown_services:
                _list+=[_step + '_' + self.PATCH_CELL for _step in _cell_dom0_shutdown_steps]
            _list+= self.PATCH_ONLY_CELL_STEP_LIST
            if self.__shutdown_services:
                _list+=[self.STEP_START_VMS + '_' + self.PATCH_CELL]
            _list+=[_step+'_'+self.PATCH_CELL for _step in _cell_ibswitch_common_post_steps]

        if self.PATCH_DOM0 in self.__target_type or self.PATCH_ALL in self.__target_type:
            _list+=[self.STEP_PREP_ENV+'_'+self.PATCH_DOM0]
            _list.append(self.STEP_FILTER_NODES)

            if (self.__task == self.TASK_PREREQ_CHECK or 
               self.__task == self.TASK_ROLLBACK_PREREQ_CHECK or
               self.__task == self.TASK_BACKUP_IMAGE):
                _list.append(self.STEP_FILTER_NODES+'_'+self.PATCH_DOM0+'_1')
                _list.append(self.STEP_RUN_PATCH_DOM0)
                _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_1')

                _list.append(self.STEP_FILTER_NODES+'_'+self.PATCH_DOM0+'_2')
                _list.append(self.STEP_RUN_PATCH_SECOND_DOM0)
                _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_2')

            if self.__task == self.TASK_PATCH or self.__task == self.TASK_ROLLBACK:
                _list.append(self.STEP_FILTER_NODES+'_'+self.PATCH_DOM0)

                if not self.__shutdown_services:
                    for _index in range(len(self._mGetDom0List())):
                        if _index == 0:
                            _list.append(self.STEP_GATHER_NODE_DATA+'_'+self.PATCH_DOM0+'_[%d]' % (_index+1))
                            _list.append(self.STEP_RUN_PATCH_SECOND_DOM0+'_[%d]' % (_index+1))
                            _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_[%d]' % (_index+1))
                            _list.append(self.STEP_POSTCHECKS+'_'+self.PATCH_DOM0+'_[%d]' % (_index+1))
                        else:
                            _list.append(self.STEP_GATHER_NODE_DATA+'_'+self.PATCH_DOM0+'_[%d]' % (_index+1))
                            _list.append(self.STEP_RUN_PATCH_DOM0+'_[%d]' % (_index+1))
                            _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_[%d]' % (_index+1))
                            _list.append(self.STEP_POSTCHECKS+'_'+self.PATCH_DOM0+'_[%d]' % (_index+1))

                else:
                    _list.append(self.STEP_GATHER_NODE_DATA+'_'+self.PATCH_DOM0+'_[1]')
                    _list.append(self.STEP_SHUTDOWN_VMS+'_'+self.PATCH_DOM0+'_[1]')
                    _list.append(self.STEP_RUN_PATCH_SECOND_DOM0+'_[1]')
                    _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_[1]')
                    _list.append(self.STEP_POSTCHECKS+'_'+self.PATCH_DOM0+'_[1]')

                    _list.append(self.STEP_GATHER_NODE_DATA+'_'+self.PATCH_DOM0+'_[2]')
                    _list.append(self.STEP_SHUTDOWN_VMS+'_'+self.PATCH_DOM0+'_[2]')
                    _list.append(self.STEP_RUN_PATCH_DOM0+'_[2]')
                    _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOM0+'_[2]')
                    _list.append(self.STEP_POSTCHECKS+'_'+self.PATCH_DOM0+'_[2]')

        if (self.PATCH_DOMU in self.__target_type or 
            self.PATCH_ALL in self.__target_type):
            _list+=[self.STEP_PREP_ENV+'_'+self.PATCH_DOMU]
            _list.append(self.STEP_FILTER_NODES)

            if (self.__task == self.TASK_PREREQ_CHECK or 
                self.__task == self.TASK_ROLLBACK_PREREQ_CHECK or
                self.__task == self.TASK_BACKUP_IMAGE):
                _list.append(self.STEP_FILTER_NODES+'_'+self.PATCH_DOMU+'_1')
                _list.append(self.STEP_RUN_PATCH_DOMU)
                _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_1')

                _list.append(self.STEP_FILTER_NODES+'_'+self.PATCH_DOMU+'_2')
                _list.append(self.STEP_RUN_PATCH_SECOND_DOMU)
                _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_2')

            if (self.__task == self.TASK_PATCH or 
                self.__task == self.TASK_ROLLBACK):
                _list.append(self.STEP_FILTER_NODES+'_'+self.PATCH_DOMU)

                if not self.__shutdown_services:
                    for _index in range(len(self._mGetDomUList())):
                        if _index == 0:
                            _list.append(self.STEP_GATHER_NODE_DATA+'_'+self.PATCH_DOMU+'_[%d]' % (_index+1))
                            _list.append(self.STEP_RUN_PATCH_SECOND_DOMU+'_[%d]' % (_index+1))
                            _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_[%d]' % (_index+1))
                            _list.append(self.STEP_POSTCHECKS+'_'+self.PATCH_DOMU+'_[%d]' % (_index+1))
                        else:
                            _list.append(self.STEP_GATHER_NODE_DATA+'_'+self.PATCH_DOMU+'_[%d]' % (_index+1))
                            _list.append(self.STEP_RUN_PATCH_DOMU+'_[%d]' % (_index+1))
                            _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_[%d]' % (_index+1))
                            _list.append(self.STEP_POSTCHECKS+'_'+self.PATCH_DOMU+'_[%d]' % (_index+1))

                else:
                    _list.append(self.STEP_GATHER_NODE_DATA+'_'+self.PATCH_DOMU+'_[1]')
                    _list.append(self.STEP_SHUTDOWN_VMS+'_'+self.PATCH_DOMU+'_[1]')
                    _list.append(self.STEP_RUN_PATCH_SECOND_DOMU+'_[1]')
                    _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_[1]')
                    _list.append(self.STEP_POSTCHECKS+'_'+self.PATCH_DOMU+'_[1]')

                    _list.append(self.STEP_GATHER_NODE_DATA+'_'+self.PATCH_DOMU+'_[2]')
                    _list.append(self.STEP_SHUTDOWN_VMS+'_'+self.PATCH_DOMU+'_[2]')
                    _list.append(self.STEP_RUN_PATCH_DOMU+'_[2]')
                    _list.append(self.STEP_CLEAN_ENV+'_'+self.PATCH_DOMU+'_[2]')
                    _list.append(self.STEP_POSTCHECKS+'_'+self.PATCH_DOMU+'_[2]')

        if self.PATCH_IBSWITCH in self.__target_type or self.PATCH_ALL in self.__target_type:
            _list+=[_step+'_'+self.PATCH_IBSWITCH for _step in _cell_ibswitch_common_pre_steps]
            _list+=  self.PATCH_ONLY_IBSWITCH_STEP_LIST
            _list+=[_step+'_'+self.PATCH_IBSWITCH for _step in _cell_ibswitch_common_post_steps]

        _list.append(self.STEP_END)

        return _list

    def mUpdatePatchStatus(self, aStatus, aStep, aComment=""):
        """
        Updates db to see changes in the progress bar.
        """

        _list = self.__step_list

        if not _list:
            return False

        if aStep not in _list:
            if aStep+'_'+self.__current_target_type not in _list:
                ebLogWarn("Step %s not in list" % aStep)
                return False
            else:
                aStep =  aStep+'_'+self.__current_target_type

        _reqobj = self.__cluctrl.mGetRequestObj()
        if _reqobj:
            _db = ebGetDefaultDB()
            _pos = str(int((100.0 / len(_list) * (_list.index(aStep)+1))))

            if aStep.startswith('patch_'):
                aStep = aStep.replace('patch_', self.__task+'_')
            if aComment == "":
                _reqobj.mSetStatusInfo(str(aStatus)+':'+_pos+':'+aStep)
            else:
                _reqobj.mSetStatusInfo(str(aStatus)+':'+_pos+':'+aStep+'-'+str(aComment))
            _db.mUpdateStatusRequest(_reqobj)
        return True

    # Workaround bug 22750766 - IB SWITCH ROLLBACK FAILS IF MORE THAN ONE RUN IS DONE OF PATCHMGR
    def _mBug22750766(self, aTask):
        """
        Workaround bug 22750766. Delete all patch files.
        This sould be called after a ibswitch rollback.
        """

        if aTask != self.TASK_ROLLBACK:
            return

        ebLogInfo("Deleting all files after ibswitch rollback. Bug 22750766.")
        _dom0 = exaBoxNode(get_gcontext())
        _dom0.mConnect(aHost=self.__dom0_to_patch_cells_ibswitches)
        _dom0.mExecuteCmdLog("rm -rf %s" % self.__cells_ibswitches_patch_base)
        _dom0.mDisconnect()

    def _mBug23519421_CleanupShm(self, aIBSwitch):
        """
        Workaround bug 23519421. Delete all sundcs_36p_repository* files
        from /dev/shm in the switches.
        """

        _cmd = "rm -rf /dev/shm/sundcs_36p_repository*"

        ebLogInfo("%s: Deleting firmware images from /dev/shm" % aIBSwitch)
        _switch = exaBoxNode(get_gcontext())
        _switch.mConnect(aHost=aIBSwitch)
        _switch.mExecuteCmdLog(_cmd)
        _switch.mDisconnect()


    # IBFabric/cluster Lock management
    def mBuildIBFabric(self):
        """
        Set an IBFabric object based on the information located in the db. We must have the
        db cluster_id in order to retrieve the information.
        """

        # If not cluster_id is provided, there is no way to know which fabric this cluster belongs to.
        # In this case, no locking will be used. This should never happen if using JSON input file
        # when doing a request for patching.

        if not self.__cluster_id:
            ebLogWarn("No cluster ID provided. Locking will not be managed during patch operation.")
            return False

        _db = ebGetDefaultDB()

        # Get cluster information located in db
        _row = _db.mCheckIBFabricClusterTable(aClusterID = self.__cluster_id)
        if not _row:
            ebLogWarn("Cluster ID not found. Locking will not be managed during patch operation.")
            return False

        # Based on fabric_id, get all the information related to that fabric
        _row = _db.mCheckIBFabricEntry(_row[1])

        if not _row:
            ebLogWarn("Fabric ID not found. Locking will not be managed during patch operation.")
            return False

        self.__fabric =  IBFabricPatch(_row[0], _row[1], _row[2], _row[3],None, _row[4], _row[5])
        self.__fabric_id = self.__fabric.mGetIBFabricID()

        return True

    def mSetPatchOperationStyle(self, aTaskType):
        """
        Decides which type of operation style will be used: rolling/non-rolling
        """

        if (self.__op_style == self.OP_STYLE_AUTO or 
            (self.__op_style == self.OP_STYLE_NON_ROLLING and 
             self.__target_env == self.ENV_PRODUCTION)):

            if self._mGetDomUList(aFromXmList=True):
                ebLogWarn("VMs up found in cluster. Operation style will be set "
                          "to '%s'" % self.OP_STYLE_ROLLING)
                self.__op_style = self.OP_STYLE_ROLLING
            else:
                ebLogWarn("VMs not found in cluster. Operation style will be "
                          "set to '%s'" % self.OP_STYLE_NON_ROLLING)
                self.__op_style = self.OP_STYLE_NON_ROLLING
                if self.PATCH_DOM0 in self.__target_type:
                    self.mTruncatedom0domuPlugins()
        ebLogInfo("Operation style set to %s" % self.__op_style)

    def mTruncatedom0domuPlugins(self):
        """
        If non-rolling style is opted when dom0 upgrade requested, then dom0domu plugis is not 
        feasible. So, ensure to trucate 'dom0domu' if specified by user.
        Return value:
           Nothing
        """
        _truncated_flag = False
        ebLogWarn("Removing plugin dom0domu from plugin list %s if non-rolling style is "
                  "selected for dom0 upgrade." % self.__plugin_types)
        if 'dom0+dom0domu' in self.__plugin_types:
            self.__plugin_types = self.__plugin_types.replace("+dom0domu", "")
            _truncated_flag = True
        elif 'dom0domu+dom0' in self.__plugin_types:
            self.__plugin_types = self.__plugin_types.replace("dom0domu+", "")
            _truncated_flag = True
        elif 'dom0domu' in self.__plugin_types:
            self.__plugin_types = self.__plugin_types.replace("dom0domu", "")
            _truncated_flag = True

        if _truncated_flag:
            ebLogWarn("The plugin type dom0domu is truncated: %s" % self.__plugin_types)
        else:             
            ebLogInfo("The plugin type dom0domu is not truncated") 

    def mUpdateTaskFile(self):
        """
        It looks for cell_states.txt to get the current status of cell patching.
        This also to keep statusinfo updated with the currentcell being patched.
        This function runs in a different process while patch is running.
        """

        _new_reqobj = None
        _uuid = None
        _output_file = None
        _dom0 = None
        _template_header='patchmgr task: %s\n'
        _read_cell_cmd = "cat {0}cell_states.txt 2>/dev/null".format(self.__cells_ibswitches_patch_base_after_unzip)
        _cells = self._mGetCellList()
        _done_cells = []
        _db = ebGetDefaultDB()
        _template_node='''
* %s:
%-20s
'''

        try:
            _new_reqobj = copy.copy(self.__cluctrl.mGetRequestObj())
            _uuid = _new_reqobj.mGetUUID()
        except Exception as e:
            ebLogError("Error while fetching request object in extra process: %s" % str(e))
            return

        # Get file path
        _output_file = self.__log_path
        if _output_file[-1] != '/':
            _output_file+='/'
        _output_file+='patchmgr.cellinfo'

        while True:
            _text = ''
            _row = None

            # Reload request information
            _row = _db.mGetRequest(_uuid)

            if not _row:
                break
         
            # Get status information
            _stat, _percentage, _step = _row[10].split(':')

            if _step.startswith(self.TASK_PATCH) or _step.startswith(self.TASK_ROLLBACK):
                # Check if patchmgr is running in cells
                if _step.find('_'+self.PATCH_CELL) >= 0:
                    _text += _template_header % _step

                    _dom0 = exaBoxNode(get_gcontext())
                    _dom0.mConnect(aHost=self.__dom0_to_patch_cells_ibswitches)
                    _i, _o, _e = _dom0.mExecuteCmd(_read_cell_cmd)

                    _output = _o.readlines()
                    _dom0.mDisconnect()

                    if _output:
                        ebLogInfo("************")
                        ebLogInfo(_output)
                        for _line in _output:
                            _cell = None
                            for _c in _cells:
                                if _line.find(_c) >= 0:
                                    _cell = _c
                                    break

                            if _cell:
                                _text += _template_node % (_cell, _line.replace(_cell+":", "").strip())

                        # Update statusinfo if necessary
                        if _new_reqobj:
                            if _cell and len(_output) == 1:
                                if _cell not in _done_cells:
                                    _done_cells.append(_cell)
                                if _row[10].find(_cell) == -1:
                                    _new_reqobj.mSetStatusInfo(_row[10].split('-')[0]+'-[%d/%d]_%s' % (\
                                                               len(_done_cells), len(_cells), _cell))
                                    _db.mUpdateStatusRequest(_new_reqobj)
                            if len(_output) > 1:
                                if _row[10].find('parallel_task_in_all_cells') == -1:
                                    _new_reqobj.mSetStatusInfo(_row[10].split('-')[0]+'-'+'parallel_task_in_all_cells')
                                    _db.mUpdateStatusRequest(_new_reqobj)

                        # Open file and write status information
                        with open(_output_file, 'w') as fd:
                            fd.write(_text)
                else:
                    ebLogInfo('Extra process ending because no cell patch is running anymore')
                    break

            # If the request is already done, then exit thread
            if _row[1].startswith('Done'):
                break

            # Wait for 3 secs before collecting information again
            sleep(3)


    def mMonitorCNSEvents(self):
        """
        Wrapper function to monitor CNS events on exadata patching.
        Basically, it invokes mMonitorPatchReqForCNS().
        """

        ebLogInfo("Starting patch notification service")

        # Init extra process that will monitor the patch status change for
        # the CNS 
        if self.__fabric and (not self.__process_cns_monitor or not self.__process_cns_monitor.is_alive()):
            self.__process_cns_monitor = Process(target=self.mMonitorPatchReqForCNS)
            self.__process_cns_monitor.start()

    def mMonitorPatchReqForCNS(self, aCollectCnsOnce=False, aFinalLastCns=False):
        """
        It monitor the patch request and send notification periodically.
        This function runs in a different process while patch is running.
        If the arg aCollectCnsOnce=True, then it check CNS and populate 
        notification if any. 
        If the arg aFinalLastCns=True, then it collects the CNS irrespective
        of any changes to patchmgr xml.
        If aCollectCnsOnce=False, then regular monitoring of CNS.
        """

        _new_reqobj = None
        _uuid = None

        _cnsjson = {}
        _db = ebGetDefaultDB()

        try:
            _new_reqobj = copy.copy(self.__cluctrl.mGetRequestObj())
            _uuid = _new_reqobj.mGetUUID()
        except Exception as e:
            ebLogWarn("mMonitorPatchReqForCNS: Within patch notification monitor"
                      " process, failed to get the object for request UUID %s" % (str(e)))
            return

        # Create dummy patchmgr xml so that it can be compared with the actual
        # generated one. Dummy/initial patchmgr xml creates only during
        # regular CNS monitor and it should not create with instant run.
        self.__patchmgr_old_xml_loc = "{0}/notification_patchxml_old".format(
                                        self.__patchmgr_log_path_on_launch_node)
        try:
          if not aCollectCnsOnce and not aFinalLastCns: 
              self.mCreateDummyPatchmgrXml()
        except Exception as e:
            ebLogDebug("mMonitorPatchReqForCNS: Error while creating Dummy "
                      "Patch XML%s" % str(e))

        while True:
            _row = None

            # Reload request information
            _row = _db.mGetRequest(_uuid)

            if not _row:
                break
            _xml_modified, _xml_data = None, None

            # In the case of dom0/domu, update logdir path if it got changed,
            # during domu/dom0 patching.
            _patchmgr_log_dir = None
            if self.__current_target_type == self.PATCH_DOMU or \
               self.__current_target_type == self.PATCH_DOM0:
                # get launch node and log dir 
                if self.__current_target_type == self.PATCH_DOMU:
                     _patcher_file_path_info = os.path.join(self.__log_path, 
                                              self.CNS_DOMU_PATCHER)

                elif self.__current_target_type == self.PATCH_DOM0:
                     _patcher_file_path_info = os.path.join(self.__log_path, 
                                           self.CNS_DOM0_PATCHER)

                # get current launch node and log_dir path
                _launch_node, _patchmgr_log_dir = \
                                 self.mReadPatcherInfo(_patcher_file_path_info)

                if self.__patchmgr_log_path_on_launch_node != _patchmgr_log_dir:
                    # New log dir have created during dom0/domu patching.
                    # call mCreateDummyPatchmgrXml function to update the log
                    # dir path
                    ebLogDebug("Log directory path is changed during patching."
                               "Create initial patchmgr xml on new node") 
                    self.mCreateDummyPatchmgrXml()
            try:
                # Get patchmgr xml for checking the patch status
                _xml_modified, _xml_data = self.mGetPatchmgrXml(aCollectCnsOnce,
                                                                aFinalLastCns)
            except Exception as e:
                ebLogInfo("mMonitorPatchReqForCNS:  Failed to get patch "
                          "notification status from node %s" % str(e))
                
            if _xml_modified:
                try:
                    # parse and get the json payload
                    _cnsjson = self.mParsePatchmgrXml(_xml_data, aFinalLastCns)
                except Exception as e:
                    ebLogError("mMonitorPatchReqForCNS: Failed to get the "
                               "notification JSON payload %s" % str(e))

                # Note: cns payload would be required for EM team to send the
                # same notification for operation team.
                # Dumping cns payload for the reference or debugging purpose.
                # TODO: will need to gather additional detail for operation 
                # team such as, launch node, cluster name, the ECRA name for
                # the cluster, etc. 
                try:
                    _cnsjson_logname_on_dom0 = os.path.join(self.__log_path, 
                                                        'cns.payload.json') 
                    with open(_cnsjson_logname_on_dom0, "w") as wjson:
                       _StrJsonPayload = json.dumps(_cnsjson,
                                indent=10,
                                separators=(',', ': '))
                       wjson.write(_StrJsonPayload)
                except Exception as e:
                    ebLogDebug("mMonitorPatchReqForCNS: Failed to write the "
                               "notification JSON %s" % str(e))

                try:
                    self.mUpdateCnsJsonPayload(_StrJsonPayload)
                except Exception as e:
                    ebLogDebug("mMonitorPatchReqForCNS: Failed to save "
                               "notification JSON in the database %s" % str(e))

            # If the request is already done or request for collecting CNS only
            # once, then exit from the monitor
            if (_row[1].startswith('Done') or 
                (aCollectCnsOnce == self.__instant_collect_of_cns) or 
                aFinalLastCns):
                break

            # Monitor patch progress/status changes.
            sleep(self.CNS_OP_MONITOR_INTERVAL_SECONDS)

    def mCreateDummyPatchmgrXml(self):
        """
        Creating the dummy patchmgr xml to compare against patch status 
        chagnes.
        """

        _elapsed_time = 0

        _dom0 = exaBoxNode(get_gcontext())
        _patchmgr_log_dir = self.__patchmgr_log_path_on_launch_node
        try:
          if (self.__current_target_type == self.PATCH_CELL or 
              self.__current_target_type == self.PATCH_IBSWITCH):
             _dom0.mConnect(aHost=self.__dom0_to_patch_cells_ibswitches)
          elif self.__current_target_type == self.PATCH_DOMU:
             # fetch current running domu to create dummy patchmgr xml 
             _get_domu_patcher = os.path.join(self.__log_path, 
                                        self.CNS_DOMU_PATCHER)
             while True:
                 if (_elapsed_time >= self.CNS_OP_TIME_OUT_SECONDS):
                     ebLogDebug("Timed out to get domu patcher node") 
                     return 
                 # get current launch node and log_dir path
                 _domuHost, _patchmgr_log_dir = \
                                       self.mReadPatcherInfo(_get_domu_patcher)
                 # if we found domuhost info and connected to it, then our job 
                 # is done, so exit from while loop
                 if _domuHost:
                     _dom0.mConnect(aHost=_domuHost)
                     break
                 else:
                     sleep(self.CNS_OP_SLEEP_TIME_SECONDS)
                     _elapsed_time += self.CNS_OP_SLEEP_TIME_SECONDS
          elif self.__current_target_type == self.PATCH_DOM0:
             # fetch current running dom0 to create dummy patchmgr xml 
             _get_dom0_patcher = os.path.join(self.__log_path, 
                                        self.CNS_DOM0_PATCHER)
             while True:
                 if (_elapsed_time >= self.CNS_OP_TIME_OUT_SECONDS):
                     ebLogDebug("Timed out to get dom0 patcher node") 
                     return
                 # get current launch node and log_dir path
                 _dom0Host, _patchmgr_log_dir = \
                                       self.mReadPatcherInfo(_get_dom0_patcher)
                 # if we found dom0host info and connected to it, then our job 
                 # is done, so exit from while loop
                 if _dom0Host:
                     _dom0.mConnect(aHost=_dom0Host)
                     break
                 else:
                     sleep(self.CNS_OP_SLEEP_TIME_SECONDS)
                     _elapsed_time += self.CNS_OP_SLEEP_TIME_SECONDS
        except Exception as e:
           ebLogDebug("mCreateDummyPatchmgrXml: Failed to connect node %s" % str(e))
           return

        # keep these global variables upto date
        self.__patchmgr_old_xml_loc = "{0}/notification_patchxml_old".format(
                                        _patchmgr_log_dir)
        self.__patchmgr_log_path_on_launch_node = _patchmgr_log_dir

        # Initially, writing dummy content to patchmgr xml
        _patchmgr_dummy_xml_create_cmd = "echo DummyPatchmgrXmlContentForPatchStatusCheckCNS > {0}"\
                                          .format(self.__patchmgr_old_xml_loc)
         
        # Create dummy patchmgr xml. This is in a loop for the reason that
        # destination path might not be exist initially (few seconds or so)
        # and creation of starter notification XML might fail, since 
        # notification process would come here, before patch request process
        # and tries to creates the dir __patchmgr_old_xml_loc and it might 
        # fail. 
        _elapsed_time = 0
        while True:
            _i, _o, _e = _dom0.mExecuteCmd(_patchmgr_dummy_xml_create_cmd)
            _patchmgr_old_xml_create_err = _e.read().strip('\n')

            if _patchmgr_old_xml_create_err:
                if _elapsed_time >= self.CNS_OP_TIME_OUT_SECONDS:
                     ebLogDebug("mCreateDummyPatchmgrXml: Failed generation of starter notification XML %s" 
                                 % str(_patchmgr_old_xml_create_err))
                     break

                sleep(self.CNS_OP_SLEEP_TIME_SECONDS)
                _elapsed_time += self.CNS_OP_SLEEP_TIME_SECONDS
            else:
                break

        _dom0.mDisconnect()

    def mGetPatchmgrXml(self, aCollectCnsOnce, aFinalLastCns):
        """
        1. Check whether patchmgr file is modified by comparing with older xml.
        Return True, if pachmgr xml is modified, otherwise return False.

        2. Also, if patchmgr xml is modified, then get the patchmgr xml file from 
        dom0[u] which has the current status of the software upgrade
        """

        _patchmgr_xml_modified = False
        _patchmgr_xml_data = None
        _elapsed_time = 0

        # Get the absolute path of patchmgr xml file from dom0 where patchmgr is running
        # The example of pathmgr xml path is:
        # '/EXAVMIMAGES/dbserver.patch.zip_exadata_ovs_122111_Linux-x86-64.zip/dbserver_patch_5.170624/
        # patchmgr_log.2017-06-30_05.55.47/notifications/notification_patchmgr_2017063006011498827683118510142_'

        _dom0 = exaBoxNode(get_gcontext())
        _launch_node = None
        _patchmgr_log_dir = self.__patchmgr_log_path_on_launch_node
        try:
          if (self.__current_target_type == self.PATCH_CELL or 
              self.__current_target_type == self.PATCH_IBSWITCH):
             _launch_node = self.__dom0_to_patch_cells_ibswitches
          elif self.__current_target_type == self.PATCH_DOMU:
             # fetch current running domU to patch/upgrade and connect 
             _get_cur_domu = os.path.join(self.__log_path, self.CNS_DOMU_PATCHER)
             while True:
                 if (_elapsed_time >= self.CNS_OP_TIME_OUT_SECONDS):
                     ebLogDebug("Timed out to get domu patcher node for notification")
                     return _patchmgr_xml_modified, _patchmgr_xml_data

                 _launch_node, _patchmgr_log_dir = \
                                           self.mReadPatcherInfo(_get_cur_domu)
                 if _launch_node:
                     # Create dummy patchmgr xml within initial domu and it should
                     # be for the first time. The instant (aCollectCnsOnce=True) 
                     # call of CNS check should not create the dummy patchmgr xml
                     if (_launch_node == self.__domu_to_patch_initial_domu and 
                         not self.__dummy_xml_created_on_initial_domu and 
                         not aCollectCnsOnce and not aFinalLastCns):
                         self.mCreateDummyPatchmgrXml()
                         self.__dummy_xml_created_on_initial_domu = True
                     break
                 else:
                     sleep(self.CNS_OP_SLEEP_TIME_SECONDS)
                     _elapsed_time += self.CNS_OP_SLEEP_TIME_SECONDS

          elif self.__current_target_type == self.PATCH_DOM0:
             # fetch current running dom0 to patch/upgrade and connect 
             _get_cur_dom0 = os.path.join(self.__log_path, self.CNS_DOM0_PATCHER)

             while True:
                 if (_elapsed_time >= self.CNS_OP_TIME_OUT_SECONDS):
                     ebLogDebug("Timed out to get dom0 patcher node for notification")
                     return _patchmgr_xml_modified, _patchmgr_xml_data

                 _launch_node, _patchmgr_log_dir = \
                                           self.mReadPatcherInfo(_get_cur_dom0)
                 if _launch_node:
                     # Create dummy patchmgr xml within initial dom0 and it 
                     # should be for the first time. The instant
                     # (aCollectCnsOnce=True) call of CNS check should not
                     # create the dummy patchmgr xml
                     if (_launch_node == self.__dom0_to_patch_initial_dom0 and 
                         not self.__dummy_xml_created_on_initial_dom0 and 
                         not aCollectCnsOnce and not aFinalLastCns):
                         self.mCreateDummyPatchmgrXml()
                         self.__dummy_xml_created_on_initial_dom0 = True
                     break
                 else:
                     sleep(self.CNS_OP_SLEEP_TIME_SECONDS)
                     _elapsed_time += self.CNS_OP_SLEEP_TIME_SECONDS

          if _launch_node:
            _dom0.mConnect(aHost=_launch_node)

          # keep upto date of the self.__patchmgr_log_path_on_launch_node
          self.__patchmgr_log_path_on_launch_node = _patchmgr_log_dir
        except Exception as e:
           ebLogDebug("mGetPatchmgrXml: Failed to connect to node '%s': %s" % (_launch_node, str(e)))
           return _patchmgr_xml_modified, _patchmgr_xml_data

        _patchmgr_xml_path_cmd = "ls -t {0}/notifications/notification_patchmgr* |head -1".format(_patchmgr_log_dir)
        try:
            _elapsed_time = 0
            # get notification_patchmgr file from dom0[u] 
            while True: 
                _i, _o, _e = _dom0.mExecuteCmd(_patchmgr_xml_path_cmd)
                _patchmgr_new_xml_loc = _o.read().strip('\n')

                # the notification_patchmgr is found
                if _patchmgr_new_xml_loc:
                    break
                elif _elapsed_time >= self.CNS_OP_TIME_OUT_SECONDS:
                    ebLogDebug("mGetPatchmgrXml: Failed executing command on node: '%s', '%s'" % (_patchmgr_xml_path_cmd, _launch_node))
                    _dom0.mDisconnect() 
                    return _patchmgr_xml_modified, _patchmgr_xml_data

                # not found/generated 'notification_patchmgr' xml yet. Retry
                # to get the same.
                sleep(self.CNS_OP_SLEEP_TIME_SECONDS)
                _elapsed_time += self.CNS_OP_SLEEP_TIME_SECONDS

            # Collect the notification at the end of each cluster as final one
            if aFinalLastCns:
                _patchmgr_xml_modified = True 
                # read the content of patchmgr xml 
                _read_patchmgr_xml_cmd = "cat {0} 2>/dev/null".format(_patchmgr_new_xml_loc)
                _i, _o, _e = _dom0.mExecuteCmd(_read_patchmgr_xml_cmd)
                _patchmgr_xml_data = _o.read()
        
                # copying patchmgr.xml from dom0 
                _cns_patchmgr_logname_on_dom0 = os.path.join(self.__log_path, 'cns.patchmgr.xml') 
                with open(_cns_patchmgr_logname_on_dom0, "w") as _wxml:
                     _wxml.write(_patchmgr_xml_data)
            else:
                # In regular monitoring of the CNS
                # Do the diff on new and old patchmgr xml file and see if that's
                # really modified
                _patchmgr_xml_diff_cmd = "diff -w {0} {1}".format(self.__patchmgr_old_xml_loc, _patchmgr_new_xml_loc)
                _i, _o, _e = _dom0.mExecuteCmd(_patchmgr_xml_diff_cmd)
                _output = _o.read()

                # patchmgr xml is modified? if yes, get the patchmgr xml file
                if _output:
                    # there is a change in patchmgr xml, so get the patchmgr content 
                    _patchmgr_xml_modified = True 

                    # update the old patchmgr xml with new one
                    _patchmgr_xml_copy_cmd = "cp -f {0} {1}".format(_patchmgr_new_xml_loc, self.__patchmgr_old_xml_loc) 

                    try:
                        _i, _o, _e = _dom0.mExecuteCmd(_patchmgr_xml_copy_cmd)
                    except Exception as e:
                        ebLogDebug("mGetPatchmgrXml: Failed executing command "
                                   "on %s with error: '%s', '%s': %s" % (
                                        self.__current_target_type, 
                                        _patchmgr_xml_copy_cmd, 
                                        _launch_node, str(e)))

                    # read the content of new patchmgr xml 
                    _read_patchmgr_xml_cmd = "cat {0} 2>/dev/null".format(_patchmgr_new_xml_loc)
                    _i, _o, _e = _dom0.mExecuteCmd(_read_patchmgr_xml_cmd)
                    _patchmgr_xml_data = _o.read()
            
                    # copying patchmgr.xml from dom0 
                    _cns_patchmgr_logname_on_dom0 = os.path.join(self.__log_path, 'cns.patchmgr.xml') 
                    with open(_cns_patchmgr_logname_on_dom0, "w") as _wxml:
                         _wxml.write(_patchmgr_xml_data)
                else:
                    _error = _e.read()
                    if _error:
                        ebLogDebug("mGetPatchmgrXml: Failed command with error: %s, %s" % (_patchmgr_xml_diff_cmd, _error))
               
        except Exception as e:
            # TODO self.__current_target_type need to be synchronized between
            # CNS monitor and the patcher processes. Otherwise if the target type
            # is set to 'ALL', individual patch actions will change it to reflect
            # the actual patch target.
            ebLogDebug("mGetPatchmgrXml: Failed to get the patch notification "
                       "file from %s %s" % (self.__current_target_type.upper(), 
                                            str(e)))

        _dom0.mDisconnect() 
        return _patchmgr_xml_modified, _patchmgr_xml_data

    def mParsePatchmgrXml(self, patchmgrxml, aFinalLastCns):
        """
        Parse the patchmgr xml file which has the current status of the sofwate 
        upgrade, running on DOM0. Also, create the json output for sending the 
        CNS (Cloud Notification Service).
        """        

        # flag to indicate final status of the target
        _target_succ_flag = True
        _target_na_flag = True

        # fill up the payload json for notificaiton
        _cnsjson = {}
        _myuuid = uuid4().hex
        _cnsjson['httpRequestId'] = _myuuid

        _cnsjson['recipients'] =  []
        _channel_info = {}
        _channel_info['channelType'] = "topics"

        _cnsjson['notificationType'] = {}
        _cnsjson['notificationType']['componentId']  = "Patch_ExadataInfra_SM"
        _cnsjson['notificationType']['id'] = "Patch_ExadataInfra_SMnotification_v1"

        _cnsjson['data'] = {}
        _cnsjson['data']['service'] = "ExadataPatch"
        _cnsjson['data']['component'] = "Patch Exadata Infrastructure"
        _cnsjson['data']['subject'] = "Patch Exadata Infrastructure Service Update" 
        _cnsjson['data']['event_post_time'] = time.strftime("%Y-%m-%d:%H.%M.%S %Z") 
        _cnsjson['data']['log_dir'] = self.__patchmgr_log_path_on_launch_node 
        _cnsjson['data']['target_type']  = self.__target_type

        # Get into root of patchmgr.xml
        _root = ET.fromstring(patchmgrxml)
        
        # Fetch Global info
        _op_type = _root.findall('./Global_info/Patchmgr_Action/Transition')
        if _op_type:
           _cnsjson['data']['operation_type'] = _op_type[0].attrib['VALUE']

        _op_style = _root.findall('./Global_info/Patch_Mode/Transition') 
        if _op_style:
           _cnsjson['data']['operation_style'] = _op_style[0].attrib['VALUE']

        _launch_node = _root.findall('./Global_info/Launch_Node/Transition') 
        if _launch_node:
           _cnsjson['data']['launch_node'] = _launch_node[0].attrib['VALUE']
 
        # Fetch cluster name
        _cnsjson['data']['cluster_name'] = self.mGetRackName() 
        # this is required for mandatory CNS check in CNSOperation.java
        _cnsjson['data']['exadata_rack'] = self.mGetRackName()

        # These are required in ecra Patcher.java for updating the image version
        # and cabinet status
        _cnsjson['data']['target_version'] = self.__target_version

        if self.mIsClusterLessUpgrade():
            _cnsjson['data']['cluster_less'] = 'yes'
        else:
            _cnsjson['data']['cluster_less'] = 'no'

        # For cells, doms, dom0s, ibswitches 
        _cnsjson['data'][self.__current_target_type+'s']  =  []

        # To parse node target type within ptachmgr xml and also update 
        # topic/id appropriately for each target so that subscriber can also
        # opt CNS for any target(s), individually, while they can also opt
        # parent one 'critical.patch_of_exadata_infrastructure' to get all CNS.
        if self.__current_target_type == self.PATCH_CELL:
           _node_type = 'Cell' 
           _channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_cell" 
           _cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_cell" 
        elif self.__current_target_type == self.PATCH_DOMU:
           _node_type = 'Compute_Node' 
           _channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_domu" 
           _cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_domu" 
        elif self.__current_target_type == self.PATCH_DOM0:
           _node_type = 'Compute_Node' 
           _channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_dom0" 
           _cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_dom0" 
        elif self.__current_target_type == self.PATCH_IBSWITCH:
           _node_type = 'IBSwitch'
           _channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_ibswitch" 
           _cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_ibswitch" 


        for _each_node_type in _root.findall('./'+_node_type):
            _node = {}
            _node['operation_target'] = _each_node_type.attrib['NAME']

            _from_ver = _each_node_type.findall('./From_Version/Transition')
            if _from_ver:
               _node['from_version'] = _from_ver[0].attrib['VALUE']

            _to_ver = _each_node_type.findall('./To_Version/Transition')
            if _to_ver:
               _node['to_version'] = _to_ver[0].attrib['VALUE']

            # Goto last patch transition state
            for _each_pstate_tran in _each_node_type.findall('./Patch_State/Transition'):
                _cur_pstate_tran = _each_pstate_tran

            _node['operation_status'] = _cur_pstate_tran.attrib['VALUE'] 
            _node['timestamp'] = _cur_pstate_tran.attrib['LAST_UPDATE_TIMESTAMP']
            _cnsjson['data'][self.__current_target_type+'s'].append(_node)

            # Check over all status (as Success or 'Not Attempted' or Failed)
            # of the node target, which will be used for final notification
            if  aFinalLastCns:
                _target_succ_flag = _target_succ_flag and (_cur_pstate_tran.attrib['VALUE'] == 'Succeeded')
                _target_na_flag = _target_na_flag and (_cur_pstate_tran.attrib['VALUE'] == 'Not Attempted')

        # Set the topic preference for the final notification of the cluster 
        if aFinalLastCns:
           self.mSetTopicForCns(_channel_info, _cnsjson, _target_succ_flag, _target_na_flag)

        # Append channel info to recipients[]
        _cnsjson['recipients'].append(_channel_info)

        return _cnsjson


    def mSetTopicForCns(self, channel_info, cnsjson, target_succ_flag, target_na_flag):
        """
        Set the topic preference for the final notification
        """

        # verify and set Success status
        if target_succ_flag and self.__current_target_type == self.PATCH_DOMU:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_domu.SUCCESS"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_domu.SUCCESS"
        elif target_succ_flag and self.__current_target_type == self.PATCH_DOM0:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_dom0.SUCCESS"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_dom0.SUCCESS"
        elif target_succ_flag and self.__current_target_type == self.PATCH_CELL:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_cell.SUCCESS"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_cell.SUCCESS"
        elif target_succ_flag and self.__current_target_type == self.PATCH_IBSWITCH:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_ibswitch.SUCCESS"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_ibswitch.SUCCESS"
        # verify and set Not Attempted status
        elif target_na_flag and self.__current_target_type == self.PATCH_DOMU:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_domu.NOTAPPLICABLE"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_domu.NOTAPPLICABLE"
        elif target_na_flag and self.__current_target_type == self.PATCH_DOM0:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_dom0.NOTAPPLICABLE"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_dom0.NOTAPPLICABLE"
        elif target_na_flag and self.__current_target_type == self.PATCH_CELL:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_cell.NOTAPPLICABLE"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_cell.NOTAPPLICABLE"
        elif target_na_flag and self.__current_target_type == self.PATCH_IBSWITCH:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_ibswitch.NOTAPPLICABLE"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_ibswitch.NOTAPPLICABLE"
        # verify and set Fail status
        elif self.__current_target_type == self.PATCH_DOMU:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_domu.FAIL"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_domu.FAIL"
        elif self.__current_target_type == self.PATCH_DOM0:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_dom0.FAIL"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_dom0.FAIL"
        elif self.__current_target_type == self.PATCH_CELL:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_cell.FAIL"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_cell.FAIL"
        elif self.__current_target_type == self.PATCH_IBSWITCH:
            channel_info['topicId'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_ibswitch.FAIL"
            cnsjson['data']['topic'] = "critical.patch_of_exadata_infrastructure.patch_Exadata_ibswitch.FAIL"

    def mCheckSingleNodeUpgradeEnable(self):
        """
        This function checks whether user requested to upgrade single node at 
        a time. It returns:
          True: if user requested to upgrade single
          False: Otherwise 
        """

        if self.__additional_options and 'isSingleNodeUpgrade' in self.__additional_options[0] \
           and self.__additional_options[0]['isSingleNodeUpgrade'].upper() == "YES":
                return True 
        else:
             return False

    def mGetSingleNodeUpgradeName(self):
        """
        This function gets the node name if specified in the rest api or in 
        the additional parameter list. 
        It returns:
           Node name, if user specified in the additional parameter 
                      i.e., in SingleUpgradeNodeName param
           None, otherwise 
        """

        if self.__additional_options and 'SingleUpgradeNodeName' in self.__additional_options[0] \
            and self.__additional_options[0]['SingleUpgradeNodeName']: 
                return self.__additional_options[0]['SingleUpgradeNodeName'] 
        else:
             return None 

    def mIsClusterLessUpgrade(self):
        """
        Check whether user requested for upgrading nodes from compute or cell
        cabinet. It returns:
          True: if user requested to upgrade nodes from cabinet
          False: Otherwise
        """
        if self.__additional_options and 'ClusterLess' in self.__additional_options[0] \
           and self.__additional_options[0]['ClusterLess'].upper() == "YES":
            return True
        else:
            return False

    def mGetCabinetLaunchNode(self):
        """
        Get launch node which is passed by ecra input paylaod.
        Return value:
            Raise Exception --> If launch node not specified in the exacloud payload
            Return Launch Node, it could be string or List.
        """
        if self.__additional_options and 'LaunchNode' in self.__additional_options[0] \
           and not self.__additional_options[0]['LaunchNode']:
            _errmsg = "Unable to set launch node for clusterless upgrade"
            raise Exception(_errmsg)
        else:
            return self.__additional_options[0]['LaunchNode']

    def mGetExcludedList(self):
        """
        Get the list of nodes which are passed by ecra input paylaod.
        Return value:
            [] --> If exclude list is empty
            Return ExcludeList if specified in the payload.
        """
        if self.__additional_options and 'ExcludedNodeList' in self.__additional_options[0] \
           and not self.__additional_options[0]['ExcludedNodeList']:
            ebLogWarn("Exclude list is empty in exacloud payload")
            return []
        else:
            return self.__additional_options[0]['ExcludedNodeList']

    def mIsOpcUserExist(self, aNode):
        """
        This function checks whether we can connect as 'opc' or not to a node
        It returns:
           True: if user 'opc' exist and able to connect
           False: if user 'opc' is not exist and not able to connect.
        """

        _domU = exaBoxNode(get_gcontext())
        _domU.mSetUser('opc')
        try:
            _domU.mConnect(aHost=aNode)
        except Exception as e:
            ebLogError("mIsOpcUserExist: Failed to connect as opc user. Error %s" % str(e))
            return False

        _domU.mDisconnect()
        return True

#########################################################################################################################

class IBFabricPatch(object):
    """
    Wrapper that allows to manage the information located in ibfabriclocks table.
    """

    def __init__(self, aFabricID, aSha512, aDoSwitch, aBusyClusters, aCluPatchObjects, aLockedFor, aFabricLock):
        self.__id = int(aFabricID)
        self.__sha512 = str(aSha512)
        self.__do_switch = str(aDoSwitch)
        self.__clusters = str(aBusyClusters)
        self.__cluobjs = aCluPatchObjects
        self.__lockedfor = str(aLockedFor)
        self.__fabriclock = int(aFabricLock)
        self.__ibswitches = []

    def mCheckCluster(self, aClusterName):
        """
        Checks if cluster is already in the local list of clusters.
        """

        _list = self.mGetCluObjects()
        if _list:
            for _index,_clu in enumerate(_list):
                if _clu.mGetClusterName() == aClusterName:
                    return _index
        return -1

    def mAddCluster(self, aClusterObj):
        """
        Adds a new cluster to the local list of clusters.
        """

        if self.__cluobjs:
            self.__cluobjs.append(aClusterObj)
        else:
            self.__cluobjs = [aClusterObj]

        return (len(self.__cluobjs) - 1)

    def mGetCluster(self, aClusterIndex):
        """
        Gets the IBClusterPatch object from the clusters list located in aClusterIndex
        """

        if self.__cluobjs and aClusterIndex < len(self.__cluobjs):
            return self.__cluobjs[aClusterIndex]
        return None

    def mDeleteCluster(self, aClusterIndex):
        """
        Deletes cluster from clusters list.
        """

        if self.__cluobjs and aClusterIndex < len(self.__cluobjs):
            self.__cluobjs.pop(aClusterIndex)

    def mSetIBFabricID(self, aFabricID):
        self.__id = int(aFabricID)

    def mGetIBFabricID(self):
        return self.__id

    def mSetSha512(self, aSha512):
        self.__sha512 = aSha512

    def mGetSha512(self):
        return self.__sha512

    def mSetDoSwitch(self, aDoSwitch):
        self.__do_switch = aDoSwitch

    def mGetDoSwitch(self):
        return self.__do_switch

    def mSetBusyClustersList(self, aClusters):
        self.__clusters = aClusters

    def mGetBusyClustersList(self):
        return self.__clusters

    def mSetCluObjects(self,aCluPatchObjects):
        self.__cluobjs = aCluPatchObjects

    def mGetCluObjects(self):
        return self.__cluobjs

    def mSetLockedFor(self, aLockedFor):
        self.__lockedfor = aLockedFor

    def mGetLockedFor(self):
        return self.__lockedfor

    def mSetFabricLock(self, aFabricLock):
        self.__fabriclock = int(aFabricLock)

    def mGetFabricLock(self):
        return self.__fabriclock

    def mSetIBSwitches(self, aIBSwitches):
        self.__ibswitches = aIBSwitches

    def mAddIBSwitch(self, aIBSwitch):
        self.__ibswitches.append(aIBSwitch)

    def mGetIBSwitches(self):
        return self.__ibswitches

    def mDumpIBFabric(self):
        """
        Prints the IBFabric information.
        """

        ebLogInfo("---------------------------------")
        ebLogInfo("IBFabric ID: %d" % self.mGetIBFabricID())
        ebLogInfo("Sha512: %s" % self.mGetSha512())
        ebLogInfo("Clusters: %s " % self.mGetBusyClustersList())
        ebLogInfo("Lockedfor: %s" % self.mGetLockedFor())
        ebLogInfo("FabricLock: %d" % self.mGetFabricLock())
        ebLogInfo("IBSwitchList: %s" % str(self.mGetIBSwitches()))
        for _c in self.__cluobjs:
            ebLogInfo("\t\tCluster %s ID: %d " %(_c.mGetClusterName(), _c.mGetIBClusterID()))
        ebLogInfo("---------------------------------")


    def mLock(self, aClusterID, non_ibswitch):
        """
        Locks a specified cluster and ibfabric if non_ibswitch is set to False.
        """

        _db = ebGetDefaultDB()

        if non_ibswitch:
            return _db.mManageIBFabricLock(self.mGetIBFabricID(), aClusterID, True, 'non_ibswitch')

        return _db.mManageIBFabricLock(self.mGetIBFabricID(), aClusterID, True, 'ibswitch')

    def mRelease(self, aClusterID):
        """
        Releases the lock for a specified cluster and ibfabric if necessary.
        """

        _db = ebGetDefaultDB()
        return _db.mManageIBFabricLock(self.mGetIBFabricID(), aClusterID, False)

    def mUpdateDoSwitchDB(self):
        """
         Updates do_switch column in db.
        """

        _db = ebGetDefaultDB()
        return _db.mSetDoSwitchIBFabic(self.mGetIBFabricID(), self.mGetDoSwitch())

    def mRefreshData(self):
        """
        Refreshs all the data in this object by reading the values from the db.
        """

        _db = ebGetDefaultDB()

        _row = _db.mCheckIBFabricEntry(aFabricID=self.mGetIBFabricID())
        ebLogInfo("Bug31399993 - In mRefreshData-1")

        if _row:
            '''
             Case 1 : Reset do_switch to 'no' in case request is left with stale data. Basically, we need to look 
                      for list_clusters_in_process to '' (empty) and lockedcount is '0'.

               sqlite> select * from ibfabriclocks;
               id|ibswitches_output_sha512|do_switch|list_clusters_in_process|lockedfor|lockcount
               1|c99d4253ec79f9008696ec7c5d5017bcaa74b02f8ee6722e6c6cf8c3a85e1edfd841a903b0366da74ba4f9a399158a002f77d856d784f5df1815ce511846267e|yes||none|0
               sqlite> .exit
            '''
            ebLogInfo("Bug31399993 - In mRefreshData-2")
            if _row[2] == 'yes' and _row[3] in [ None, '' ] and _row[5] > 0:
                ebLogInfo("A stale session was found in the DB, cleaning the same and proceeding with patch operations.")
                self.mSetDoSwitch('no')
                self.mUpdateDoSwitchDB()
            else:
                self.mSetDoSwitch(_row[2])
                ebLogInfo("Bug31399993 - In mRefreshData-3. _row[2] = %s" % _row[2])

            self.mSetSha512(_row[1])
            self.mSetBusyClustersList(_row[3])
            self.mSetLockedFor(_row[4])
            self.mSetFabricLock(_row[5])
            ebLogInfo("Ibfabric table entries inside mRefreshData method are as follows : \n%s\n%s\n%s\n%s\n%s\n" % (_row[1], _row[2], _row[3], _row[4], _row[5]))

#########################################################################################################################

# class:            IBClusterPatch
# description:      It is a wrapper that allows to manage the information located in ibfabricclusters. It also allows
#                   to get the ibswitches information and sha512sum for each cluster xml we receive as input.

class IBClusterPatch(object):
    """
    Wrapper that allows to manage the information located in ibfabricclusters.
    It also allows to get the ibswitches information and sha512sum for each
    cluster xml that is received as input.
    """

    def __init__(self, aOptions, aCall=None, aCluCtrl=None):

        self.__fabricID = -1
        self.__fabricSha512 = None
        self._clusterID = -1
        self.__ibSwitchList = []
        self.__node = None
        self.__cluctrl = None

        self.__options = aOptions

        if aCall:
            # Dictionay obtained from parsing JSON input file
            self.__call = aCall

            _hostname = 'hostname'

            # Clean options
            for _key in self.__options.__dict__:
                if _key != _hostname:
                    setattr(self.__options, _key, None)

            # Set cluster XML file
            self.__options.configpath = aCall['XmlOeda']
            # Init cluster
            self.__initClusterHandler()
            # Build clustername (cluster key)
            self.mBuildClusterName()

        elif aCluCtrl:
            self.__cluctrl = aCluCtrl

    def __initClusterHandler(self):
        """
        Initializes a exaBoxCluCtrl object in order to parse the xml file we received.
        """

        from exabox.ovm.clucontrol import exaBoxCluCtrl

        # Get context
        _ebContext = get_gcontext()
        #Create node
        self.__node = exaBoxNode(_ebContext, aLocal=True)
        self.__node.mConnect(aHost="localhost")
        # Create exaBoxCluCtrl object
        self.__cluctrl = exaBoxCluCtrl(aCtx=_ebContext, aNode= self.__node)
        # Parse xml file
        self.__cluctrl.mParseXMLConfig(self.__options)
        # KMS ImportKey requires an UUID to be set, it can be any one
        self.__cluctrl.mSetUUID(str(uuid4()))

        # KMS Mode
        # Fetch ssh keys in case of KMS env. Same keys would be deleted at
        # class exaBoxCluCtrl()-> mDispatchCluster()-> mDeleteOndiskKeys()

        self.__enable_kms = self.__cluctrl.mCheckConfigOption('enable_kms', 'True')
        self.__ociexacc = self.__cluctrl.mCheckConfigOption('ociexacc', 'True')

        # Get one dom0 that belongs to this cluster
        # TODO: EXCLUDED LIST IS NOT PROCESSED IN IB/ROCE PATCHING CLASS
        self.__dom0 = None
        for _dom0, _ in self.__cluctrl.mReturnDom0DomUPair(aIsClusterLessXML=self.__cluctrl.mIsClusterLessXML()):
            self.__dom0 = _dom0
            break

        # In case of upgrading cells from storage/clusterless xml, then we 
        # need to set dom0 with user provided launch node 
        if self.__cluctrl.mIsClusterLessXML() and self.__call['TargetType'] and \
           'cell' in self.__call['TargetType'] and  'AdditionalOptions' in self.__call:
            _addtitional_list = self.__call['AdditionalOptions'][0]
            if 'LaunchNode' in _addtitional_list: 
                self.__dom0 = _addtitional_list['LaunchNode']
                self.__cluctrl.mAppendToHostList(self.__dom0)
            else: 
                ebLogWarn("Unable to get launch node for cell upgrade")

        if not self.__dom0:
            raise ExacloudRuntimeError(0x0604, 0x0A, "Unable to fetch dom0")

        if self.__ociexacc and self.__enable_kms:
            self.__cluctrl.mGetKms().mCheckWallet()
            self.__cluctrl.mCheckifKeysinCasper()
        self.__cluctrl.mImportKeys(self.__options)

        # Get the ibfabric information (ibswitches command)
        if self.__cluctrl.mIsKVM():
            self.mfetchRoceFabric()
        else:
            self.mfetchIBFabric()

    def mfetchRoceFabric(self):
        """
        Update switch list and checksum on switch list
        """
        _fabric_sha512 = None
        _switch_list = []

        _switch = self.__cluctrl.mReturnSwitches(False, True)
        ebLogDebug("RocE Switch list from XML : %s" % _switch)

        _dom0 = exaBoxNode(get_gcontext())
        _dom0.mConnect(aHost = self.__dom0)
        _dom0.mExecuteCmdLog('printf "%s" > %s' % ("\\n".join(_switch), "/tmp/swith_list"))

        for _sw in _switch:
           _switch_list.append({'hostname': _sw.split('.')[0], 'ip':''})

        _in, _out, _err = _dom0.mExecuteCmd("sha512sum /tmp/swith_list |awk '{print $1}'; rm -f /tmp/swith_list")

        # Check if the command generated any error
        _err_lines = _err.readlines()
        if _err_lines:
            # Log the error. Do not bail out though, as it might be a warning.
            _err_msg = "Command generated error. Command, error: sha512sum, '%s'" % (
                        '\n'.join(_err_lines))
            ebLogWarn(_err_msg)
            raise ExacloudRuntimeError(0x0604, 0x0A, "Command returned invalid data. Command: sha512sum")

        # Parse output to get checksum
        _output = _out.readlines()
        if _output:
            _fabric_sha512 = _output[0].strip()
                    
        _dom0.mDisconnect()

        ebLogInfo("CheckSum %s" % _fabric_sha512)

        # Save information
        self.mSetIBSwitchList(_switch_list)
        self.mSetIBFabricSha512(_fabric_sha512)

    def mfetchIBFabric(self):
        """
        Get the ibfabric information for this cluster by running ibswitches command.
        """

        _fabric_sha512 = None
        _switch_list = []

        # Steps to get ibswitches information
        # 1.- Get ibswitches output and sort it
        # 2.- Get sha512sum in order to get a unique id for this ibfabric
        # 3.- Get switch hostnames by parsing the output

        ### Here we are using /tmp to create and then delete a file with ibswitches information.
        ### Should we use /EXAVMIMAGES?
        _cmd = 'ibswitches |sed  "/\(SIF\)\|\(QDR GW\)\|\(MF0\)/Id"| sort -u -b -k 3  > /tmp/fabric.switches; '\
               'sha512sum /tmp/fabric.switches|awk \'{print $1}\'; cat /tmp/fabric.switches; rm -f /tmp/fabric.switches'

        _dom0 = exaBoxNode(get_gcontext())
        _dom0 .mConnect(aHost = self.__dom0)
        _in, _out, _err = _dom0.mExecuteCmd(_cmd)

        # Check if the command generated any error
        _err_lines = _err.readlines()
        if _err_lines:
            # Log the error. Do not bail out though, as it might be a warning.
            _err_msg = "Command generated error. Command, error: ibswitches, '%s'" % (
                        '\n'.join(_err_lines))
            ebLogWarn(_err_msg)

        # A valid ibswithes command output will have a "Switch" string
        # at the begining of every line. Check for the string.
        _switch_pattern = "^Switch"
        _switch_pattern_found = False

        # Parse output to get hostname and IP for each switch found
        _output = _out.readlines()
        if _output and len(_output) > 1:
            _fabric_sha512 = _output[0].strip()
            _output.pop(0)
            for _o in _output:
                # These lines should have the _switch_pattern string.
                # Be relaxed about matching cases and whitespaces.
                if not re.match(_switch_pattern, _o.strip(), re.IGNORECASE):
                    # Log that the line is not valid
                    _err_msg = "Command output is invalid. Command, line pattern, output: ibswitches, '%s', '%s'" % (
                                    _switch_pattern, _o)
                    ebLogError(_err_msg)
                    # Still hoping for a valid line
                    continue

                # Valid line found, extract hostname and ip
                _switch_pattern_found = True
                _re_out = re.match(".*\"(SUN.*)\".*", _o)
                if _re_out:
                    _str = _re_out.groups()[0].strip().split()
                    _switch_list.append({'hostname': _str[-2], 'ip':_str[-1]})

        _dom0.mDisconnect()
        # Raise exception if no valid line was found
        if not _switch_pattern_found:
            raise ExacloudRuntimeError(0x0604, 0x0A, "Command returned invalid data. Command: ibswitches")

        # Save information
        self.mSetIBSwitchList(_switch_list)
        self.mSetIBFabricSha512(_fabric_sha512)

    def mBuildClusterName(self):
        """
        Builds clustername or key: Dom0Name0vmNames0...
        """

        self.__cluname = ""
        _excluded_node_list = []
        # For clusterless, take clucontrol logic which will generate smaller IDs
        if self.__cluctrl.mIsClusterLessXML():
            _dom0s, _, _cells, _ = self.__cluctrl.mReturnAllClusterHosts()
            _host_list=''
            if 'AdditionalOptions' in self.__call:
                _addtitional_list = self.__call['AdditionalOptions'][0]
                if 'ExcludedNodeList' in _addtitional_list:
                    _excluded_node_list = _addtitional_list['ExcludedNodeList']
                else:
                    ebLogDebug("ExcludedNodeList is empty")
            if _dom0s:
                if _excluded_node_list:
                   _dom0s = [_node for _node in _dom0s if _node not in \
                            _excluded_node_list]
                _host_list = _dom0s[0].split('.')[0] + _dom0s[-1].split('.')[0]
            elif _cells:
                if _excluded_node_list:
                   _cells = [_node for _node in _cells if _node not in \
                            _excluded_node_list]
                _host_list = _cells[0].split('.')[0] + _cells[-1].split('.')[0]
            self.__cluname = ''.join(_host_list)
        else:
            self.__cluname = self.__cluctrl.mBuildClusterId()

    def mGetCall(self):
        return self.__call

    def mSetCall(self, aCall):
        self.__call = aCall

    def mGetOptions(self):
        return self.__options

    def mSetOptions(self, aOptions):
        self.__options = aOptions

    def mSetIBFabricID(self, aIBFabricID):
        self.__fabricID = int(aIBFabricID)

    def mGetIBFabricID(self):
        return self.__fabricID

    def mSetIBFabricSha512(self, aSha512):
        self.__fabricSha512 = aSha512

    def mGetIBFabricSha512(self):
        return self.__fabricSha512

    def mSetIBSwitchList(self, aList):
        self.__ibSwitchList = aList

    def mGetIBSwitchList(self):
        return self.__ibSwitchList

    def mSetIBClusterID(self, aClusterID):
        self.__clusterID = int(aClusterID)

    def mGetIBClusterID(self):
        return self.__clusterID

    def mSetClusterName(self, aClusterName):
        self.__cluname = aClusterName

    def mGetClusterName(self):
        return self.__cluname

    def mGetXMLIBSwitchList(self):
        if self.__cluctrl.mIsKVM():
           return self.__cluctrl.mReturnSwitches(False, True)
        else:
           return self.__cluctrl.mReturnSwitches(True)

#########################################################################################################################

class ebCluPatchDispatcher(object):
    """
    It parses an input file and sends recursive calls to exacloud. Monitors the requests.

    Handles the patch orchestration:
        * One patch per cluster allowed at a given time
        * One ibswitch patch per fabric allowed at a given time.
        * If an ibswitch patch is running, then any cluster inside of the fabric should be running
          a patch.

    """

    LOG_DIRECTORY = 'log/patch/'
    LATEST_VER_FROM_FILESYSTEM = 'fileSystem'
    LATEST_VER_FROM_OBJECTSTORE = 'objectStore'

    REGISTRY_ENTRY = 'patch_monitor_cmd'
    #Bug 32025441 - Increased the timeout to 23 hours.
    TIMEOUT = 82800
    SLEEP_TIME = 30
    RETRY_TIME = 10
    EXACLOUD_PATCH_WORKING_SPACE_MB = 0    

    STEP_PARSE_JSON = 'parse_json_file'
    STEP_DOWNLOAD = 'download_patch_files'
    STEP_POPULATE_TABLES = 'populate_tables'
    STEP_MONITOR = 'patch_monitor'
    OCIEXACC_LOC = ''

    DISPATCH_STEP_LIST = [STEP_PARSE_JSON, STEP_DOWNLOAD, STEP_POPULATE_TABLES, STEP_MONITOR]

    def __init__(self, aJob=None):
        
        from exabox.ovm.clucontrol import exaBoxCluCtrl

        self.__exacloud_calls = []
        self.__ibFabrics = []
        self.__expected_requests = 0
        self.__done_requests = []
        self.__pending_requests = []
        self.__reqObj = None
        self.__agent = True
        self.__node = None
        self.__hostname = None
        self.__logDir = None
        self.__zipFilesDir = None
        self.__object_store = {}
        self.__object_store_uri = None
        self.__oss_patch_key = None
        self.__latest_verion_source_loc = self.LATEST_VER_FROM_FILESYSTEM
        _get_context = get_gcontext()

        # Create exaBoxCluCtrl object for its usage inside 
        # ebCluPatchDispatcher class.
        self.__node = exaBoxNode(_get_context, aLocal=True)
        self.__node.mConnect(aHost="localhost")
        self.__cluctrl = exaBoxCluCtrl(_get_context, self.__node)

        # Get Patchpayload location.
        if not self.mGetPatchPayLoad():
            ebLogError("Patch Stage location for ociexacc environment not specified in exabox.conf")
        self.PATCH_PAYLOADS_DIRECTORY = self.mGetPatchPayLoad()

        # Set request object. If not aJob
        self.mSetRequestObj(aJob)

    def mSetRequestObj(self, aJob=None):
        """
        Sets patch request object (Job).
        """

        class _SimpleJob(object):
            def __init__(self):
                self.__uuid = str(uuid4())
                self.__statusInfo = ""
            def mGetUUID(self):
                return self.__uuid
            def mGetWorker(self):
                return 0
            def mGetStatusInfo(self):
                return self.__statusInfo
            def mSetStatusInfo(self, aStatus):
                self.__statusInfo = aStatus

        # If not aJob is provided, then it creates a 'fake' job.
        # This help us to have a specific guid to handle the master
        # patch request lock. One patch request must run at a tim

        if not aJob:
            self.__reqObj = _SimpleJob()
            self.__agent = False
        else:
            self.__reqObj = aJob

    def mGetPatchPayLoad(self):
        """
        In case of OCI EXACC environemnts, PatchPayload details are fetched
        from ociexacc_exadata_patch_download_loc parameter as per details from 
        the exabox.conf file.
        """

        patch_payloads_directory = 'PatchPayloads/'
        self.OCIEXACC = self.__cluctrl.mCheckConfigOption('ociexacc')
        if self.OCIEXACC == "True":
            self.OCIEXACC_LOC = self.__cluctrl.mCheckConfigOption('ociexacc_exadata_patch_download_loc').strip()
            if(self.OCIEXACC_LOC == '' or self.OCIEXACC_LOC == None or not self.OCIEXACC_LOC):
                patch_payloads_directory = False
            else:
                patch_payloads_directory = self.OCIEXACC_LOC + 'PatchPayloads/'
        else:
            ebLogDebug('*** ociexacc parameter is set to False. Retaining the patch path to default exacloud location.')
        return patch_payloads_directory     

    def mGetRequestObj(self):
        """
        Gets patch request object (Job).
        """

        return self.__reqObj

    def mUpdateStatusFromList(self, aStatus, aStep, aComment=''):
        """
        Updates the patch request status for the initial (and common to all patches) steps.
        """

        if not self.__agent:
            return

        _reqobj = self.mGetRequestObj()

        if _reqobj:
            _db = ebGetDefaultDB()
            # First steps are set to be the 15% of all the patching operation
            # The other 85% is divided in the number of requests sent to exacloud
            _pos = str(int( (15.0/len(self.DISPATCH_STEP_LIST)) * (self.DISPATCH_STEP_LIST.index(aStep)+1)))
            if aComment:
                aStep+='-'+aComment

            _reqobj.mSetStatusInfo(str(aStatus)+':'+_pos+':'+aStep)
            _db.mUpdateStatusRequest(_reqobj)


    def mUpdateStatusFromRequests(self):
        """
        Updates the patch request status in order of the number of exacloud
        recursive requests completed.
        """

        if not self.__agent:
            return

        _reqobj = self.mGetRequestObj()

        if _reqobj:
            _db = ebGetDefaultDB()

            # Create statusinfo comment
            _comment = "pending[{0}/{1}]_done[{2}/{1}]".format(len(self.__pending_requests), self.__expected_requests,\
                                                              len(self.__done_requests))
            # Get current status from db
            _status = _reqobj.mGetStatusInfo()
            if _status:
                # There is always a 15% done for the initial steps. Other 85% is from requests being executed.
                _pos = str(15 + int( (85.0/self.__expected_requests) * (len(self.__done_requests))))
                # We change only the comment and percentage instead of all the status
                _s = _status.split('-')[0].split(':')
                _reqobj.mSetStatusInfo(_s[0]+':'+_pos+':'+_s[2]+'-'+_comment)
            _db.mUpdateStatusRequest(_reqobj)

    def mLockPatchCmd(self):
        """
        Acquires patch lock. Only one master patch request must be executed at a time.
        """

        _db = ebGetDefaultDB()

        # Get the request
        _job = self.mGetRequestObj()
        if not _job:
            ebLogError("Patch job object is empty. Nothing to be done")
            return False

        _retry = 20
        # Try multiple times to get the lock for the reason that user can submit
        # multiple cluster requests at the same time. 
        while _retry > 0:
            # Check if there is another patch-cluster request running. We use registry table here.
            if _db.mCheckRegEntry(self.REGISTRY_ENTRY):
                ebLogWarn("mLockPatchCmd: Concurrent patching request detected. Retrying...")
                sleep(random.randint(10,30))
                _retry-=1
            else:
                break
        else:
            ebLogError("mLockPatchCmd: In-spite of multiple attempts, could not get the master lock") 
            return False

        # Acquire lock
        _db.mSetRegEntry(self.REGISTRY_ENTRY, 'True', str(_job.mGetUUID()), str(_job.mGetWorker()))

        ebLogDebug("mLockPatchCmd - Set registry entry: UUID = %s, Worker Id = %s" % (str(_job.mGetUUID()), str(_job.mGetWorker())))
        return True

    def mReleasePatchCmd(self):
        """
        Releases the patch lock. It deletes the entry in registry table.
        """

        # Get the request
        _job = self.mGetRequestObj()
        if not _job:
            ebLogError("mReleasePatchCmd: Patch job object is empty. Nothing to be done")
            return False

        _db = ebGetDefaultDB()
        # Delete row from registry to release patch-cluster cmd
        _db.mDelRegEntry(self.REGISTRY_ENTRY)

        ebLogDebug("mReleasePatchCmd - Delete registry entry: UUID = %s, Worker Id = %s" % (str(_job.mGetUUID()), str(_job.mGetWorker())))

    def mCheckLocalIBFabric(self, aSha512):
        """
        Checks the existance of an ibfabric with same sha512sum.
        It return the local list index for that ibfabric.
        """

        for _index, _fabric in enumerate(self.__ibFabrics):
            if _fabric.mGetSha512() == aSha512:
                return _index
        return -1

    def mAreClustersRepeated(self, aJson):
        """
        Checks if a xml cluster was already mentioned in the JSON file.
        """

        ### TBD - Change the way we do this check:
        # Right now we only compare the oeda xml path. However, we should
        # open each file just to be sure that the cluster is not the same
        _xmls = []

        # Iterate in JSON entries
        for _entry in aJson['Params']:
            if 'Clusters' in _entry:
                for _cluster in _entry['Clusters']:
                    if 'xml_oeda' in _cluster:
                        # Bug30014992: Decode cluster xml using Base64 format 
                        # and then compare the cluster name.
                        _xml_oeda_data = b64decode(_cluster['xml_oeda']).decode('utf8')

                        # Read cluster/customer name from oeda xml 
                        _cluster_name = self.mReadClusterNameFromOedaXml(_xml_oeda_data)

                        if _cluster_name in _xmls:
                            ebLogError("Cluster oeda xml for rack %s is used in more than one entry in JSON file." %\
                                        _cluster_name)
                            return True
                        _xmls.append(_cluster_name)
        return False

    def mCheckPatchFileExistInFileSystem(self):
        """
        Check the existance of required exadata patch files in local 
        file system.
        """

        for _version in self.__object_store.keys():
            for _file in set(self.__object_store[_version]['files']):
                _version_directory = os.path.join(self.PATCH_PAYLOADS_DIRECTORY, _version, _file)

                if _version_directory and os.path.isdir (_version_directory) is True:
                    _version_directory = os.path.abspath(_version_directory)
                    _listfile = os.listdir (_version_directory)
                     
                    if len(_listfile) <= 0:
                        ebLogError("Patch file not found in '%s'" % _version_directory)
                        return ebError(0x0767)
                    elif len(_listfile) > 2:
                        ebLogError("Payload directory contains more than required patch files : '%s'" % _listfile)
                        return ebError(0x0767)
                else:
                    ebLogError("Patch directory '%s' not found" % _version_directory)
                    return ebError(0x0767)
        return 0 

    def mGetFilesFromObjectStore(self):
        """
        Download the files from object store to local filesystem.
        """

        _downloads = {}
        _started_threads = 0
        _passed = 0
        _fd = None

        # Download a patch file
        def _mDownloadSingleFile(aURL, aLocalLocation):
            """
            There are three operations mainly in this method:
               1. Download encrypted software bits from the object sotre
               2. Decrypt the downloaded files
               3. Remove original encrypt file to avail disk space
            """

            # Step 1: 
            #   Download encrypted software bits from the object sotre
            _cmd = "wget %s -O %s -q" % (aURL, aLocalLocation)

            # Connect to localhost
            _node = exaBoxNode(get_gcontext(),aLocal=True)
            _node.mConnect(aHost = self.__hostname)

            # Run command to download from object store
            ebLogDebug("Run command to download from object store: %s" % _cmd)
            _i, _o, _e = _node.mExecuteCmd(_cmd)

            # Wait for wget to complete
            if _o:
                _out = _o.readlines()

            # Save exit code to see if download was actually successfully
            _downloads[aLocalLocation]['exit_code'] =  _node.mGetCmdExitStatus()
            # If exit code not 0, then save error message
            if _downloads[aLocalLocation]['exit_code'] != 0:
                _error_str = _e.readlines()
                if _error_str:
                    _downloads[aLocalLocation]['errors'] = "\n".join(_error_str)
                return
                   
            # Step 2: 
            #     Decrypt the downloaded file using phrase key. 
            #     The output filename should not contain '.gpg'
            _cmd = "gpg --yes --batch --passphrase %s -o %s -d %s" % \
                     (self.__oss_patch_key, aLocalLocation[:-4], aLocalLocation)

            # Run command to decrypt downloaded files. Commenting below debug 
            # since we should not print the passward phrase.
            # ebLogDebug(_cmd)
            _i, _o, _e = _node.mExecuteCmd(_cmd)
            # Wait for gpg command to complete
            if _o:
                _out = _o.readlines()

            # Save exit code to see if decrypt was actually successfully
            _downloads[aLocalLocation]['exit_code'] =  _node.mGetCmdExitStatus()
            # If exit code not 0, then save error message
            if _downloads[aLocalLocation]['exit_code'] != 0:
                _error_str = _e.readlines()
                if _error_str:
                    _downloads[aLocalLocation]['errors'] = "\n".join(_error_str)
                return

            # Step 3: 
            #  Remove original encrypt file to avail diskspace 
            _cmd = "/bin/rm -f %s" % (aLocalLocation)

            # Run command to remove original downloaded files
            ebLogDebug("Run command to remove original downloaded files: %s" % _cmd)
            _i, _o, _e = _node.mExecuteCmd(_cmd)

            # Save exit code to see if decrypt was actually successfully
            _downloads[aLocalLocation]['exit_code'] =  _node.mGetCmdExitStatus()
            # If exit code not 0, then save error message
            if _downloads[aLocalLocation]['exit_code'] != 0:
                _error_str = _e.readlines()
                if _error_str:
                    _downloads[aLocalLocation]['errors'] = "\n".join(_error_str)

            _node.mDisconnect()
        # end of method _mDownloadSingleFile()

        # Get file format for each target and on a particular target version
        def _mGetSoftwareFileFormat(ossUrl, aTargetVersion):
            """
            Prepare file format for the software bits on each target.
            Example:
            The software bit format for the version 12.2.1.1.2.170926 look
            similar to this:-
                CellPatchFile     -> 12.2.1.1.2.170926.patch.zip.gpg
                SwitchPatchFile   -> 12.2.1.1.2.170926.patch.zip.gpg
                DBPatchFile       -> dbserver.patch.zip.gpg
                DomuYumRepository -> exadata_ol6_122112_Linux-x86-64.zip.gpg
                Dom0YumRepository -> exadata_ovs_122112_Linux-x86-64.zip.gpg

            Once download from object store and decrypt, we should see file 
            format as :
                CellPatchFile     -> 12.2.1.1.2.170926.patch.zip
                SwitchPatchFile   -> 12.2.1.1.2.170926.patch.zip
                DBPatchFile       -> dbserver.patch.zip
                DomuYumRepository -> exadata_ol6_122112_Linux-x86-64.zip
                Dom0YumRepository -> exadata_ovs_122112_Linux-x86-64.zip
            """

            _file_format = {}

            # Connect to localhost
            _node = exaBoxNode(get_gcontext(),aLocal=True)
            _node.mConnect(aHost = self.__hostname)

            # Create log dir if not present yet. It so happen that, this dir
            # won't refreshed or truly not created yet, so in that case,
            # nothing wrong to re-create the log dir.
            if os.path.isdir (self.__logDir) is False: 
                _node.mMakeDir(self.__logDir)

            # Run command to list payload dir from object store
            _i, _o, _e = _node.mExecuteCmd('wget --no-parent %s -O %s/ecs_patch_list.txt' % (ossUrl, self.__logDir))

            # Wait for wget to complete
            if _o:
                _out = _o.readlines()

            # Nothing to be done if error returns.
            # If exit code not 0, then save error message
            if _node.mGetCmdExitStatus() != 0:
                _error_str = _e.readlines()
                if _error_str:
                    ebLogInfo("Failed to get list of exadata version files from object store. Error: %s " % _error_str.read())

            _cmd = 'grep "ecs_infra_patch/PatchPayloads" %s/ecs_patch_list.txt | grep %s'
            _i, _o, _e = _node.mExecuteCmd(_cmd % (self.__logDir, aTargetVersion))
            _node.mDisconnect()

            _read_file_format = _o.readlines()
            """
            Read software file format from the output. The above grep output,
            looks similar to below example:
            $ grep "ecs_infra_patch/PatchPayloads" ecs_patch_list.txt | grep 12.2.1.1.2.170926
              ecs_infra_patch/PatchPayloads/12.2.1.1.2.170926/CellPatchFile/12.2.1.1.2.170926.patch.zip.gpg
              ecs_infra_patch/PatchPayloads/12.2.1.1.2.170926/DBPatchFile/dbserver.patch.zip.gpg
              ecs_infra_patch/PatchPayloads/12.2.1.1.2.170926/Dom0YumRepository/exadata_ovs_122112_Linux-x86-64.zip.gpg
              ecs_infra_patch/PatchPayloads/12.2.1.1.2.170926/DomuYumRepository/exadata_ol6_122112_Linux-x86-64.zip.gpg
              ecs_infra_patch/PatchPayloads/12.2.1.1.2.170926/SwitchPatchFile/12.2.1.1.2.170926.patch.zip.gpg
            """
            for _entry in _read_file_format:
                _entry = _entry.replace("\n",'')
                _entry = _entry.strip()
                """
                grep command should return ouput as similar to below in each line
                 "ecs_infra_patch/PatchPayloads/12.2.1.1.2.170926/CellPatchFile/12.2.1.1.2.170926.patch.zip.gpg"
                  so, after spliting with '/', we should get exactly 5 list elements.
                """
                _list = _entry.split('/')
                if _list.__len__() == 5:
                    if _list[3] == ebCluPatchControl.KEY_NAME_CellPatchFile:
                        _file_format[ebCluPatchControl.KEY_NAME_CellPatchFile]= \
                             _list[4]
                    elif _list[3] == ebCluPatchControl.KEY_NAME_SwitchPatchFile:
                        _file_format[ebCluPatchControl.KEY_NAME_SwitchPatchFile]= \
                             _list[4]
                    elif _list[3] == ebCluPatchControl.KEY_NAME_DBPatchFile:
                        _file_format[ebCluPatchControl.KEY_NAME_DBPatchFile]= \
                             _list[4]
                    elif _list[3] == ebCluPatchControl.KEY_NAME_CellPatchFile:
                        _file_format[ebCluPatchControl.KEY_NAME_CellPatchFile]= \
                             _list[4]
                    elif _list[3] == ebCluPatchControl.KEY_NAME_Domu_YumRepository:
                        _file_format[ebCluPatchControl.KEY_NAME_Domu_YumRepository]= \
                             _list[4]
                    elif _list[3] == ebCluPatchControl.KEY_NAME_Dom0_YumRepository:
                        _file_format[ebCluPatchControl.KEY_NAME_Dom0_YumRepository]= \
                             _list[4]
                    else:
                        ebLogInfo("Valid software file format not found: " % _list)

                else:
                    ebLogInfo("Required software file format not found: " % _list)

            return _file_format
        # end of method _mGetSoftwareFileFormat()

        try:
            _oss_url = self.__object_store_uri
            if not _oss_url:
                ebLogError("Object Store URL property not found")

            if _oss_url[-1] != '/':
                _oss_url+='/'

            ebLogInfo("OSS URL : %s" % _oss_url)

            # Iterate over the versions that have missing packages
            for _version in self.__object_store.keys():
                # Form local target directory. ZIP_LOC/version/env_type
                _version_directory = _version+'/'
                self.mCreatePatchZipFilesDirs(_version_directory)

                # Save dir location in object story dictionary
                self.__object_store[_version]['dir'] = os.path.join(self.PATCH_PAYLOADS_DIRECTORY, _version_directory)
                # Get software bit format for the required version
                self.__object_store[_version]['zip_file_format'] = _mGetSoftwareFileFormat(_oss_url, _version) 
                # Iterate over the files that should be downloaded
                for _file in set(self.__object_store[_version]['files']):
                    _local_patch_sub_directory = _version_directory + _file
                    self.mCreatePatchZipFilesDirs(_local_patch_sub_directory)

                    _local_loc = None 
                    _remote_loc = None
                    # Form object store remote location to download 
                    _remote_loc = os.path.join(_oss_url, 'ecs_infra_patch/PatchPayloads/', _version, _file,  self.__object_store[_version]['zip_file_format'][_file])
                    # Form local file system location 
                    _local_loc = os.path.join(self.PATCH_PAYLOADS_DIRECTORY, _version_directory, _file, self.__object_store[_version]['zip_file_format'][_file])

                    # Adding to the status dictionary
                    _downloads[_local_loc] = {'exit_code': 0, 'errors': '', 'thread': None}
                    # Check if the file already exists in the local directory
                    # Ignore last 4 chars from fileformat to skip '.gpg'
                    if  self.__node.mFileExists(_local_loc[:-4]):
                        ebLogInfo("File %s found in file system. No need to download." % (_local_loc[:-4]))
                    else:
                        # Start the thread that will download
                        _t = threading.Thread(target=_mDownloadSingleFile,
                                               args = (_remote_loc, _local_loc))

                        ebLogInfo("Starting to download file %s" % _local_loc)
                        _downloads[_local_loc]['thread'] = _t
                        _t.start()
                        _started_threads+=1

            if _started_threads > 0:
                _finished_d = 0
                ebLogInfo("Waiting for %d thread(s) to finish patch files download..." % _started_threads)
                self.mUpdateStatusFromList(True, self.STEP_DOWNLOAD, "[0/%d]" % (_started_threads))

                for _key in _downloads.keys():
                    if _downloads[_key]['thread']:
                        _downloads[_key]['thread'].join()
                        _finished_d+=1
                        self.mUpdateStatusFromList(True, self.STEP_DOWNLOAD, "[%d/%d]" % (_finished_d, _started_threads))

            for _key, _download in _downloads.items():
                if _download['exit_code'] != 0:
                    _passed = ebError(0x0616)
                    ebLogError("Failed to download file %s:" % _key)
                    ebLogError(_download['errors'])
                    # Delete any file created by mistake
                    if self.__node:
                        ebLogInfo("Cleaning local environment " + _key)
                        self.__node.mExecuteCmd("rm -f " + _key)

            ebLogDebug("Object Store dictionary: %s" % self.__object_store)

        except Exception as e:
            ebLogError("*** "+str(e))
            ebLogError(traceback.format_exc())
            return ebError(0x0616)

        return _passed

    def mParsePatchJson(self, aOptions):
        """
        Parse json input file. It fills a dictionary with each call that 
        should be done to exacloud.
        """

        # Valid target types
        _valid_plugin_types = ['domu', 'dom0', 'dom0domu', 'dom0+dom0domu', 'dom0domu+dom0']

        _jconf = aOptions.jsonconf

        # For each entry in aParams, we can have multiple clusters.
        # This means that for each entry, we will iterate on each on each cluster:
        #       One worker per cluster (even it the cluster has multiple target_types)
        #
        # for entry in json_entries:
        #   for cluster in entry['Clusters']:
        #       Append a new call to exacloud_calls list
        #
        # XML files can't be called in different entries. Each xml must be 
        # mentioned only once per JSON
    
        if _jconf and 'Params' in _jconf.keys():
            # Check xml files are not repeated
            if self.mAreClustersRepeated(_jconf):
                return False

            def mParseLatestVersion(aPatchFile, aVersion):
                """
                This function replaces the 'LATEST' with actual latest
                value in patch path and also construct correct path for the
                patching file.
                Return 'False' if failed to parse the patch path file.
                """

                _dom0YumRepo = False
                if aPatchFile.find(ebCluPatchControl.KEY_NAME_Dom0_YumRepository) > -1:
                    _dom0YumRepo = True

                # If directory path is not having 'LATEST' string and it's not exacc, then 
                # no job here; simply return (aPatchFile) as it is.
                if (not aPatchFile or aPatchFile.find('LATEST') == -1) and self.OCIEXACC != 'True':
                    ebLogInfo("mParseLatestVersion: PatchFile = '%s' " % aPatchFile) 
                    return aPatchFile

                if not aVersion:
                        ebLogError("Invalid input version: %s " % aVersion)
                        return False

                aPatchFile = aPatchFile.replace('LATEST', aVersion)
                if self.OCIEXACC_LOC in self.PATCH_PAYLOADS_DIRECTORY:
                    aPatchFile = os.path.join(self.PATCH_PAYLOADS_DIRECTORY, aVersion, \
                                 aPatchFile.rstrip('/').split('/')[-1])
                if os.path.isdir(aPatchFile) is True:
                    aPatchFile = os.path.abspath(aPatchFile)
                    _listfile = os.listdir (aPatchFile)

                    # Sample Path for _dom0YumRepo for 19.3.6 version
                    # ol7 is for KVM
                    # aPatchFile =
                    # exacloud/PatchPayloads/19.3.6.0.0.200317/Dom0YumRepository/exadata_ol7_19.3.6.0.0.200317_Linux-x86-64.zip,
                    # exacloud/PatchPayloads/19.3.6.0.0.200317/Dom0YumRepository/exadata_ovs_19.3.6.0.0.200317_Linux-x86-64.zip
                    # if there are multiple files are PatchPayloads/19.3.5.0.0.200228/Dom0YumRepository/
                    _dom0files = []
                    if _dom0YumRepo is True and len(_listfile) > 1:
                        for f in (_listfile):
                            _dom0files.append(os.path.join(aPatchFile, f))
                        aPatchFile = ','.join(_dom0files)

                        ebLogDebug("Dom0Repository file for LATEST Version is %s " % aPatchFile)
                    # if there is a single file under PatchPayloads/19.3.5.0.0.200228/<any directory> , proceed as before
                    elif len(_listfile) == 1:
                        aPatchFile = os.path.join(aPatchFile, _listfile[0])
                    else:
                        # it would download from object store. 
                        raise Exception("Patch file is not found in %s " % aPatchFile)
                else:
                    # dir creates when downloading file from object file. 
                    raise Exception("Patch directory path does not exist: %s " % aPatchFile)

                return aPatchFile
            # end of method mParseLatestVersion()

            # Iterate on each entry in Params
            for _entry in _jconf['Params']:
                _operation = ''
                _payload = ''
                _style = ''
                _backupmode = ''
                _enableplugins = ''
                _plugintypes = '' 
                _fedramp = ''
                _patch_retry_flag = ''
                _patch_master_request_id = ''
                _additionaloption = {}
                _version = ''
                _target = []
                _download_files = []

                # Get patch operation
                if 'Operation' not in _entry:
                    ebLogError("'Operation' not provided in json entry")
                    return False
                elif  _entry['Operation'].lower() not in [ebCluPatchControl.TASK_BACKUP_IMAGE,
                                                  ebCluPatchControl.TASK_PREREQ_CHECK,
                                                  ebCluPatchControl.TASK_PATCH,
                                                  ebCluPatchControl.TASK_ROLLBACK_PREREQ_CHECK,
                                                  ebCluPatchControl.TASK_ROLLBACK,
                                                  ebCluPatchControl.TASK_POSTCHECK,
                                                  ebCluPatchControl.TASK_KSPLICE,
                                                  ebCluPatchControl.TASK_ONEOFF]:
                    ebLogError("Invalid 'Operation' value(%s) in json entry." % _entry['Operation'])
                    return False
                else:
                    _operation = _entry['Operation']

                # Get payload type. Default: release
                if 'PayloadType' in _entry and _entry['PayloadType'].lower() in [ebCluPatchControl.PAYLOAD_RELEASE, \
                                                                         ebCluPatchControl.PAYLOAD_NON_RELEASE]:
                    _payload = _entry['PayloadType']
                else:
                    ebLogError("PayloadType not defined in json entry.")
                    return False

                # Get operation style. Default: rolling
                if 'OperationStyle' in _entry and _entry['OperationStyle'].lower() in [ebCluPatchControl.OP_STYLE_ROLLING,
                                                                               ebCluPatchControl.OP_STYLE_AUTO,
                                                                               ebCluPatchControl.OP_STYLE_NON_ROLLING ]:
                    _style = _entry['OperationStyle']
                else:
                    ebLogError("OperationStyle not provided in json entry.")
                    return False

                # Get backup mode. Default: no 
                if 'BackupMode' in _entry and _entry['BackupMode'].lower() in ['', ebCluPatchControl.OP_BACKUPMODE_NO,
                                                                                ebCluPatchControl.OP_BACKUPMODE_YES ]:
                    _backupmode = _entry['BackupMode']
                else:
                    ebLogError("BackupMode either not provided or invalid entry in json entry.")
                    return False

                # Get additional options if any 
                if 'AdditionalOptions' in _entry:
                    _additionaloption = _entry['AdditionalOptions']

                # Get object_store_uri
                if 'object_store_uri' in _entry:
                    self.__object_store_uri = _entry['object_store_uri']
                    ebLogInfo("Object Store URI: %s" % self.__object_store_uri)
                else:
                    ebLogInfo("Object Store URI is not configured or used")

                # Get FedrampEnabled value
                if 'FedrampEnabled' in _entry:
                    _fedramp = _entry['FedrampEnabled']
                    ebLogInfo("Current FedrampEnabled value in EcsProperty Table : %s" % _fedramp)
                else:
                    ebLogInfo("FedrampEnabled value is not configured or used in EcsProperty Table")

                # Get target version
                if 'TargetVersion' in _entry:
                    # Bug-26830429 - Evaluate the available latest version 
                    if _entry['TargetVersion'].upper() == 'LATEST':
                        ebLogInfo("Finding the LATEST target version.")
                        _version = self.mGetLatestPatchVersion()
                    else:
                        _version = _entry['TargetVersion']
                        ebLogInfo("The TargetVersion selected: %s " % _version)

                    if _version not in self.__object_store:
                        self.__object_store[_version] = {'files': _download_files,
                                                         'dir'  : None}
                else:
                    ebLogError("TargetVersion not defined in json entry.")
                    return False

                # Get target type: dom0, domu, cell, ibswitch
                if 'TargetType' in _entry:
                    for _ttype in _entry['TargetType']:
                        if _ttype.lower() in [ebCluPatchControl.PATCH_DOM0, ebCluPatchControl.PATCH_CELL,
                                              ebCluPatchControl.PATCH_IBSWITCH,ebCluPatchControl.PATCH_DOMU]:
                            _target.append(_ttype.lower())
                        else:
                            ebLogWarn("TargetType '%s' not valid. Input will be ignored" % _ttype)
                else:
                    ebLogError("'TargetType' not provided in json entry")
                    return False

                # Get Run Plugin value. Default: no 
                if 'EnablePlugins' in _entry:
                    if _entry['EnablePlugins'].lower() in ['yes','no']:
                        _enableplugins = _entry['EnablePlugins'].lower()
                    else:
                        ebLogError("Invalid plugins option is specified: '%s'" % _entry['EnablePlugins'])
                        return False
                else:
                    ebLogError("EnablePlugins param either not provided or invalid entry in json entry.")
                    return False

                # Get the param value which indicate whether we need to run 
                # plugins on dom0/domu/dom0's domu. Default: none 
                if 'PluginTypes' in _entry:
                    if _entry['PluginTypes']:
                        _tmp_plugin_types = _entry['PluginTypes'].strip()
                        _tmp_plugin_types = _tmp_plugin_types.replace(" ", "") 
                        _tmp_plugin_types = _entry['PluginTypes'].lower()
                      
                        # Validate plugins types
                        if _enableplugins == 'yes' and _tmp_plugin_types in ["", " ", "none"]:
                            ebLogError("Invalid plugin types specified: '%s'." % _tmp_plugin_types)
                            return False
                        elif _enableplugins == 'yes' and ebCluPatchControl.PATCH_DOM0 in _target:
                            if not _tmp_plugin_types in ['dom0', 'dom0domu', 'dom0+dom0domu', 'dom0domu+dom0']:
                                ebLogError("Invalid plugin types specified for dom0: '%s'." % _tmp_plugin_types)
                                return False
                        elif _enableplugins == 'yes' and  ebCluPatchControl.PATCH_DOMU in _target:
                            if not _tmp_plugin_types in ['domu']:
                                ebLogError("Invalid plugin types specified for domU: '%s'." % _tmp_plugin_types)
                                return False

                        # Just copy as it's if no plugin enable specified. 
                        _plugintypes = _tmp_plugin_types 
                else:
                    ebLogError("PluginTypes param either not provided or invalid entry in json entry.")
                    return False

                # Get patching request retry flag. Default: no 
                if 'Retry' in _entry:
                    if _entry['Retry'].lower() in ['yes','no']:
                        _patch_retry_flag = _entry['Retry'].lower()
                    else:
                        ebLogError("Invalid Retry option is specified: '%s'" % _entry['Retry'])
                        return False
                else:
                    ebLogError("Retry param either not provided or invalid entry in json entry.")
                    return False

                # Get patching master request id. Default: none
                if 'RequestId' in _entry:
                    _patch_master_request_id = _entry['RequestId'].lower()
                else:
                    ebLogError("RequestId param either not provided or invalid entry in json entry.")
                    return False

                # If not clusters specified for this entry, then ignore
                if 'Clusters' not in _entry:
                    ebLogWarn("'Clusters' not provided in json entry. This entry will be ignored")
                    continue
                
                # Get patch files
                if _payload == ebCluPatchControl.PAYLOAD_RELEASE:
                    # Just add to download list; actual verification of
                    # download would be done in mGetFilesFromObjectStore() 
                    if ebCluPatchControl.PATCH_CELL in _target:
                        _download_files.append('CellPatchFile')

                    if ebCluPatchControl.PATCH_IBSWITCH in _target:
                        if 'CellPatchFile' in _entry:
                            ebLogWarn("'SwitchPatchFile' not specified in json. 'CellPatchfile' will be used instead.")
                            _entry['SwitchPatchFile'] = _entry['CellPatchFile']
                        else:
                            ### ATENTION: CellPatchFile is added here because it is the same for cells and ibswitches
                            _download_files.append('SwitchPatchFile')

                    if ebCluPatchControl.PATCH_DOM0 in _target: 
                        for _input in ['DBPatchFile', 'Dom0YumRepository']:
                            _download_files.append(_input)

                    if ebCluPatchControl.PATCH_DOMU in _target:
                        for _input in ['DBPatchFile', 'DomuYumRepository']:
                            _download_files.append(_input)
                else:

                    if 'PatchFile' not in _entry:
                        ebLogWarn("'PatchFile' not provided in json entry. Object store will be used to retrieve file.")
                        _download_files.append('PatchFile')
                        _entry['PatchFile'] = None

                # Call common paramters for this entry
                _call = {
                          'Operation'          : _operation,
                          'PayloadType'        : _payload,
                          'OperationStyle'     : _style,
                          'TargetType'         : _target,
                          'TargetVersion'      : _version,
                          'BackupMode'         : _backupmode,
                          'EnablePlugins'      : _enableplugins,
                          'PluginTypes'        : _plugintypes,
                          'Fedramp'            : _fedramp,
                          'Retry'              : _patch_retry_flag,
                          'RequestId'          : _patch_master_request_id,
                          'AdditionalOptions'  : _additionaloption 
                          }

                # Save patch file or files necessary to run the patch.
                if _payload == ebCluPatchControl.PAYLOAD_RELEASE:
                    
                    # Bug-26830429 - Construct the actual path for the target
                    # patch file if dir path has the 'LATEST' value.
                    for _ttype in _target:
                        if _ttype == ebCluPatchControl.PATCH_CELL:
                            _call['CellPatchFile'] = _entry['CellPatchFile']
                            # Construct path with latest version for patch file
                            _call['CellPatchFile'] = mParseLatestVersion(_call['CellPatchFile'], _version)
                            if _call['CellPatchFile'] == False:
                                return False
                        elif _ttype == ebCluPatchControl.PATCH_IBSWITCH:
                            _call['SwitchPatchFile'] = _entry['SwitchPatchFile']
                            # Construct path with latest version for patch file
                            _call['SwitchPatchFile'] = mParseLatestVersion(_call['SwitchPatchFile'], _version)
                            if _call['SwitchPatchFile'] == False:
                                return False

                        elif _ttype == ebCluPatchControl.PATCH_DOM0:
                            _call['DBPatchFile'] = _entry['DBPatchFile']
                            # Construct path with latest version for patch file
                            _call['DBPatchFile'] = mParseLatestVersion(_call['DBPatchFile'], _version)
                            if _call['DBPatchFile'] == False:
                                return False

                            _call['Dom0YumRepository'] = _entry['Dom0YumRepository']
                            _call['Dom0YumRepository'] = mParseLatestVersion(_call['Dom0YumRepository'], _version)
                            if _call['Dom0YumRepository'] == False:
                                return False

                        elif _ttype == ebCluPatchControl.PATCH_DOMU:
                            _call['DBPatchFile'] = _entry['DBPatchFile']
                            # Construct path with latest version for patch file
                            _call['DBPatchFile'] = mParseLatestVersion(_call['DBPatchFile'], _version)
                            if _call['DBPatchFile'] == False:
                                return False

                            _call['DomuYumRepository'] = _entry['DomuYumRepository']
                            _call['DomuYumRepository'] = mParseLatestVersion(_call['DomuYumRepository'], _version)
                            if _call['DomuYumRepository'] == False:
                                return False
                else:
                    _call['PatchFile'] = _entry['PatchFile']
                    for _ttype in _target:
                        if _ttype == ebCluPatchControl.PATCH_DOM0:
                            if 'Dom0YumRepository' in _entry:
                                _call['Dom0YumRepository'] = \
                                   _entry['Dom0YumRepository']
                            break
                        if _ttype ==  ebCluPatchControl.PATCH_DOMU:
                            if 'DomuYumRepository' in _entry:
                                _call['DomuYumRepository'] = \
                                    _entry['DomuYumRepository']
                            break

                # Iterate on each cluster specified in this entry
                for _cluster in _entry['Clusters']:
                    if 'xml_oeda' in _cluster:
                        # Bug30014992: Decode cluster xml using Base64 and 
                        # write into a file and give same reference to
                        # xml oeda 
                        _xml_oeda_data = b64decode(_cluster['xml_oeda']).decode('utf8')

                        # Read cluster/customer name from oeda xml
                        _cluster_name = self.mReadClusterNameFromOedaXml(_xml_oeda_data)

                        _cluster_xml_path = os.path.join(self.__logDir, 
                                                         "exadata_patching_oedaxml_"+_cluster_name+".xml") 

                        if os.path.isdir (self.__logDir):
                            ebLogDebug("Cluster oeda xml file location on exacloud: %s" % _cluster_xml_path) 
                        else:
                            ebLogError("Patch log location '%s' is not existing" % self.__logDir) 

                        try:
                            with open(_cluster_xml_path, "w") as cluserxmldata:
                               cluserxmldata.write(_xml_oeda_data)

                            ebLogDebug("Cluster oeda xml written to a file on exacloud: %s" % _cluster_xml_path) 
                            _call['XmlOeda'] = _cluster_xml_path 
                        except Exception as e:
                            ebLogError("Fail to write the cluster oeda xml '%s'. Error: %s" % \
                                        (_cluster_xml_path, str(e))) 
                            ebLogError("The cluster %s will be ignored" % _cluster_name)
                            continue

                        if 'target_env' in _cluster and _cluster['target_env'] in [ebCluPatchControl.ENV_PRODUCTION, \
                           ebCluPatchControl.ENV_PREPRODUCTION, ebCluPatchControl.ENV_DEVELOPMENT, \
                           ebCluPatchControl.ENV_TEST]:

                            _call['TargetEnv'] = _cluster['target_env']
                            _call['RackName']  = _cluster['rack_name']
                            # Add to object store only if necessary
                            if _download_files:
                                for _f in _download_files:
                                    if _f not in self.__object_store[_version]['files']:
                                        self.__object_store[_version]['files'].append(_f)
                        else:
                            ebLogError("target_env not provided for xml '%s'. This cluster will be ignored" % \
                                       _cluster_xml_path)
                            continue
                        # Append a new call to the list of exacloud calls to be done
                        self.__exacloud_calls.append(copy.deepcopy(_call))
                    else:
                        ebLogWarn("'xml_oeda' not found in cluster entry. Input will be ignored")
                self.ClusterCount = len(_entry['Clusters'])
            return True
        return False

    def mSetPathToObjectStorePatchFiles(self):
        """
        Assign each call the correct path of the images that were
        downloaded from object store.
        """

        _delete = []
        _found = True

        for _index, _call in enumerate(self.__exacloud_calls):
            for _file in ['CellPatchFile', 'SwitchPatchFile','DBPatchFile', 
                          'Dom0YumRepository', 'DomuYumRepository', 'PatchFile']:
                if _file not in _call:
                    continue

                if _call[_file] is None:
                    _target_file = _file
                    _found = False

                    if _call['TargetVersion'] in self.__object_store:
                        if _target_file in self.__object_store[_call['TargetVersion']]['files']:
                            _obj_store_dir = os.path.join(self.__object_store[_call['TargetVersion']]['dir'] , _target_file)
                            if _obj_store_dir and os.path.isdir (_obj_store_dir) is True:
                                _obj_store_dir = os.path.abspath(_obj_store_dir)
                                _listfile = os.listdir (_obj_store_dir)
                                if len(_listfile) == 1:
                                    _call[_file] = os.path.join(_obj_store_dir, _listfile[0])
                                    _found = True
                                else:
                                    ebLogError("Target patch file not found in %s' " % _obj_store_dir)
                                    ebLogError("Payload directory contains : %s' " % _listfile)
                            else:
                                ebLogError("Target patch directory '%s' not found." % _obj_store_dir)

                    if not _found:
                        ebLogWarn("File %s not found for call with index %d. "\
                                   "This call will be discarded" % (_file, _index))
                        _delete.append(_index)
                        break
                else:
                    # Evaluate the target file and get the path to it 
                    if os.path.isdir (_call[_file]) is True:
                        _call[_file] = os.path.abspath(_call[_file])
                        _listfile = os.listdir (_call[_file])
                        if len(_listfile) == 1:
                            _call[_file] = os.path.join(_call[_file], _listfile[0])
                        else:
                            ebLogError("Patch file not found in %s " % _call[_file])
        if _delete:
            ebLogInfo("Deleting exacloud calls with incomplete input parameters.")
            for _index in reversed(_delete):
                self.__exacloud_calls.pop(_index)

        ebLogDebug("Exacloud calls: %s" % self.__exacloud_calls)

    def mCheckExacloudMnt(self):
        """
        Validates the disk space usage of thread and requests log location to 
        accomdate newer logs once patching is complete. In the current case, if 
        there is no space available on the logs location. Patching task would 
        fail in the end due to unable to copy the logs from the patched nodes 
        although upgrade was successful.
        """

        # Read exacloud patch working space size
        _rc = True
        self.EXACLOUD_PATCH_WORKING_SPACE_MB = self.__cluctrl.mCheckConfigOption('exacloud_patch_working_space_mb').strip()
        if (not self.EXACLOUD_PATCH_WORKING_SPACE_MB) or self.EXACLOUD_PATCH_WORKING_SPACE_MB == '' or (int(self.EXACLOUD_PATCH_WORKING_SPACE_MB) == 0):
            ebLogError("Invalid exacloud disk space configured to store exacloud thread and request logs : %s , please validate the parameter 'exacloud_patch_working_space_mb' in exabox.conf and re-run patching." % self.EXACLOUD_PATCH_WORKING_SPACE_MB)
            _rc = False
        else:
            _df_cmd = "/bin/df -mP ."
            _in, _out, _err = self.__cluctrl.mExecuteCmd(_df_cmd)

            _df_cmd = "/bin/awk '{print $4}'"
            _in, _out, _err = self.__cluctrl.mExecuteCmd(_df_cmd, aStdIn=_out)

            _df_cmd = "/bin/grep -vi Avail"
            _in, _out, _err = self.__cluctrl.mExecuteCmd(_df_cmd, aStdIn=_out)
            _cluTotal = int(self.EXACLOUD_PATCH_WORKING_SPACE_MB) * int(self.ClusterCount)
            _output = _out.readlines()
            _out = _output[0].strip()
            if int(_out) < int(_cluTotal):
                ebLogInfo("\nDisk statistics on exacloud area before patch operation: ")
                ebLogInfo("   - Free disk space on exacloud area : %s MB" % _out)
                ebLogInfo("   - Disk space expected on exacloud area for thread and request logs: %s MB(Disk space required to store logs per cluster) * %s(Number of clusters requested to patch) = %s MB \n" % (self.EXACLOUD_PATCH_WORKING_SPACE_MB, self.ClusterCount, _cluTotal))
                _rc = False
        return _rc

    def mPopulatePatchTables(self, aOptions):
        """
        Populates the db tables with all the ibfabric, clusters and ibswitches 
        information. It is possible that information is already in the db.
        """

        _fabricObj = None
        _fabricID = None
        _fabricIndex = None
        _cluName = None
        _clusterIndex = None

        _db = ebGetDefaultDB()

        # Iterate on each exacloud dictionary call
        for index, _call in enumerate(self.__exacloud_calls):
            # Create Cluster object
            _clu = IBClusterPatch(aOptions, _call)

            # Get sha512 and switch list that we got from ibswitches command/ It is necessary
            # to check wether the fabric it belongs to already exists or not
            _tmpSha512 = _clu.mGetIBFabricSha512()
            _tmpIBSwitches = _clu.mGetIBSwitchList()
            _cluName = _clu.mGetClusterName()

            # Check if the fabric is already in the local object list
            _fabricIndex = self.mCheckLocalIBFabric(_tmpSha512)
            _fabricID = -1
            # If fabric is not listed, then check in DB
            if _fabricIndex == -1:
                _row = _db.mCheckIBFabricEntry(aSha512=_tmpSha512)
                # If the sha512 was not found, the fabric doesn't exist or ibswitches in the fabric changed
                if not _row:
                    ebLogInfo("Fabric '%s' not found in DB" % _tmpSha512)
                    # Check if at least one of the switches are already in the table
                    _sw_row = _db.mCheckIBFabricIBSwitchesTable([ _sw['hostname'] for _sw in _tmpIBSwitches])

                    # If found, then the fabric was already there but sha512 changed.
                    if _sw_row:
                        ebLogInfo("At least one switch was found in IBFabricIBSwitches table")
                        _row = _db.mCheckIBFabricEntry(aFabricID=_sw_row[1])
                        if _row:
                            # Check if the fabric found is already in the local list
                            _fabricIndex = self.mCheckLocalIBFabric(_row[1])
                            if _fabricIndex == -1:
                                _fabricObj = IBFabricPatch(_row[0], _row[1], _row[2], _row[3], None, _row[4], _row[5])
                                self.__ibFabrics.append(_fabricObj)
                                _fabricIndex = len(self.__ibFabrics) - 1
                            else:
                                _fabricObj = self.__ibFabrics[_fabricIndex]
                        else:
                            ebLogError("IBFabric not found in DB. Cluster xml entry will be ignored.")
                            continue
                    # If there are no switches in the table, then we must add the new fabric
                    else:
                        ebLogInfo("Adding IBFabric '%s' to DB" % _tmpSha512)
                        _db.mSetIBFabricEntry(_tmpSha512)
                        _row = _db.mCheckIBFabricEntry(aSha512=_tmpSha512)
                        if _row:
                            _fabricObj = IBFabricPatch(_row[0], _row[1], _row[2], _row[3], None, _row[4], _row[5])
                            self.__ibFabrics.append(_fabricObj)
                            _fabricIndex = len(self.__ibFabrics) - 1
                        else:
                            ebLogError("IBFabric not found in DB. Cluster xml entry will be ignored.")
                            continue

                # If fabric was already registred in DB
                else:
                    ebLogInfo("IBFabric with id=%s already registered in DB" % _row[0])
                    _fabricObj = IBFabricPatch(_row[0], _row[1], _row[2], _row[3], None, _row[4], _row[5])
                    self.__ibFabrics.append(_fabricObj)
                    _fabricIndex = len(self.__ibFabrics) - 1

                if not _fabricObj:
                    ebLogError("IBFabric Object empty. Cluster xml entry will be ignored")
                    continue
            else:
                _fabricObj = self.__ibFabrics[_fabricIndex]
                ebLogInfo("IBFabric '%s' with id=%d found IBFabric local list" % (_fabricObj.mGetSha512(),
                                                                                  _fabricObj.mGetIBFabricID()))
            ebLogError("Bug31399993 - Before calling mRefreshData")
            _fabricObj.mRefreshData()
            ebLogError("Bug31399993 - After calling mRefreshData")
            _fabricID = _fabricObj.mGetIBFabricID()
            ebLogError("Bug31399993 - Before calling mRefreshData. _fabricID = %s" % _fabricID)
            #_fabric_busy_clu = eval(fabricObj.mGetBusyClustersList())

            ########### CLuster Check ###########

            # Set FabricID in cluster object
            _clu.mSetIBFabricID(_fabricID)

            # Check if cluster exists in fabric object
            _clusterIndex = _fabricObj.mCheckCluster(_cluName)

            # If cluster is not listed in the fabric, then check if it already exists in DB
            if _clusterIndex == -1:
                _row = _db.mCheckIBFabricClusterTable(aClusterName=_cluName)
                # If cluster not in DB, add a new entry
                if not _row:
                    ebLogInfo("Adding cluster '%s' to IBFabricCluster" % _cluName)
                    _db.mSetIBFabricClusterEntry(_clu)
                # Check one more time to get the Cluster ID
                _row = _db.mCheckIBFabricClusterTable(aClusterName=_cluName)
                #If cluster exists in DB
                if _row:
                    if int(_row[1]) == _fabricID:
                        _clu.mSetIBClusterID(int(_row[0]))
                        _clusterIndex = _fabricObj.mAddCluster(_clu)
                        ebLogInfo("Cluster '%s' clu_id=%s fabric_id=%s added to fabric's cluster local list" % \
                                  (_row[2], _row[0], _row[1]))
                    else:
                        # TBD: We should check if there is anything running in that cluster. If not,
                        #      Then we should remove the entry and add it again.
                        ebLogInfo("Cluster not attached to the correct Fabric. Cluster xml entry will be ignored")
                        continue
                # Cluster not found in DB. Add a new entry
                else:
                    ebLogError("Cluster %s not found in DB. Cluster xml entry will be ignored" % _cluName)
                    continue
            # Cluster is already in the IBFabric Cluster List
            else:
                _clu = _fabricObj.mGetCluster(_clusterIndex)


            ##### IBSwitches Check ######

            # Get domain. We must get the domain from the switches lsited in the xml file.
            # ibswitches command list the hostname with no domain
            _xml_switches = _clu.mGetXMLIBSwitchList()
            _domain = ".".join(_xml_switches[0].split('.')[1:])
            # List of switches. We update the list of switches at the end
            _updatedList = []
            # List of ibswitch hostnames (from ibswitches command) with domain
            _ibswitches_output = [ _sw['hostname']+'.'+_domain for _sw in _tmpIBSwitches]

            # Iterate in all the ibswitches
            for _switch in  _ibswitches_output:
                _add = True
                # Check if the ibswitch is already in DB
                _list = _db.mGetListOfIBFabricIBSwitches(_fabricID)
                for _row in _list:
                    if _switch.strip() == str(_row[2]).strip():
                        _add = False
                        break
                # If not, then add a new entry with the ibswitch
                if _add:
                    _db.mSetIBFabricIBSwitchesEntry(_fabricID, _switch)
                    ebLogInfo("Switch '%s' added to IBFabric with id=%d" % (_switch, _fabricID))
                _updatedList.append(_switch)
            # Update the local list of switches for this fabric
            _fabricObj.mSetIBSwitches(_updatedList)

            # Set do_switches flag only if we are actuall doingany task in ibswitches
            _fabric_do_switches = str(_fabricObj.mGetDoSwitch()).lower()
            if _fabric_do_switches == 'no' and ebCluPatchControl.PATCH_IBSWITCH in  _call['TargetType']:
                ebLogInfo("Set do_switch to 'yes' in fabric with id=%d" % _fabricID)
                _fabricObj.mSetDoSwitch('yes')
                _fabricObj.mUpdateDoSwitchDB()

    def mGetCountOfRequests(self):
        """
        Calculates the number of expected exacloud requests:
        One request per cluster + one request per ibfabric (ibswitch task)

        TODO: The following for loop assumes that, one dispatcher thread support one
              cluster patching request. But, it's better to support multiple cluster upgrade
              with single dispatcher thread.
        """

        _requests = 0
        for _f in self.__ibFabrics:
            ebLogInfo("Bug31399993 - In mGetCountOfRequests")
            for _c in (_f.mGetCluObjects()):
                _call = _c.mGetCall()
                ebLogInfo("Bug31399993 - In mGetCountOfRequests - Case 1")
                '''
                 Case 1 : when the cluster list is none or empty and the value of doswitch is yes and locking acquired for target is ibswitch, we need to
                          set the request count to 0 and return as we do not want to proceed when an ongoing patch operation is related to ibswitch.
                          Concurrent requests to other racks that involve a shared ib fabric and an ibswitch-any other target scenario is not 
                          allowed.

                          -> Valid values for mGetBusyClustersList() are : integer values separated by spaces.
                          -> Valid values for mGetLockedFor() are : ibswitch/non_ibswitch/none
                          -> Valid values for mGetDoSwitch() are : yes/no
                '''
                if _f.mGetBusyClustersList() not in [ None, '' ] and ((_f.mGetDoSwitch().lower() == 'yes' and _f.mGetLockedFor().lower() in [ 'ibswitch' ]) or (_f.mGetLockedFor().lower() in [ 'non_ibswitch' ] and ebCluPatchControl.PATCH_IBSWITCH in _call['TargetType'])):
                    ebLogError("*** IBSwitch/Non-IBSwitch target patching cannot run at the same time in a shared IB fabric environment, unable to process this request.")
                    return _requests

                '''
                 Case 2 : Just increment the request count, if given target type is ibswitch.
                '''
                ebLogInfo("Bug31399993 - In mGetCountOfRequests - case 2")
                if _f.mGetDoSwitch().lower() == 'yes' and ebCluPatchControl.PATCH_IBSWITCH in _call['TargetType']:
                    _requests += 1
                    ebLogInfo("Expected number of requests in case of an IBSwitch operation : %s" % (_requests))
                    return _requests

                '''
                 Case 3 : When the target type is something other than IBSwitch, increment the _requests counter by 1.
                '''
                ebLogInfo("Bug31399993 - In mGetCountOfRequests - case 3")
                for _target in  _call['TargetType']:
                    if _target in [ebCluPatchControl.PATCH_CELL, ebCluPatchControl.PATCH_DOM0, \
                                   ebCluPatchControl.PATCH_DOMU]:
                        _requests+=1
                        ebLogInfo("Expected number of requests in case of a Non-IBSwitch operation : %s" % (_requests))
                        break

        ebLogInfo("Bug31399993 - In mGetCountOfRequests - _requests = %s" % _requests)

        return _requests

    def mDispatchCall(self, aFabric, aCluster, aNonIBSwitch):
        """
        Sends a patch request to exacloud.
        """

        _default_error_json = { 'status':    'Done',
                                'uuid':      '00000000-0000-0000-0000-000000000000',
                                'error':     '-1',
                                'error_str': 'Unable to send request.',
                                'non_ibswitch': aNonIBSwitch,
                                'cluster_id': None,
                                'fabric_ptr': None}

        # Get Options
        _options = aCluster.mGetOptions()
        # The patch information (files, version, etc...) are in this dictionary.
        # We will put in the jsonconf option
        _call = copy.deepcopy(aCluster.mGetCall())
        # We must add the cluster_id so we can keep track of the cluster and ibfabric lock
        _call['ClusterID'] = str(aCluster.mGetIBClusterID())
        # If this cluster wants to do a non_ibswitch patching but in the list of targets ibswitch is included,
        # then we must take it out.
        if aNonIBSwitch:
            _found = False
            for _index, _ttype in enumerate(_call['TargetType']):
                if _ttype == ebCluPatchControl.PATCH_IBSWITCH:
                    _found = True
                    break
            if _found:
                _call['TargetType'].pop(_index)

        else:
                # If doing an ibswitch operation, then no other operation should pass in here.
                _call['TargetType'] = [ebCluPatchControl.PATCH_IBSWITCH]

        if len(_call['TargetType']) == 0:
            return None

        _options.configpath = _call['XmlOeda']
        _options.jsonconf = _call
        _options.clusterctrl = _call['Operation']

        # Acquire lock. We need to acquire the lock even beofre launching the request.
        if not aFabric.mLock(_call['ClusterID'], aNonIBSwitch):
            ebLogWarn("Unable to acquire lock. The request will be ignored")
            _default_error_json['cluster_id'] = _call['ClusterID']
            _default_error_json['fabric_ptr'] = aFabric
            return _default_error_json

        # Create client that will send the request
        _client = ebExaClient()
        # Send request
        _client.mIssueRequest(aOptions=_options)
        # Get JSON response to track the uuid for that request
        _json_response  = _client.mGetJsonResponse()

        if 'error' not in _json_response:
            _json_response['error'] = 'Undef'
            _json_response['error_str'] = 'Undef'
            self.mLinkRequestDirectory(_json_response['uuid'])
        else:
            if _json_response['error'] != 'Undef' or _json_response['error'] == '':
                ebLogWarn('Error detected in request. Releasing cluster lock')
                if not aNonIBSwitch:
                    aFabric.mSetDoSwitch('no')
                    aFabric.mUpdateDoSwitchDB()
                aFabric.mRelease(_call['ClusterID'])

        _db = ebGetDefaultDB()
        _db.mInsertChildRequestToPatchList(self.mGetRequestObj().mGetUUID(),
                                           _json_response['uuid'],
                                           'Undef')

        return {'status':    _json_response['status'],
                'uuid':      _json_response['uuid'],
                'error':     _json_response['error'],
                'error_str': _json_response['error_str'],
                'non_ibswitch': aNonIBSwitch,
                'cluster_id':   _call['ClusterID'],
                'fabric_ptr':   aFabric }

    def mUpdatePendingCalls(self):
        """
        Updates all the exacloud requests information by reading the db requests table.
        """

        _done = []
        _master_patch_list = {}
        _updated_patch_list = {}
        _db = ebGetDefaultDB()
        _master_uuid = self.mGetRequestObj().mGetUUID()

        # See if the request was done through the agent
        #if _master_req and _master_req.__class__.__name__ != '_SimpleJob':
        #    _master_patch_list = {}
            # Refresh master request data
            #_master_req.mLoadRequestFromDB(_master_req.mGetUUID())
            # Get patch_list from the master request
            #_patch_col = _master_req.mGetPatchList()
            #if _patch_col and _patch_col.startswith('Undef') is False:
            #    try:
            #        _master_patch_list = literal_eval(_patch_col.strip())
            #    except:
            #        _master_patch_list = {}

        # Get patch list
        _rows = _db.mGetChildRequestsList(_master_uuid)
        if _rows:
            for _row in _rows:
                _master_patch_list[_row[0]] = _row[1]

        # Update individual requests
        for _index, _request in enumerate(self.__pending_requests):

            if not _request:
                _done.append(_index)
                continue

            _row = _db.mGetRequest(_request['uuid'])
            if _row:
                self.__pending_requests[_index]['status'] = _row[1]
                self.__pending_requests[_index]['error'] = _row[6]
                self.__pending_requests[_index]['error_str'] = _row[7]

            # If request finished, then we must delete it from pending list
            if self.__pending_requests[_index]['status'].startswith('Done'):
                _done.append(_index)
                # Check there is no lock stuck in there
                _non_ib_switch = self.__pending_requests[_index]['non_ibswitch']
                _cluid = self.__pending_requests[_index]['cluster_id']
                _fabric = self.__pending_requests[_index]['fabric_ptr']
                _fabric.mRefreshData()
                _list = _fabric.mGetBusyClustersList().strip().split()
                for _id in _list:
                    if int(_id.strip()) == int(_cluid):
                        ebLogWarn('Lock stuck in db. Cleaning lock.')
                        if not _non_ib_switch:
                            _fabric.mSetDoSwitch('no')
                            _fabric.mUpdateDoSwitchDB()
                        _fabric.mRelease(_cluid)

            # Update request information in the patch list
            _uuid = self.__pending_requests[_index]['uuid']
            _status = self.__pending_requests[_index]['status']
            if self.__pending_requests[_index]['error'] != 'Undef' and \
               self.__pending_requests[_index]['error'] != '0':
                if self.__pending_requests[_index]['error'].strip() == '701-614':
                    _status = 'No_action_required'
                    ebLogInfo('No action required')
                else:
                    _status = 'Failed'
            if _uuid in _master_patch_list and _master_patch_list[_uuid] != _status:
                _updated_patch_list[_uuid] = _status
        # Update patch list in the db
        for _key in _updated_patch_list.keys():
            _db.mUpdateChildRequestStatus(_master_uuid, _key, _updated_patch_list[_key])

        # Delete request from pending list and add it to done requests list
        for _index in reversed(_done):
            self.__done_requests.append(self.__pending_requests.pop(_index))

        # Update progress bar
        self.mUpdateStatusFromRequests()
        return ( len(self.__done_requests) + len(self.__pending_requests))

    def mGetFabricIDsFromPendingRequests(self):
        """
        Returns the IDs from the fabrics that have pending requests
        """

        return  [int(_req['fabric_ptr'].mGetIBFabricID()) for _req in self.__pending_requests]


    def mDumpCallInformation(self):
        """
        Prints all the exacloud requests information
        """

        ebLogInfo("***** Patch Requests - Done*****")
        for _req in self.__done_requests:
            ebLogInfo('uuid: %-40s  status:%-10s ret_code:%-10s error_str:%s' % (_req['uuid'], _req['status'],
                                                                                 _req['error'], _req['error_str']))
            if _req['uuid'] != "00000000-0000-0000-0000-000000000000" or _req['error_str'] != "Unable to send request":
                # Incident logs collection as per ENH 30006991
                # for easier analysis and debugging.
                self.__cluctrl.mHandlerGenIncidentFile('patching', _req['uuid'])

        ebLogInfo("***** Patch Requests - Pending *****")
        for _req in self.__pending_requests:
            ebLogInfo('uuid: %-40s  status:%-10s ret_code:%-10s error_str:%s' % (_req['uuid'], _req['status'],
                                                                                 _req['error'], _req['error_str']))

    def mMonitorPatchRequest(self):
        """
        Monitor the exacloud patch requests. I takes care of orchestration:
        1.- It sends all the non_ibswitch requests.
        2.- It sends ibswitch requests only when non_ibswitch requests are running in the fabric
        3.- It waits until all the requests are done.
        """

        _db = ebGetDefaultDB()

        ebLogInfo("\n*** Starting Patch Request Monitor. Expected_requests = %d ***" % self.__expected_requests)

        # Start by sending the non_ibswitch requests
        #for _fabric in self.__ibFabrics:
        #    _clusterObjs = _fabric.mGetCluObjects()
        #    for _clu in _clusterObjs:
        #        _res = self.mDispatchCall(_fabric, _clu, True)
        #        if _res:
        #            self.__pending_requests.append(_res)

        _elapsed_time = 0
        _sent_requests = 0

        try:

            while True:

                if _sent_requests < self.__expected_requests:

                    # Get fabric ids from pending requests
                    _pending_fabric_ids = self.mGetFabricIDsFromPendingRequests()

                    # Iterate in all fabrics
                    for _fabric in self.__ibFabrics:
                        # Refresh object data (read db info)
                        _fabric.mRefreshData()

                        # If pending requests in fabric ignore
                        if int(_fabric.mGetIBFabricID()) in _pending_fabric_ids:
                            continue

                        # If clusters are locked, then go to next fabric
                        if int(_fabric.mGetFabricLock()) != 0:
                            continue

                        # If fabric must do an ibswitch task and no cluster is locked, we can run the task
                        if str(_fabric.mGetDoSwitch()).lower() == 'yes':
                            # Get first cluster that has 'ibswitch' included in TargetType
                            _clusterObjs = _fabric.mGetCluObjects()
                            for _clu in _clusterObjs:
                                if ebCluPatchControl.PATCH_IBSWITCH in _clu.mGetCall()['TargetType']:
                                    _retry = 3
                                    # We must be careful here. It is possible patch locks are already released but
                                    # registry table is not cleaned yet. In this case the exacloud call will be sent
                                    # but it will fail.
                                    while _retry > 0:
                                        if _db.mCheckRegEntry(_clu.mGetClusterName()):
                                            ebLogInfo("Cluster with key '%s' is busy. Retry in 10 secs" % \
                                                      _clu.mGetClusterName())
                                            _retry -= 1
                                        else:
                                            break
                                        sleep(self.RETRY_TIME)

                                    # Dispatch ibswitch requests
                                    _res = self.mDispatchCall(_fabric, _clu, False)
                                    if _res:
                                        self.__pending_requests.append(_res)
                                    break

                _sent_requests = self.mUpdatePendingCalls()

                if (_elapsed_time % (self.SLEEP_TIME*5)) == 0:
                    ebLogInfo("\t\tmonitor_status: ---> Done=[%d], Pending=[%d], Expected[%d]" % ( \
                               len(self.__done_requests), len(self.__pending_requests), self.__expected_requests))

                # If all requests are done, then finish monitor
                if len(self.__done_requests) == self.__expected_requests:
                    self.mDumpCallInformation()
                    break

                # Sleep monitor
                sleep(self.SLEEP_TIME)
                _elapsed_time+= self.SLEEP_TIME

                # If timeout, then finish the monitor
                if _elapsed_time>= self.TIMEOUT:
                    ebLogError("Patch request monitor timed out. Admin should check for individual requests status:")
                    self.mDumpCallInformation()
                    return ebError(0x0603)
                
        except Exception as e:
                raise e

        # Get return code based on the sent requests
        _stat = None
        _req_uuid = self.mGetRequestObj().mGetUUID()
        _patch_rows = _db.mGetChildRequestsList(_req_uuid)

        if _patch_rows:
            for _row in _patch_rows:
                if _row[1] == 'Failed' or _row[1] == 'Pending':
                        return ebError(0x0605)
                if _row[1] == 'No_action_required' and _stat is None:
                        _stat = _row[1]
                if _row[1] == 'Done':
                        _stat = _row[1]

        for _req in self.__done_requests:
            if _req['uuid'] == '00000000-0000-0000-0000-000000000000':
                return ebError(0x0605)

        if _stat and _stat == 'No_action_required':
            return ebError(0x0614)
        return 0

    def mStartPatchRequestExecution(self, aOptions):
        """
        Initial master patch function:
        1.- Acquire master patch lock
        2.- Parses JSON file
        3.- Populates tables
        4.- Releases master patch lock
        5.- Starts monitor
        """

        _rc = 0
        _concurrent = False

        if 'hostname' in  aOptions:
            self.__hostname = aOptions.hostname

            self.__node = exaBoxNode(get_gcontext(),aLocal=True)
            self.__node.mConnect(aHost=aOptions.hostname)
   
        try:

            # Acquire patch-cluster cmd lock
            ebLogInfo("Step 1 of 5: Acquiring master patch lock")
            if self.mLockPatchCmd() is False:
                ebLogError("*** Another patch-cluster request is in process."
                           " Try later.")
                _concurrent = True
                return ebError(0x0601)
            ebLogInfo("Acquired master patch lock")

            # Create log directory
            self.__logDir = self.mCreateLogDirectory()

            # Parse JSON input file
            ebLogInfo("Step 2 of 5: Parse JSON file")
            self.mUpdateStatusFromList(True, self.STEP_PARSE_JSON)
            if not self.mParsePatchJson(aOptions):
                ebLogError("Failed to validate the input configuration file.")
                return ebError(0x0602)
            ebLogInfo("Parsed JSON file")

            # Space usage check on exacloud mount point to ensure thread and 
            # request logs are stored and patching completes without any issues.
            if not self.mCheckExacloudMnt():
                ebLogError("Insufficient disk space to store exacloud requests and thread logs.")
                return ebError(0x0777)
            else:
                ebLogDebug("Sufficient free disk space found for exacloud threads and request logs.")


            if self.__latest_verion_source_loc == self.LATEST_VER_FROM_OBJECTSTORE and \
               self.__object_store and sum(len(self.__object_store[_version]['files']) \
               for _version in self.__object_store) > 0:
                ebLogDebug("Get patch files from object store if necessary.")
                self.mUpdateStatusFromList(True, self.STEP_DOWNLOAD)
                _rc = self.mGetFilesFromObjectStore()
                if _rc != 0:
                    return _rc
                #Set path to downloaded files into each request to be launched
                self.mSetPathToObjectStorePatchFiles()
            elif self.__latest_verion_source_loc == self.LATEST_VER_FROM_FILESYSTEM:
                ebLogDebug("Using file system to read patch files.")
                _rc = self.mCheckPatchFileExistInFileSystem()
                if _rc != 0:
                    return _rc

            # Populate IBFabric Table
            ebLogInfo("Populate IBFabric Table")
            self.mUpdateStatusFromList(True, self.STEP_POPULATE_TABLES)
            self.mPopulatePatchTables(aOptions)
            ebLogInfo("Populated IBFabric Table")

            # Get total number of expected requests
            self.__expected_requests = self.mGetCountOfRequests()

            if self.__expected_requests == 0:
                ebLogError("No patching requested derived. Terminating the patching request")
                return ebError(0x0606)

            ebLogInfo("Total number of expected requests = %d" % (
                self.__expected_requests ) )

            # Start by sending the non_ibswitch requests
            ebLogInfo("Start sending non_ibswitch requests")
            for _fabric in self.__ibFabrics:
                _clusterObjs = _fabric.mGetCluObjects()
                for _clu in _clusterObjs:
                    _res = self.mDispatchCall(_fabric, _clu, True)
                    if _res:
                        self.__pending_requests.append(_res)
            ebLogInfo("Done sending non_ibswitch requests")

        except ExacloudRuntimeError as ecre:
            ebLogError("mStartPatchRequestExecution: ExacloudRuntimeError detected. " + 
                       "Error Code, Error Type, Error Message: %s, %s, %s" % (
                        ecre.mGetErrorCode(), ecre.mGetErrorType(), ecre.mGetErrorMsg())) 
            ebLogError(traceback.format_exc())
            _rc = ebError(0x0604)
        except Exception as e:
            ebLogError("mStartPatchRequestExecution error: " + str(e))
            ebLogError(traceback.format_exc())
            _rc = ebError(0x0604)

        finally:
            # Release patch-cluster cmd lock
            if not _concurrent:
                self.mReleasePatchCmd()
                ebLogInfo("Step 4 of 5: Released master patch lock")

        # Check if patch execution already failed
        if _rc == ebError(0x0604):
            ebLogError("Patch Execution already failed. "
                       "Not running Patch Monitor")
            return _rc

        try:
            # Start Monitor. It will dispatch every single call
            ebLogInfo("Step 5 of 5: Start Monitoring requests")
            self.mUpdateStatusFromList(True, self.STEP_MONITOR)
            _rc = self.mMonitorPatchRequest()
        except Exception as e:
            ebLogError("mStartPatchRequestExecution -monitor- error: "+str(e))
            ebLogError(traceback.format_exc())
            _rc = ebError(0x0615)

        return _rc

    def mCreateLogDirectory(self):
        """
        Creates a log directory for the master request. This will have symlinks to
        individual worker log directories for all the patch workers.
        Example: exacloud/log/patch/<master_request_UUID>
        """

        try:
            _req = self.mGetRequestObj()
            if _req:
                _dir = self.LOG_DIRECTORY + _req.mGetUUID()
                self.__node.mExecuteCmd('mkdir -p ' + _dir)
                return _dir
            else:
                raise Exception
        except:
            ebLogWarn("No log directory will be created.")

        return None

    def mCreatePatchZipFilesDirs(self, aInternalDirectory):
        """
        Creates a directory for the master request to save the patch zip files
        downloaded from object store.
        """

        _dir = ""

        try:

            if aInternalDirectory:
                _dir = self.PATCH_PAYLOADS_DIRECTORY + aInternalDirectory
                self.__node.mExecuteCmd('mkdir -p ' + _dir)
                ebLogInfo("Directory '%s' successfully created" % _dir)

        except:
            ebLogWarn("Directory '%s' not created." % _dir)

        return None

    def mLinkRequestDirectory(self, aRequestUUID):
        """
        Creates a symbolic link from the master request log directory to
        a certain individual request log directory.
        Example:
            exacloud/log/patch/<master_request_UUID>/<worker_request_UUID> ->
            ../../../oeda/requests/<worker_request_UUID>/log
        """

        _oeda_path = ''
        try:
            for _dir in self.__logDir.split('/'):
                if _dir:
                    _oeda_path+='../'
            _oeda_path+='oeda/requests/'+aRequestUUID+'/log'
            self.__node.mExecuteCmd('cd %s; ln -s %s %s' % (self.__logDir, _oeda_path, aRequestUUID))

        except:
            ebLogWarn("No symlink created to request log directory.")

    def mGetLatestPatchVersion(self):
        """
        Get the latest patch version by looking at the file system and
        object store
        """

        _valid_versions_fs = []
        _valid_versions_objstore = []
        _latest_ver_frm_objstr, _latest_ver_from_fs = None, None

        # instantiate the class oracle version
        _verobj = OracleVersion()

        # List the available patches from the file system PatchPayloads
        # -------------------------------------------------------------
        if os.path.isdir (self.PATCH_PAYLOADS_DIRECTORY) is True:
            _ldir = os.listdir(self.PATCH_PAYLOADS_DIRECTORY)
            # Go through the file system to get the latest patch version
            for _entry in _ldir:
                _patch_dir_path = ''
                _patch_dir_path = self.PATCH_PAYLOADS_DIRECTORY + _entry
                # validate the patch version is dir or not
                if os.path.isdir (_patch_dir_path) is True:
                   # Expect version in form a.b.c.d.e.f[.g] where f is 6 digits
                   # and g is an optional. Example: 12.2.1.1.1.170620, 
                   # 18.1.4.0.0.180125.3, 18.1.10.0.0.181031.1.
                   _re_out = re.match('^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\.[0-9]{6,6}(|\.[0-9]+)$', _entry) 
                   if _re_out: 
                      _valid_versions_fs.append(_entry)
                   else:
                      ebLogWarn("Invalid version found in file system: %s " % _entry)

            ebLogInfo("Following versions are found in file system:")
            for _ver in _valid_versions_fs:
                ebLogInfo("%s" % _ver)

        # get the latest/highest version from file system 
        _latest_ver_from_fs = _verobj.mGetHighestVer(_valid_versions_fs)
        ebLogInfo("Latest version from file system: %s" % _latest_ver_from_fs)

        # Get Latest from object store
        # ----------------------------        
        try:
            # Connect to localhost
            _node = exaBoxNode(get_gcontext(),aLocal=True)
            _node.mConnect(aHost = self.__hostname)

            # Read object storage URL
            _oss_url = self.__object_store_uri 
            if _oss_url:
                # Get encyption/decryption key. config/exadbcpatch.conf has key
                # 'exacs_patch_key' and it's of format 'key = "keyvalue"' and
                # also ignore input line if it started with '#' which can be 
                # treated as comment line 
                _i, _o, _e = _node.mExecuteCmd('grep "exacs_patch_key" config/exadbcpatch.conf | grep -v "^#" | cut -d = -f 2')

                if _o:
                    self.__oss_patch_key = _o.read().replace('\"','').strip('\n')
                    if len(self.__oss_patch_key) == 0:
                        ebLogError("Object Store decryption key is empty")
                        ebLogInfo("LATEST TargetVersion is selected from file system:loc-1: %s " % _latest_ver_from_fs)
                        self.__latest_verion_source_loc = self.LATEST_VER_FROM_FILESYSTEM
                        return _latest_ver_from_fs
                    # print key in asterisks format
                    ebLogInfo("Object Store decryption key: %s" % 
                               self.__oss_patch_key.translate("*"*256))
                elif not _e:
                    ebLogError("Object Store decryption key not found in exadbcpatch.conf. Error: %s" % _e.readlines())
                    ebLogInfo("LATEST TargetVersion is selected from file system:loc-2: %s " % _latest_ver_from_fs)
                    self.__latest_verion_source_loc = self.LATEST_VER_FROM_FILESYSTEM
                    return _latest_ver_from_fs

                # Trailing slash to indicate the last item in the URL is a directory
                if _oss_url[-1] == '/':
                    _oss_url [-1] = ''
                    ebLogInfo("Reading latest version from Object_store: %s" % _oss_url)
            else:
                ebLogInfo("Object Store URI is not available")
                ebLogInfo("LATEST TargetVersion is selected from file system:loc-3: %s " % _latest_ver_from_fs)
                self.__latest_verion_source_loc = self.LATEST_VER_FROM_FILESYSTEM
                return _latest_ver_from_fs

            # Create log dir if not present yet. It so happen that, this dir
            # won't refreshed or truly not created yet, so in that case,
            # nothing wrong to re-create the log dir.
            if os.path.isdir (self.__logDir) is False: 
                _node.mMakeDir(self.__logDir)

            # Command to list version from object store.
            _i, _o, _e = _node.mExecuteCmd('wget --no-parent %s -O %s/ecs_patch_list.txt' % (_oss_url, self.__logDir))

            # Wait for above wget to complete so that ecs_patch_list.txt
            # creates and it's required for grep command 
            if _o:
                _out = _o.readlines()

            # If exit code not 0, then save error message
            if _node.mGetCmdExitStatus() != 0:
                _error_str = _e.readlines()
                if _error_str:
                     ebLogError("Failure in reading Object Store URI. Error: %s" % _error_str)
                     _node.mDisconnect()
                     ebLogInfo("LATEST TargetVersion is selected from file system: %s " % _latest_ver_from_fs)
                     return _latest_ver_from_fs

            _cmd = 'grep "ecs_infra_patch/PatchPayloads" %s/ecs_patch_list.txt | cut -d \'/\' -f 3 | sort -u'
            _i, _o, _e = _node.mExecuteCmd(_cmd % self.__logDir)
            _node.mDisconnect()

            _read_vers = _o.readlines()
            # Go through the object store list to get the latest patch version
            for _entry in _read_vers:
                _entry = _entry.replace("\n",'')
                _entry = _entry.strip()
                # Expect version in form a.b.c.d.e.f[.g] where f is 6 digits
                # and g is an optional. Example: 12.2.1.1.1.170620, 
                # 18.1.4.0.0.180125.3, 18.1.10.0.0.181031.1.
                _re_out = re.match('^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+\.[0-9]{6,6}(|\.[0-9]+)$', _entry) 
                if _re_out: 
                    _valid_versions_objstore.append(_entry)
                else:
                    ebLogWarn("Invalid version found in Object Store: %s " % _entry)

            ebLogInfo("Following versions are found in Object Store:")
            for _ver in _valid_versions_objstore:
                ebLogInfo("%s" % _ver)

            # get the latest/highest version from object store 
            _latest_ver_frm_objstr = _verobj.mGetHighestVer(_valid_versions_objstore)
            ebLogInfo("Latest version from Object Store: %s" % _latest_ver_frm_objstr)
        except Exception as e:
            ebLogWarn('Unable to get version from object Store. Detail: %s' % str(e))

        # Get the latest from both file system and object store 
        if _latest_ver_from_fs and _latest_ver_frm_objstr:
            ret = _verobj.mCompareVersions(_latest_ver_from_fs, _latest_ver_frm_objstr)
            if ret == -1 or ret == 0:
                _target_version = _latest_ver_frm_objstr
                self.__latest_verion_source_loc = self.LATEST_VER_FROM_OBJECTSTORE 
            else:
                _target_version = _latest_ver_from_fs
        elif _latest_ver_from_fs:
            _target_version = _latest_ver_from_fs
        else:
            _target_version = _latest_ver_frm_objstr
            self.__latest_verion_source_loc = self.LATEST_VER_FROM_OBJECTSTORE 

        ebLogInfo("LATEST TargetVersion selected: %s " % _target_version)

        return _target_version

    def mReadClusterNameFromOedaXml(self, _xml_oeda_data):
        """
        Read cluster/customer name from oeda xml. Return cluster name
        """

        # Read cluster/customer name from oeda xml
        _root = ET.fromstring(_xml_oeda_data)
        if re.search("xmlns=", _xml_oeda_data):
            # xmlns found in xml, use name space tag to read 
            # customer name
            ebLogDebug("Found xml name space in oeda xml file")
            _cluster_name = _root.find("{model}customerName").text
        else:
            # no xmlns found in xml, normal read of customer name
            ebLogDebug("Not found xml name space in oeda xml file")
            _cluster_name = _root.find("customerName").text

        return _cluster_name

#########################################################################################################################

class ebCluPatchHealthCheck(object):
    """
    Handles the patch prechecks/postchecks done to ensure the state of the node
    after running the patchmgr
    """

    def __init__(self, aCluCtrlObj):
        self.cluctrl = aCluCtrlObj

    def mPingNode(self, aRemoteNode):
        """
        Pings a host. Then it tries to connect via ssh.
        """

        ebLogInfo("Checking connection to %s." % aRemoteNode)

        if self.cluctrl.mPingHost(aRemoteNode):
            _node = exaBoxNode(get_gcontext())
            try:
                _node.mConnect(aHost=aRemoteNode)
                _node.mDisconnect()
            except:
                ebLogError('Failed to connect to %s (pingable though).' % aRemoteNode)
                return False
        else:
            ebLogError('Failed to ping %s.' % aRemoteNode)
            return False

        return True

    def mCheckTargetVersion(self, aNode, aNodeType, aVersionToCompare=None, aInactiveImage=False):
        """
        Returns the current image version installed on aNode. If aVersionToCompare is provided, the current version on
        aNode is extracted and compared to aVersionToCompare. returns 0 if equal, >0 if aNodes current version is bigger,
        <0 if aNodes current version is lower
        """

        _cmd = 'imageinfo -ver' 
        _current_version = None
        _parse = False

        # instantiate the class oracle version
        _verobj = OracleVersion()

        if aInactiveImage:
            if aNodeType in [ebCluPatchControl.PATCH_DOM0, 
                             ebCluPatchControl.PATCH_DOMU]:
                _cmd = ("/opt/oracle.SupportTools/dbserver_backup.sh "
                        "--ignore-nfs-smbfs-mounts --check-rollback "
                       "| grep -a 'Image version on the spare root partition'")
                _parse = True
            if aNodeType == ebCluPatchControl.PATCH_CELL:
                _cmd = "imageinfo -inactive -ver"
             
        #TODO this only works for dbnodes and cells
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aNode)

        _i, _o, _e = _node.mExecuteCmd(_cmd)
        _node.mDisconnect()

        _o =  _o.readlines()
        if _o:
            if _parse:
                _re_out = re.match('.*Image version on the spare root partition is\s+(.+)', _o[0].strip())
                if _re_out:
                    _current_version = _re_out.groups()[0]
                    ebLogDebug('Image version when parsing enabled = %s' % _current_version)
            else:
                if not _o[0].strip().lower().startswith('undefined'):
                    _current_version = _o[0].strip()
                    ebLogDebug('Image version when parsing is not enabled = %s' % _current_version)
        else:
            ebLogInfo('mCheckTargetVersion: Not able to fetch Image version.')

        _e = _e.readlines()
        if _e:
            ebLogInfo('mCheckTargetVersion: Error in fetching image version: (%s)'% _e)

        if not aInactiveImage and not _current_version:
            raise Exception("Unable to obtain or parse image version for %s. got: %s" % (aNode, _current_version))

        if not aVersionToCompare or not _current_version:
            return _current_version

        """taken from  /opt/oracle.cellos/host_access_control """

        return _verobj.mCompareVersions(_current_version, aVersionToCompare)

    def mCheckIBSwitchVersion(self, aIBSwitch, aVersionToCompare=None):
        """
        Returns the firmware version installed in aIBSwitch. If aVersionToCompare is provided, then
        it returns 0 if aIBSwitch version is equal to aVersionToCompare, <0 if aIBSwitch version is lower or
        >0 if aIBSwitch version is higher.
        """

        _ret = 0
        _cmd = 'version | head -1'
        _current_version = None

        # instantiate the class oracle version
        _verobj = OracleVersion()
     
        _switch = exaBoxNode(get_gcontext())
        _switch.mConnect(aHost=aIBSwitch)
        _in, _out, _err = _switch.mExecuteCmd(_cmd)
        _switch.mDisconnect()
        _output = _out.readlines()

        if _output:
            _current_version = _output[0].strip().split()[-1]

        if not _current_version or not aVersionToCompare:
            return _current_version
        
        ebLogInfo('mCheckIBSwitchVersion: Current version = %s, and Comparing Version = %s' % 
                   (_current_version, aVersionToCompare))
        return _verobj.mCompareVersions(_current_version, aVersionToCompare)

    def mCheckCrsIsUp(self, aDomU):
        """
        Checks the CRS status Up or Down. Returns True if up else, False
        """

        _ret = True
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDomU)
        _cmd = "cat /etc/oratab | grep '^+ASM.*' | cut -f 2 -d ':'"
        ebLogInfo("Wait for crs to be up")
        _crs_cmd_pfx = _node.mSingleLineOutput(_cmd)
        _crs_cmd_pfx += '/bin/crsctl '
        _cmd = _crs_cmd_pfx + 'check crs'
        _in, _out, _err = _node.mExecuteCmd(_cmd)
        _output = _out.readlines()
        # expcting the following output
        # CRS-4638: Oracle High Availability Services is online
        # CRS-4537: Cluster Ready Services is online
        # CRS-4529: Cluster Synchronization Services is online
        # CRS-4533: Event Manager is online

        if _output:
            _crs_up = True
            for _line in _output:
                _line = _line.strip()
                if "is online" not in _line:
                    ebLogInfo('*** crs check cluster output: ' +_line)
                    _crs_up = False
                    break
            if _crs_up == True:
                _ret = _ret and True
            else:
                _ret = _ret and False
        else:
            _errors = _err.readlines()
            ebLogError("CRS check output:\n" + "\n".join(_errors))
            _ret = False
        _node.mDisconnect()
        return _ret

    def mCheckCrsIsEnabled(self, aDomU):
        """
         Checks the CRS config is enabled or disabled. Returns True if enabled 
         else, False
        """

        _ret = True
        _cmd = ("crs=`cat /etc/oratab|grep grid|grep -v '^#'"
                  "|grep -i asm|cut -d ':' -f2`; $crs/bin/crsctl config crs")
        
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aDomU)
        _in, _out, _err = _node.mExecuteCmd(_cmd)
        _output = _out.readlines()
        # expcting the following output
        # CRS-4622: Oracle High Availability Services autostart is enabled.
      
        if _output and _output[0].strip().lower().endswith('enabled.'):
                _ret = True
        else:
            _errors = _err.readlines()
            ebLogError("CRS config output:\n" + "\n".join(_errors))
            _ret = False
        _node.mDisconnect()
        return _ret

    def mCollectCrsResourceStat(self, aNode ,aLogFile, aTaskType=None ):
        """
         ToDo: This method is required for future enhancement.

         This method is invoked before and after upgrade/Rollaback 
         of DomU patching to ensure all the services running before 
         upgrade or rollback is started up after the patching is 
         complete.
        """

        _ret = True
        _cmd_crs_cmd = "crs=`cat /etc/oratab|grep grid|grep -v '^#'|grep -i asm|cut -d ':' -f2`;$crs/bin/crsctl status res > %s" %(aLogFile)

        _aDomU = exaBoxNode(get_gcontext())
        _aDomU.mConnect(aHost=aNode)
        _in, _out, _err = _aDomU.mExecuteCmd(_cmd_crs_cmd)
        _aDomU.mDisconnect()
            
        if aTaskType in [ ebCluPatchControl.TASK_POSTCHECK ]:
            _crs_diff_cmd = "diff %s %s" %(ebCluPatchControl.PREPATCH_CRS_LOG, ebCluPatchControl.POSTPATCH_CRS_LOG)
            _aDomU = exaBoxNode(get_gcontext())
            _aDomU.mConnect(aHost=aNode)
            _in, _out, _err = _aDomU.mExecuteCmd(_crs_diff_cmd)
            _output = _out.readlines()
            if _aDomU.mGetCmdExitStatus() != 0:
                ebLogError("There were some differences reported in the CRS resource logs, precheck CRS logs : %s Postcheck CRS logs : %s \n"  %(ebCluPatchControl.PREPATCH_CRS_LOG, ebCluPatchControl.POSTPATCH_CRS_LOG))
                ebLogInfo("diff %s %s \n" %(ebCluPatchControl.PREPATCH_CRS_LOG,ebCluPatchControl.POSTPATCH_CRS_LOG))
                for _out in _output:
                    _out = _out.rstrip()
                    ebLogInfo("%s" %_out)
                _ret = False
            else:
                _aDomU.mDisconnect()
            return _ret

    def mCheckImageSuccess(self, aNode):
        """
        Checks the image installation status.
        """

        _ret = False
        _cmd = "/usr/local/bin/imageinfo -status "
        _node = exaBoxNode(get_gcontext())
        _node.mConnect(aHost=aNode)
        _in, _out, _err = _node.mExecuteCmd(_cmd)
        _output = _out.readlines()
        if _output:
            if _output[0].strip().lower().startswith('success'):
                _ret = True
            else:
                ebLogError("Imageinfo output:\n" + "\n".join(_output))
        _node.mDisconnect()
        return _ret

    def mCheckIBSwitchSMState(self, aIBSwitch, aOrigState={}):
        """
        Checks SM state. It includes: opensmd, partconfig and getmaster.
        if aOrigState is provided.
        """

        _cmd = 'service opensmd status; service partconfigd status; getmaster '\
               '| head -n 1'
        _opensm = True
        _partitiond = True
        _sm_enabled = True
        _sm_state = None

        try:
            _switch = exaBoxNode(get_gcontext())
            _switch.mConnect(aHost=aIBSwitch)
            _in, _out, _err = _switch.mExecuteCmd(_cmd)
            _output = _out.readlines()
            if _output and len(_output)>=3:
                if re.match("opensm is stopped", _output[0].strip()):
                    _opensm = False
                if re.match("partitiond-daemon is stopped", _output[1].strip()):
                    _partitiond = False
                if re.match("Local SM not enabled", _output[2].strip()):
                    _sm_enabled = False
                elif re.match("Local SM enabled and running", _output[2].strip()):
                    _match = re.match(".*state\s+([A-Z\s]+)", _output[2].strip())
                    if _match:
                        _sm_state = _match.groups()[0]
            _switch.mDisconnect()

            if aOrigState:
                if aOrigState['opensm'] == _opensm and aOrigState['partitiond'] == _partitiond and \
                   aOrigState['sm_enabled'] == _sm_enabled:
                    # Bu26943824 - remove all white-space and special chars from
                    # sm_state and then compare with string 'STANDBY', so that we
                    # really don't worry about whether sm_state has either 
                    # 'STAND BY' or 'STANDBY'
                    aOrigState['sm_state'] = re.sub('\s', '', aOrigState['sm_state'])
                    if _sm_state is not None:
                        _sm_state = re.sub('\s', '', _sm_state)

                    if aOrigState['sm_state'] == _sm_state:
                        return True
                    if aOrigState['sm_state'] == 'MASTER' and _sm_state == 'STANDBY':
                        return True
                    if _sm_state == 'MASTER' and aOrigState['sm_state'] == 'STANDBY':
                        return True
                
                ebLogWarn('opensmd enabled    - expected: %s current: %s' % (aOrigState['opensm'], _opensm))
                ebLogWarn('partitiond enabled - expected: %s current: %s' % (aOrigState['partitiond'], _partitiond))
                ebLogWarn('SM enabled state   - expected: %s current: %s' % (aOrigState['sm_enabled'], _sm_enabled))
                ebLogWarn('SM state           - expected: %s current: %s' % (aOrigState['sm_state'], _sm_state))
                return False

        except Exception as e:
            ebLogError("\nError in populating IBSwitch service status on '%s'.\n" % aIBSwitch)
            ebLogError("*** "+str(e))
            ebLogError(traceback.format_exc())

        return   {'opensm'    : _opensm,
                  'partitiond'  : _partitiond,
                  'sm_enabled': _sm_enabled,
                  'sm_state'  : _sm_state}

    def mCheckIBSwitchPartitions(self, aIBSwitch, aOrigState={}):
        """
        Checks 'smnodes' and 'smpartition' are same even after patching/rollback 
        apply. Return True if list is same, and return False if list is changed.
        It also collects original state of smnode_list and smpartition_list if 
        this function doesn't have aOrigState argument is passed.
        """

        _smnode_list_output = None
        _smpartition_list_output = None

        try:
            _switch = exaBoxNode(get_gcontext())
            _switch.mConnect(aHost=aIBSwitch)
  
            _cmd = "smnodes list"
            _in, _out, _err = _switch.mExecuteCmd(_cmd)
            if _out:
                _smnode_list_output = _out.read()
                _smnode_list_output = re.sub('\s', '', _smnode_list_output) 

            _cmd = "smpartition list active no-page"
            _in, _out, _err = _switch.mExecuteCmd(_cmd)
            if _out:
                _smpartition_list_output = _out.read()
                _smpartition_list_output = re.sub('\s', '', _smpartition_list_output) 

            _switch.mDisconnect()

            if aOrigState:
                # Remove special char, white-spaces before comparison the sm list output
                if _smnode_list_output is not None:
                    _smnode_list_output = re.sub('\s', '', _smnode_list_output)
                if _smpartition_list_output is not None:
                    _smpartition_list_output = re.sub('\s', '', _smpartition_list_output)

                if aOrigState['smnodes_list'] == _smnode_list_output and \
                   aOrigState['smpartition_list'] == _smpartition_list_output:
                       return True

                ebLogWarn('SM Node List      - expected: %s current: %s' % (aOrigState['smnodes_list'], _smnode_list_output))
                ebLogWarn('SM Partition List - expected: %s current: %s' % (aOrigState['smpartition_list'], _smpartition_list_output))
                return False
        except Exception as e:
            ebLogError("\nError in populating IBSwitch service status on '%s'.\n" % aIBSwitch)     
            ebLogError("*** "+str(e))
            ebLogError(traceback.format_exc())

        return   {'smnodes_list'  : _smnode_list_output,
                  'smpartition_list'  : _smpartition_list_output}

    def mCheckCellServices(self, aCell, aOrigState={}, aCheckRunning=False):
        """
        Checks the cell services status. if aCheckRunning is set to True,
        it checks if services are up. If aOrigState provided, then it compares the
        current services state with the ones from the input.
        If aOrigState is no specified, then it returns the current services status.
        """

        _services = {}
        _cmd = 'cellcli -e "list cell detail" | grep running'

        ebLogDebug("Check running service flag: '%s'" % aCheckRunning)
        _cell = exaBoxNode(get_gcontext())
        _cell.mConnect(aHost=aCell)
        _in, _out, _err = _cell.mExecuteCmd(_cmd)
        _exit_code = _cell.mGetCmdExitStatus()
        _output = _out.readlines()
        _cell.mDisconnect()
        # we should get three exadata services to be up and running.
        # Example:
        #  cellsrvStatus:          running
        #  msStatus:               running
        #  rsStatus:               running

        if _output:
            for _line in _output:
                _tmp = _line.split()
                _services[_tmp[0][:-1]] = _tmp[1].strip()

        if aCheckRunning:
            if not _services or len(_services) != 3:
                ebLogWarn("Cell service status on cell '%s' is: '%s'" % (aCell, _services))
                return False
            return True

        if aOrigState:
            for _service in _services.keys():
                if _service and aOrigState[_service] == _services[_service]:
                    continue
                if _service:
                    ebLogWarn("Cell service Original state = '%s', NewState ='%s' on cell '%s'" % (aOrigState[_service], _services[_service], aCell))
                else:
                    ebLogWarn("Cell service Original state = '%s' on cell '%s'" % (aOrigState[_service],  aCell))
                return False
            return True

        return _services

    def mCheckDBServices(self, aDBNode, aOrigState={}, aCheckRunning=False):
        """
        Checks the dbserverd services status. if aCheckRunning is set to True,
        it checks if services are up. If aOrigState provided, then it compares the
        current services state with the ones from the input.
        If aOrigState is no specified, then it returns the current services status.
        """

        _services = {}
        _cmd = 'dbmcli -e "list dbserver detail" | egrep "msStatus|rsStatus"'

        if aCheckRunning:
            _cmd += ' | grep -asiq running'


        _dbnode = exaBoxNode(get_gcontext())
        _dbnode.mConnect(aHost=aDBNode)
        _in, _out, _err = _dbnode.mExecuteCmd(_cmd)
        _exit_code = _dbnode.mGetCmdExitStatus()
        _output = _out.readlines()
        _dbnode.mDisconnect()

        if aCheckRunning:
            if int(_exit_code) != 0:
                return False
            return True

        if _output:
            for _line in _output:
                _tmp = _line.split()
                _services[_tmp[0][:-1]] = _tmp[1].strip()

        if aOrigState:
            for _service in _services.keys():
                if _service and aOrigState[_service] == _services[_service]:
                    continue
                return False
            return True

        return _services


    def mCheckVMsUp(self, aDom0, aOrigVMsList=None):
        """
        Gets a list of active vms (xm list). If aOrigVMsList provided,
        if the dom0 has all the vms from the list up, True is returned.
        If the dom0 does not have all of the vms up, False is returned
        """

        _domUs = []
        _cmd = ""

        if self.cluctrl.mIsKVM(aHostname=aDom0):
            _cmd = "virsh list|tail -n+3|awk '{print $2}' | sed '/^$/d'"
        else:
            _cmd = "xm list|tail -n+3|awk '{print $1}'"

        _dom0 = exaBoxNode(get_gcontext())
        _dom0.mConnect(aHost=aDom0)
        _in, _out, _err = _dom0.mExecuteCmd(_cmd)
        _output = _out.readlines()
        _dom0.mDisconnect()

        if _output:
            for _line in _output:
                _domUs.append(_line.strip())

        if aOrigVMsList is not None:
            for _vm in aOrigVMsList:
                if _vm not in _domUs:
                    return False
            return True

        return _domUs


    def mVerifyCellsInUseByASM(self, aCellList):
        """
        Returns the list of cells that are actually in use by ASM.
        """

        _cmd_cell = "cellcli -e 'list griddisk attributes name, asmmodestatus'| grep -asq 'ONLINE\|SYNC'"
        _cmd_cell_restart = 'cellcli -e "alter cell restart services all"'
        _cells_in_use = []

        for _cell in aCellList:

            # Check cell services are up
            _up_services = self.mCheckCellServices(_cell, aCheckRunning=True)
            if not _up_services:
                # Restart services to see if they go up
                ebLogInfo("Cell services will be restarted")
                _node = exaBoxNode(get_gcontext())
                _node.mConnect(aHost=_cell)
                _node.mExecuteCmdLog(_cmd_cell_restart)
                sleep(10)
                _node.mDisconnect()
                # Get celld status again
                _up_services = self.mCheckCellServices(_cell, aCheckRunning=True)

            if _up_services:
                _node = exaBoxNode(get_gcontext())
                _node.mConnect(aHost=_cell)
                _in, _out, _err = _node.mExecuteCmd(_cmd_cell)
                _rc = _node.mGetCmdExitStatus()
                _node.mDisconnect()

                if int(_rc) == 0:
                    _cells_in_use.append(_cell)

            else:
                ebLogError("Cell services not up in cell %s. It will be ignored" % _cell)

        return _cells_in_use


    def mControlCellServices(self, aCellList, aAction='start'):
        """
        Controls cell services by starting/stopping the services. It checks that celld status
        shows as expected.
        """

        _cmd = None
        _success = True

        if aAction == 'start':
            _cmd = 'service celld start'
        elif aAction == 'stop':
            _cmd = 'service celld stop'
        elif aAction == 'restart':
            _cmd = 'cellcli -e "alter cell restart services all"'
        else:
            ebLogError("Action '%s' not valid in mControlCellServices" % aAction)
            return False

        def _runCellServicesCmd(aCell):
            _ret = True

            _cell = exaBoxNode(get_gcontext())
            _cell.mConnect(aHost=aCell)
            _in, _out, _err = _cell.mExecuteCmd(_cmd)

            _errors = _err.readlines()
            if _errors:
                ebLogWarn("".join(_errors))

            _cell.mDisconnect()
            _services = self.mCheckCellServices(aCell)

            for _s in _services.keys():
                if aAction == 'start' or aAction == 'restart':
                    if _services[_s] != 'running':
                        ebLogError("Cell '%s' service %s not running. Status = %s" % (aCell, _s, _services[_s]))
                        _ret = False
                else:
                    if _services[_s] == 'running':
                        ebLogError("Cell '%s' service %s is running." % (aCell, _s))
                        _ret = False
            return _ret

        for _cell in aCellList:
            ebLogInfo("Run cell services action '%s' in cell '%s'" % (aAction, _cell))
            _success &= _runCellServicesCmd(_cell)

        return _success


    def mManageVMs(self, aDom0, aDomUList, aAction='start'):
        """
        Creates/shutdown VMs in aDom0
        """

        _success = True

        if aAction not in['start', 'shutdown']:
            ebLogError("Action '%s' not valid in mManageVMs" % aAction)
            return 0

        _dom0 = exaBoxNode(get_gcontext())
        _dom0.mConnect(aHost=aDom0)

        vmhandle = ebVgLifeCycle()
        vmhandle.mSetOVMCtrl(aCtx=get_gcontext(), aNode=_dom0)

        for _domU in aDomUList:

            ebLogInfo("Action '%s' vm '%s' in dom0 '%s'" % (aAction, _domU, aDom0))
            _ret = vmhandle.mDispatchEvent(aAction, aOptions=None, aVMId=_domU)

            if _ret != 0:
                # It is possible vms where already up/down. In those case, we should not return error
                if (aAction == 'start' and _ret != 0x0410) or (aAction == 'shutdown' and _ret !=0x0411):
                    _success = False
                    continue

            if aAction == 'start' and _ret == 0:
                ebLogInfo("Waiting for vm '%s' to come up (until cpu_time = 40)" % _domU)
                if self.cluctrl.mIsKVM(aHostname=aDom0):
                    # virsh cpu-stats <domu> --total | grep -ia cpu_time | awk  '{print $2}'
                    # 190370.589664906
                    _cpu_cmd_to_execute = "virsh cpu-stats  %s --total | grep -ia cpu_time | awk  '{print $2}'" % _domU
                else:
                    # xm list <domU> -l | grep -ia cpu_time
                    # (cpu_time 224204.654947)
                    _cpu_cmd_to_execute = "xm list %s -l|grep -ia cpu_time" % _domU
                while True:
                    _i, _o, _e = _dom0.mExecuteCmd(_cpu_cmd_to_execute)
                    _out = _o.readlines()
                    if _out:
                        _cpu_time = re.search("([0-9]+\.[0-9]+)", _out[0])
                        if _cpu_time:
                            if float(_cpu_time.groups()[0]) >= 40.0:
                                break
                        else:
                            ebLogError("Not able to parse cpu_time data in vm '%s'" % _domU)
                            break
                    else:
                        ebLogError("No vm '%s' information available" % _domU)
                        break

                    sleep(30)

        _dom0.mDisconnect()

        return _success


    def mVerifyGriddiskDeactivationOutcome(self, aCellList, aTaskType):
        """
        Returns True if asmdeactivationoutcome is set to 'Yes', otherwise, return False
        """

        _ret = True

        if aTaskType in [ebCluPatchControl.OP_STYLE_NON_ROLLING, ebCluPatchControl.OP_STYLE_AUTO]:
            _cmd_cell = "cellcli -e list griddisk attributes name,asmmodestatus,asmdeactivationoutcome where asmmodestatus='ONLINE'"
        elif aTaskType in [ebCluPatchControl.OP_STYLE_ROLLING, ebCluPatchControl.OP_STYLE_AUTO]: 
            _cmd_cell = "cellcli -e list griddisk attributes name,asmmodestatus,asmdeactivationoutcome where asmmodestatus='ONLINE' and asmdeactivationoutcome !='Yes'"

        for _cell in aCellList:
            _node = exaBoxNode(get_gcontext())
            _node.mConnect(aHost=_cell)
            _in,_out,_err = _node.mExecuteCmd(_cmd_cell)
            _output = _out.readlines()
            if _output:
                ebLogInfo('Following Griddisks cannot be de-activated on cell: (%s)' % (_cell))
                for _line in _output:
                    _disk_split = _line.split(None, 2)
                    if _disk_split:
                        if aTaskType in [ebCluPatchControl.OP_STYLE_NON_ROLLING, ebCluPatchControl.OP_STYLE_AUTO]:
                            ebLogInfo('*** Disk name : %s , Reason : %s' % (_disk_split[0],_disk_split[1]))
                        elif aTaskType in [ebCluPatchControl.OP_STYLE_ROLLING, ebCluPatchControl.OP_STYLE_AUTO]:
                            ebLogInfo('*** Disk name : %s , Reason : %s' % (_disk_split[0],_disk_split[2]))
                        _ret = False
            _node.mDisconnect()

        return _ret
